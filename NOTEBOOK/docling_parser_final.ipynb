{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d64cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% PHASE A ENHANCED - Production-ready version\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.types.doc import TextItem, TableItem, PictureItem\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be16690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseAParser:\n",
    "    \"\"\"Enhanced parser for Phase A with better error handling and features.\"\"\"\n",
    "    \n",
    "    def __init__(self, pdf_path: Path, output_dir: Path, pdf_hash: str):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_dir = output_dir\n",
    "        self.pdf_hash = pdf_hash\n",
    "        self.blocks = []\n",
    "        self.section_stack = []\n",
    "        self.stats = defaultdict(int)\n",
    "        \n",
    "    def parse(self) -> List[Dict]:\n",
    "        \"\"\"Main parsing workflow.\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"PHASE A: PARSE & NORMALIZE (ENHANCED)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Convert\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(str(self.pdf_path))\n",
    "        doc = result.document\n",
    "        \n",
    "        # Extract blocks\n",
    "        block_id = 0\n",
    "        for item, level in doc.iterate_items():\n",
    "            try:\n",
    "                block = self._extract_block(item, level, block_id, doc)\n",
    "                if block:\n",
    "                    self.blocks.append(block)\n",
    "                    self.stats[block['type']] += 1\n",
    "                    block_id += 1\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error processing block {block_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Post-processing\n",
    "        self._augment_captions()\n",
    "        self._validate_blocks()\n",
    "        \n",
    "        # Save\n",
    "        self._save_output()\n",
    "        self._print_stats()\n",
    "        \n",
    "        return self.blocks\n",
    "    \n",
    "    def _extract_block(self, item, level: int, block_id: int, doc) -> Optional[Dict]:\n",
    "        \"\"\"Extract single block with full metadata.\"\"\"\n",
    "        \n",
    "        # Get provenance metadata\n",
    "        page, bbox = self._extract_provenance(item)\n",
    "        \n",
    "        # Type and text extraction\n",
    "        if isinstance(item, PictureItem):\n",
    "            block = self._extract_figure(item, doc, block_id, page, bbox)\n",
    "        elif isinstance(item, TableItem):\n",
    "            block = self._extract_table(item, doc, block_id, page, bbox)\n",
    "        elif isinstance(item, TextItem):\n",
    "            block = self._extract_text(item, doc, block_id, page, bbox, level)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        # Add common metadata\n",
    "        block.update({\n",
    "            \"section_path\": \" > \".join(self.section_stack) if self.section_stack else \"root\",\n",
    "            \"pdf_hash\": self.pdf_hash,\n",
    "            \"level_in_doc\": level  # Original document level\n",
    "        })\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def _extract_provenance(self, item) -> Tuple[Optional[int], Optional[Dict]]:\n",
    "        \"\"\"Extract page and bounding box from provenance.\"\"\"\n",
    "        page, bbox = None, None\n",
    "        if hasattr(item, 'prov') and item.prov:\n",
    "            prov = item.prov[0]\n",
    "            page = getattr(prov, 'page_no', None)\n",
    "            if hasattr(prov, 'bbox'):\n",
    "                b = prov.bbox\n",
    "                bbox = {\n",
    "                    \"x0\": float(b.l), \n",
    "                    \"y0\": float(b.t), \n",
    "                    \"x1\": float(b.r), \n",
    "                    \"y1\": float(b.b),\n",
    "                    \"width\": float(b.r - b.l),\n",
    "                    \"height\": float(b.t - b.b)\n",
    "                }\n",
    "        return page, bbox\n",
    "    \n",
    "    def _extract_figure(self, item: PictureItem, doc, block_id: int, \n",
    "                       page: int, bbox: Dict) -> Dict:\n",
    "        \"\"\"Extract figure block.\"\"\"\n",
    "        return {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": \"figure\",\n",
    "            \"text\": \"[Figure]\",\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"caption\": item.caption_text(doc=doc),\n",
    "            \"figure_id\": str(item.self_ref),\n",
    "            \"has_caption\": bool(item.caption_text(doc=doc))\n",
    "        }\n",
    "    \n",
    "    def _extract_table(self, item: TableItem, doc, block_id: int,\n",
    "                      page: int, bbox: Dict) -> Dict:\n",
    "        \"\"\"Extract table block.\"\"\"\n",
    "        markdown = item.export_to_markdown(doc=doc)\n",
    "        return {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": \"table\",\n",
    "            \"text\": markdown,\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"caption\": item.caption_text(doc=doc),\n",
    "            \"table_id\": str(item.self_ref),\n",
    "            \"has_caption\": bool(item.caption_text(doc=doc)),\n",
    "            \"num_rows\": markdown.count('\\n') if markdown else 0,\n",
    "            \"num_cols\": len(markdown.split('\\n')[0].split('|')) - 2 if markdown and '\\n' in markdown else 0\n",
    "        }\n",
    "    \n",
    "    def _extract_text(self, item: TextItem, doc, block_id: int,\n",
    "                     page: int, bbox: Dict, level: int) -> Dict:\n",
    "        \"\"\"Extract text-based block (heading, paragraph, code, etc).\"\"\"\n",
    "        \n",
    "        # Classify type\n",
    "        label = str(item.label).lower() if hasattr(item, 'label') else ''\n",
    "        text = item.text or \"\"\n",
    "        \n",
    "        if 'section' in label or 'title' in label:\n",
    "            item_type = 'heading'\n",
    "            self._update_section_stack(text, level)\n",
    "        elif 'code' in label:\n",
    "            item_type = 'code'\n",
    "        elif 'formula' in label or 'equation' in label:\n",
    "            item_type = 'equation'\n",
    "        elif 'list' in label or text.strip().startswith(('•', '-', '*', '1.', '2.')):\n",
    "            item_type = 'list'\n",
    "        else:\n",
    "            item_type = 'paragraph'\n",
    "        \n",
    "        block = {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": item_type,\n",
    "            \"text\": text,\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"char_count\": len(text),\n",
    "            \"word_count\": len(text.split())\n",
    "        }\n",
    "        \n",
    "        # Type-specific fields\n",
    "        if item_type == \"heading\":\n",
    "            block[\"heading_level\"] = level\n",
    "        elif item_type == \"code\":\n",
    "            block[\"code_language\"] = getattr(item, 'code_language', 'unknown')\n",
    "        elif item_type == \"equation\":\n",
    "            block[\"latex\"] = getattr(item, 'latex', None)\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def _update_section_stack(self, text: str, level: int):\n",
    "        \"\"\"Update section hierarchy stack.\"\"\"\n",
    "        if not text or len(text) < 3:\n",
    "            return\n",
    "        \n",
    "        # Adjust stack based on level\n",
    "        if level <= len(self.section_stack):\n",
    "            self.section_stack = self.section_stack[:level-1]\n",
    "        \n",
    "        self.section_stack.append(text[:100])  # Truncate long headings\n",
    "    \n",
    "    def _augment_captions(self):\n",
    "        \"\"\"Enhanced caption augmentation with multiple strategies.\"\"\"\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if block['type'] not in ['figure', 'table']:\n",
    "                continue\n",
    "            if block.get('caption'):\n",
    "                continue\n",
    "            \n",
    "            caption = None\n",
    "            \n",
    "            # Strategy 1: Look backward for heading on same page\n",
    "            for j in range(i-1, max(i-30, -1), -1):\n",
    "                prev = self.blocks[j]\n",
    "                if prev['page'] != block['page']:\n",
    "                    break\n",
    "                if prev['type'] == 'heading' and prev.get('heading_level', 99) <= 3:\n",
    "                    caption = prev['text']\n",
    "                    break\n",
    "            \n",
    "            # Strategy 2: Look forward for paragraph starting with \"Figure\" or \"Table\"\n",
    "            if not caption:\n",
    "                for j in range(i+1, min(i+5, len(self.blocks))):\n",
    "                    next_block = self.blocks[j]\n",
    "                    if next_block['page'] != block['page']:\n",
    "                        break\n",
    "                    text = next_block.get('text', '').strip()\n",
    "                    if text.startswith(('Figure', 'Table', 'Fig.')):\n",
    "                        caption = text.split('\\n')[0]  # First line only\n",
    "                        break\n",
    "            \n",
    "            # Strategy 3: Use section path as fallback\n",
    "            if not caption:\n",
    "                caption = block['section_path']\n",
    "            \n",
    "            block['caption'] = caption\n",
    "            block['caption_source'] = 'augmented'\n",
    "            block['has_caption'] = True\n",
    "    \n",
    "    def _validate_blocks(self):\n",
    "        \"\"\"Validate and clean blocks.\"\"\"\n",
    "        valid_blocks = []\n",
    "        for block in self.blocks:\n",
    "            # Skip empty text blocks\n",
    "            if block['type'] in ['paragraph', 'heading'] and not block.get('text', '').strip():\n",
    "                continue\n",
    "            \n",
    "            # Ensure required fields\n",
    "            if 'block_id' not in block or 'type' not in block:\n",
    "                continue\n",
    "            \n",
    "            valid_blocks.append(block)\n",
    "        \n",
    "        self.blocks = valid_blocks\n",
    "    \n",
    "    def _save_output(self):\n",
    "        \"\"\"Save blocks to JSONL.\"\"\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_file = self.output_dir / \"docling_blocks.jsonl\"\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for block in self.blocks:\n",
    "                f.write(json.dumps(block, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        print(f\"\\n✓ Saved: {output_file}\")\n",
    "    \n",
    "    def _print_stats(self):\n",
    "        \"\"\"Print comprehensive statistics.\"\"\"\n",
    "        fig_tab = [b for b in self.blocks if b['type'] in ['figure', 'table']]\n",
    "        with_caps = [b for b in fig_tab if b.get('has_caption')]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"EXTRACTION STATISTICS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total blocks: {len(self.blocks)}\")\n",
    "        print(f\"\\nBlock types:\")\n",
    "        for block_type, count in sorted(self.stats.items()):\n",
    "            print(f\"  {block_type:12s}: {count:4d}\")\n",
    "        print(f\"\\nFigures/Tables: {len(fig_tab)}\")\n",
    "        print(f\"With captions:  {len(with_caps)} ({len(with_caps)/len(fig_tab)*100:.1f}%)\")\n",
    "        print(f\"\\nPages covered: {len(set(b['page'] for b in self.blocks if b.get('page')))}\")\n",
    "        print(f\"\\nREADY FOR PHASE B: CHUNKING EXPERIMENTS\")\n",
    "        print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed91273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:48:13,428 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-21 13:48:13,486 - INFO - Going to convert document batch...\n",
      "2025-10-21 13:48:13,487 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-21 13:48:13,499 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 13:48:13,501 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-21 13:48:13,508 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 13:48:13,510 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE A: PARSE & NORMALIZE (ENHANCED)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:48:13,881 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-10-21 13:48:13,901 - INFO - Accelerator device: 'mps'\n",
      "2025-10-21 13:48:15,097 - INFO - Accelerator device: 'mps'\n",
      "2025-10-21 13:48:15,677 - INFO - Processing document fintbx_ex.pdf\n",
      "2025-10-21 13:48:41,370 - INFO - Finished converting document fintbx_ex.pdf in 27.95 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved: ../data/final/docling_blocks.jsonl\n",
      "\n",
      "============================================================\n",
      "EXTRACTION STATISTICS\n",
      "============================================================\n",
      "Total blocks: 907\n",
      "\n",
      "Block types:\n",
      "  code        :   40\n",
      "  equation    :   15\n",
      "  figure      :    8\n",
      "  heading     :   54\n",
      "  list        :   35\n",
      "  paragraph   :  742\n",
      "  table       :   13\n",
      "\n",
      "Figures/Tables: 21\n",
      "With captions:  21 (100.0%)\n",
      "\n",
      "Pages covered: 28\n",
      "\n",
      "READY FOR PHASE B: CHUNKING EXPERIMENTS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% RUN ENHANCED PARSER\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = Path(\"../data/fintbx_ex.pdf\")\n",
    "    output_dir = Path(\"../data/final\")\n",
    "    \n",
    "    parser = PhaseAParser(\n",
    "        pdf_path=pdf_path,\n",
    "        output_dir=output_dir,\n",
    "        pdf_hash=\"sample_hash\"  # Replace with actual hash\n",
    "    )\n",
    "    \n",
    "    blocks = parser.parse()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
