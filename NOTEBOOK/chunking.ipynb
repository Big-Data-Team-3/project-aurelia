{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e1a094",
   "metadata": {},
   "source": [
    "## Stage  1: Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc01823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% PHASE A ENHANCED - Production-ready version\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.types.doc import TextItem, TableItem, PictureItem\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450f1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseAParser:\n",
    "    \"\"\"Enhanced parser for Phase A with better error handling and features.\"\"\"\n",
    "    \n",
    "    def __init__(self, pdf_path: Path, output_dir: Path, pdf_hash: str):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.output_dir = output_dir\n",
    "        self.pdf_hash = pdf_hash\n",
    "        self.blocks = []\n",
    "        self.section_stack = []\n",
    "        self.stats = defaultdict(int)\n",
    "        \n",
    "    def parse(self) -> List[Dict]:\n",
    "        \"\"\"Main parsing workflow.\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"PHASE A: PARSE & NORMALIZE (ENHANCED)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Convert\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(str(self.pdf_path))\n",
    "        doc = result.document\n",
    "        \n",
    "        # Extract blocks\n",
    "        block_id = 0\n",
    "        for item, level in doc.iterate_items():\n",
    "            try:\n",
    "                block = self._extract_block(item, level, block_id, doc)\n",
    "                if block:\n",
    "                    self.blocks.append(block)\n",
    "                    self.stats[block['type']] += 1\n",
    "                    block_id += 1\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Error processing block {block_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Post-processing\n",
    "        self._augment_captions()\n",
    "        self._validate_blocks()\n",
    "        \n",
    "        # Save\n",
    "        self._save_output()\n",
    "        self._print_stats()\n",
    "        \n",
    "        return self.blocks\n",
    "    \n",
    "    def _extract_block(self, item, level: int, block_id: int, doc) -> Optional[Dict]:\n",
    "        \"\"\"Extract single block with full metadata.\"\"\"\n",
    "        \n",
    "        # Get provenance metadata\n",
    "        page, bbox = self._extract_provenance(item)\n",
    "        \n",
    "        # Type and text extraction\n",
    "        if isinstance(item, PictureItem):\n",
    "            block = self._extract_figure(item, doc, block_id, page, bbox)\n",
    "        elif isinstance(item, TableItem):\n",
    "            block = self._extract_table(item, doc, block_id, page, bbox)\n",
    "        elif isinstance(item, TextItem):\n",
    "            block = self._extract_text(item, doc, block_id, page, bbox, level)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        # Add common metadata\n",
    "        block.update({\n",
    "            \"section_path\": \" > \".join(self.section_stack) if self.section_stack else \"root\",\n",
    "            \"pdf_hash\": self.pdf_hash,\n",
    "            \"level_in_doc\": level  # Original document level\n",
    "        })\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def _extract_provenance(self, item) -> Tuple[Optional[int], Optional[Dict]]:\n",
    "        \"\"\"Extract page and bounding box from provenance.\"\"\"\n",
    "        page, bbox = None, None\n",
    "        if hasattr(item, 'prov') and item.prov:\n",
    "            prov = item.prov[0]\n",
    "            page = getattr(prov, 'page_no', None)\n",
    "            if hasattr(prov, 'bbox'):\n",
    "                b = prov.bbox\n",
    "                bbox = {\n",
    "                    \"x0\": float(b.l), \n",
    "                    \"y0\": float(b.t), \n",
    "                    \"x1\": float(b.r), \n",
    "                    \"y1\": float(b.b),\n",
    "                    \"width\": float(b.r - b.l),\n",
    "                    \"height\": float(b.t - b.b)\n",
    "                }\n",
    "        return page, bbox\n",
    "    \n",
    "    def _extract_figure(self, item: PictureItem, doc, block_id: int, \n",
    "                       page: int, bbox: Dict) -> Dict:\n",
    "        \"\"\"Extract figure block.\"\"\"\n",
    "        return {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": \"figure\",\n",
    "            \"text\": \"[Figure]\",\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"caption\": item.caption_text(doc=doc),\n",
    "            \"figure_id\": str(item.self_ref),\n",
    "            \"has_caption\": bool(item.caption_text(doc=doc))\n",
    "        }\n",
    "    \n",
    "    def _extract_table(self, item: TableItem, doc, block_id: int,\n",
    "                      page: int, bbox: Dict) -> Dict:\n",
    "        \"\"\"Extract table block.\"\"\"\n",
    "        markdown = item.export_to_markdown(doc=doc)\n",
    "        return {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": \"table\",\n",
    "            \"text\": markdown,\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"caption\": item.caption_text(doc=doc),\n",
    "            \"table_id\": str(item.self_ref),\n",
    "            \"has_caption\": bool(item.caption_text(doc=doc)),\n",
    "            \"num_rows\": markdown.count('\\n') if markdown else 0,\n",
    "            \"num_cols\": len(markdown.split('\\n')[0].split('|')) - 2 if markdown and '\\n' in markdown else 0\n",
    "        }\n",
    "    \n",
    "    def _extract_text(self, item: TextItem, doc, block_id: int,\n",
    "                     page: int, bbox: Dict, level: int) -> Dict:\n",
    "        \"\"\"Extract text-based block (heading, paragraph, code, etc).\"\"\"\n",
    "        \n",
    "        # Classify type\n",
    "        label = str(item.label).lower() if hasattr(item, 'label') else ''\n",
    "        text = item.text or \"\"\n",
    "        \n",
    "        if 'section' in label or 'title' in label:\n",
    "            item_type = 'heading'\n",
    "            self._update_section_stack(text, level)\n",
    "        elif 'code' in label:\n",
    "            item_type = 'code'\n",
    "        elif 'formula' in label or 'equation' in label:\n",
    "            item_type = 'equation'\n",
    "        elif 'list' in label or text.strip().startswith(('‚Ä¢', '-', '*', '1.', '2.')):\n",
    "            item_type = 'list'\n",
    "        else:\n",
    "            item_type = 'paragraph'\n",
    "        \n",
    "        block = {\n",
    "            \"block_id\": block_id,\n",
    "            \"type\": item_type,\n",
    "            \"text\": text,\n",
    "            \"page\": page,\n",
    "            \"bbox\": bbox,\n",
    "            \"char_count\": len(text),\n",
    "            \"word_count\": len(text.split())\n",
    "        }\n",
    "        \n",
    "        # Type-specific fields\n",
    "        if item_type == \"heading\":\n",
    "            block[\"heading_level\"] = level\n",
    "        elif item_type == \"code\":\n",
    "            block[\"code_language\"] = getattr(item, 'code_language', 'unknown')\n",
    "        elif item_type == \"equation\":\n",
    "            block[\"latex\"] = getattr(item, 'latex', None)\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def _update_section_stack(self, text: str, level: int):\n",
    "        \"\"\"Update section hierarchy stack.\"\"\"\n",
    "        if not text or len(text) < 3:\n",
    "            return\n",
    "        \n",
    "        # Adjust stack based on level\n",
    "        if level <= len(self.section_stack):\n",
    "            self.section_stack = self.section_stack[:level-1]\n",
    "        \n",
    "        self.section_stack.append(text[:100])  # Truncate long headings\n",
    "    \n",
    "    def _augment_captions(self):\n",
    "        \"\"\"Enhanced caption augmentation with multiple strategies.\"\"\"\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if block['type'] not in ['figure', 'table']:\n",
    "                continue\n",
    "            if block.get('caption'):\n",
    "                continue\n",
    "            \n",
    "            caption = None\n",
    "            \n",
    "            # Strategy 1: Look backward for heading on same page\n",
    "            for j in range(i-1, max(i-30, -1), -1):\n",
    "                prev = self.blocks[j]\n",
    "                if prev['page'] != block['page']:\n",
    "                    break\n",
    "                if prev['type'] == 'heading' and prev.get('heading_level', 99) <= 3:\n",
    "                    caption = prev['text']\n",
    "                    break\n",
    "            \n",
    "            # Strategy 2: Look forward for paragraph starting with \"Figure\" or \"Table\"\n",
    "            if not caption:\n",
    "                for j in range(i+1, min(i+5, len(self.blocks))):\n",
    "                    next_block = self.blocks[j]\n",
    "                    if next_block['page'] != block['page']:\n",
    "                        break\n",
    "                    text = next_block.get('text', '').strip()\n",
    "                    if text.startswith(('Figure', 'Table', 'Fig.')):\n",
    "                        caption = text.split('\\n')[0]  # First line only\n",
    "                        break\n",
    "            \n",
    "            # Strategy 3: Use section path as fallback\n",
    "            if not caption:\n",
    "                caption = block['section_path']\n",
    "            \n",
    "            block['caption'] = caption\n",
    "            block['caption_source'] = 'augmented'\n",
    "            block['has_caption'] = True\n",
    "    \n",
    "    def _validate_blocks(self):\n",
    "        \"\"\"Validate and clean blocks.\"\"\"\n",
    "        valid_blocks = []\n",
    "        for block in self.blocks:\n",
    "            # Skip empty text blocks\n",
    "            if block['type'] in ['paragraph', 'heading'] and not block.get('text', '').strip():\n",
    "                continue\n",
    "            \n",
    "            # Ensure required fields\n",
    "            if 'block_id' not in block or 'type' not in block:\n",
    "                continue\n",
    "            \n",
    "            valid_blocks.append(block)\n",
    "        \n",
    "        self.blocks = valid_blocks\n",
    "    \n",
    "    def _save_output(self):\n",
    "        \"\"\"Save blocks to JSONL.\"\"\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_file = self.output_dir / \"docling_blocks.jsonl\"\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for block in self.blocks:\n",
    "                f.write(json.dumps(block, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        print(f\"\\n‚úì Saved: {output_file}\")\n",
    "    \n",
    "    def _print_stats(self):\n",
    "        \"\"\"Print comprehensive statistics.\"\"\"\n",
    "        fig_tab = [b for b in self.blocks if b['type'] in ['figure', 'table']]\n",
    "        with_caps = [b for b in fig_tab if b.get('has_caption')]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"EXTRACTION STATISTICS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total blocks: {len(self.blocks)}\")\n",
    "        print(f\"\\nBlock types:\")\n",
    "        for block_type, count in sorted(self.stats.items()):\n",
    "            print(f\"  {block_type:12s}: {count:4d}\")\n",
    "        print(f\"\\nFigures/Tables: {len(fig_tab)}\")\n",
    "        print(f\"With captions:  {len(with_caps)} ({len(with_caps)/len(fig_tab)*100:.1f}%)\")\n",
    "        print(f\"\\nPages covered: {len(set(b['page'] for b in self.blocks if b.get('page')))}\")\n",
    "        print(f\"\\nREADY FOR PHASE B: CHUNKING EXPERIMENTS\")\n",
    "        print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bcb0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 15:36:10,824 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-21 15:36:10,869 - INFO - Going to convert document batch...\n",
      "2025-10-21 15:36:10,869 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-21 15:36:10,874 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 15:36:10,876 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-21 15:36:10,881 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-21 15:36:10,883 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE A: PARSE & NORMALIZE (ENHANCED)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 15:36:11,357 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-10-21 15:36:11,376 - INFO - Accelerator device: 'mps'\n",
      "2025-10-21 15:36:12,609 - INFO - Accelerator device: 'mps'\n",
      "2025-10-21 15:36:13,406 - INFO - Processing document fintbx_ex.pdf\n",
      "2025-10-21 15:36:39,226 - INFO - Finished converting document fintbx_ex.pdf in 28.40 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved: ../data/final/docling_blocks.jsonl\n",
      "\n",
      "============================================================\n",
      "EXTRACTION STATISTICS\n",
      "============================================================\n",
      "Total blocks: 907\n",
      "\n",
      "Block types:\n",
      "  code        :   40\n",
      "  equation    :   15\n",
      "  figure      :    8\n",
      "  heading     :   54\n",
      "  list        :   35\n",
      "  paragraph   :  742\n",
      "  table       :   13\n",
      "\n",
      "Figures/Tables: 21\n",
      "With captions:  21 (100.0%)\n",
      "\n",
      "Pages covered: 28\n",
      "\n",
      "READY FOR PHASE B: CHUNKING EXPERIMENTS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% RUN ENHANCED PARSER\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = Path(\"../data/fintbx_ex.pdf\")\n",
    "    output_dir = Path(\"../data/final\")\n",
    "    \n",
    "    parser = PhaseAParser(\n",
    "        pdf_path=pdf_path,\n",
    "        output_dir=output_dir,\n",
    "        pdf_hash=\"sample_hash\"  # Replace with actual hash\n",
    "    )\n",
    "    \n",
    "    blocks = parser.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c4d99",
   "metadata": {},
   "source": [
    "## Stage 2: Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21051ae0",
   "metadata": {},
   "source": [
    "### Cleanup of Parsed Documents before Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb10e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "INPUT_PATH = '../data/final/docling_blocks.jsonl'\n",
    "OUTPUT_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "REPORT_PATH = '../data/final/cleanup_report.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a55b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total blocks: 907\n",
      "\n",
      "üîç REDUNDANCY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Blocks by Type:\n",
      "  heading        :    54\n",
      "  figure         :     8\n",
      "  paragraph      :   742\n",
      "  table          :    13\n",
      "  code           :    40\n",
      "  equation       :    15\n",
      "  list           :    35\n",
      "\n",
      "üóëÔ∏è  Redundant Content (Categories may overlap):\n",
      "  Single dots (.):        458\n",
      "  Single characters:      458\n",
      "  Page numbers only:      4\n",
      "  Augmented figures:      7 (info only)\n",
      "  Very small text (<3ch): 464\n",
      "\n",
      "üìä Overlap Analysis:\n",
      "  Dots that are also single chars: 458\n",
      "  Dots that are also small text:  458\n",
      "\n",
      "üìâ ACTUAL Unique Redundant Blocks: 464 (51.2%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: CORRECTED Data Analysis - Identify Redundancies\n",
    "def analyze_redundancies(jsonl_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze the JSONL file to identify redundant/useless patterns.\n",
    "    Uses SETS to avoid double-counting blocks.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                blocks.append(json.loads(line))\n",
    "    \n",
    "    print(f\"üìä Total blocks: {len(blocks)}\\n\")\n",
    "    \n",
    "    # Use SETS to track unique block_ids (avoid double counting)\n",
    "    stats = {\n",
    "        'total_blocks': len(blocks),\n",
    "        'by_type': Counter(),\n",
    "        'single_dot': set(),           # Changed to set\n",
    "        'single_char': set(),          # Changed to set\n",
    "        'page_numbers_only': set(),    # Changed to set\n",
    "        'augmented_figures': set(),    # Changed to set\n",
    "        'very_small_text': set(),      # Changed to set\n",
    "        'redundant_blocks': set()      # NEW: Union of all redundant blocks\n",
    "    }\n",
    "    \n",
    "    for block in blocks:\n",
    "        block_type = block.get('type', 'unknown')\n",
    "        block_id = block.get('block_id')\n",
    "        stats['by_type'][block_type] += 1\n",
    "        \n",
    "        text = block.get('text', '').strip()\n",
    "        char_count = block.get('char_count', 0)\n",
    "        word_count = block.get('word_count', 0)\n",
    "        \n",
    "        # Single dot paragraphs\n",
    "        if text == '.' and block_type == 'paragraph':\n",
    "            stats['single_dot'].add(block_id)\n",
    "            stats['redundant_blocks'].add(block_id)\n",
    "        \n",
    "        # Single character blocks (excluding meaningful ones)\n",
    "        if char_count == 1 and text not in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']:\n",
    "            stats['single_char'].add(block_id)\n",
    "            stats['redundant_blocks'].add(block_id)\n",
    "        \n",
    "        # Page numbers only (single digit/number paragraphs)\n",
    "        if block_type == 'paragraph' and text.isdigit() and len(text) <= 2:\n",
    "            stats['page_numbers_only'].add(block_id)\n",
    "            stats['redundant_blocks'].add(block_id)\n",
    "        \n",
    "        # Augmented figure captions\n",
    "        if block_type == 'figure' and block.get('caption_source') == 'augmented':\n",
    "            stats['augmented_figures'].add(block_id)\n",
    "            # Note: figures might be kept, so don't add to redundant_blocks\n",
    "        \n",
    "        # Very small text (likely parsing artifacts)\n",
    "        if block_type == 'paragraph' and char_count < 3 and text != '':\n",
    "            stats['very_small_text'].add(block_id)\n",
    "            stats['redundant_blocks'].add(block_id)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"üîç REDUNDANCY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nBlocks by Type:\")\n",
    "    for btype, count in stats['by_type'].items():\n",
    "        print(f\"  {btype:15s}: {count:5d}\")\n",
    "    \n",
    "    print(f\"\\nüóëÔ∏è  Redundant Content (Categories may overlap):\")\n",
    "    print(f\"  Single dots (.):        {len(stats['single_dot'])}\")\n",
    "    print(f\"  Single characters:      {len(stats['single_char'])}\")\n",
    "    print(f\"  Page numbers only:      {len(stats['page_numbers_only'])}\")\n",
    "    print(f\"  Augmented figures:      {len(stats['augmented_figures'])} (info only)\")\n",
    "    print(f\"  Very small text (<3ch): {len(stats['very_small_text'])}\")\n",
    "    \n",
    "    # Show overlap analysis\n",
    "    print(f\"\\nüìä Overlap Analysis:\")\n",
    "    dots_and_chars = stats['single_dot'] & stats['single_char']\n",
    "    print(f\"  Dots that are also single chars: {len(dots_and_chars)}\")\n",
    "    \n",
    "    dots_and_small = stats['single_dot'] & stats['very_small_text']\n",
    "    print(f\"  Dots that are also small text:  {len(dots_and_small)}\")\n",
    "    \n",
    "    # ACTUAL unique redundant blocks\n",
    "    total_redundant = len(stats['redundant_blocks'])\n",
    "    \n",
    "    print(f\"\\nüìâ ACTUAL Unique Redundant Blocks: {total_redundant} ({total_redundant/len(blocks)*100:.1f}%)\")\n",
    "    \n",
    "    # Convert sets back to lists for JSON serialization\n",
    "    stats['single_dot'] = list(stats['single_dot'])\n",
    "    stats['single_char'] = list(stats['single_char'])\n",
    "    stats['page_numbers_only'] = list(stats['page_numbers_only'])\n",
    "    stats['augmented_figures'] = list(stats['augmented_figures'])\n",
    "    stats['very_small_text'] = list(stats['very_small_text'])\n",
    "    stats['redundant_blocks'] = list(stats['redundant_blocks'])\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run corrected analysis\n",
    "stats = analyze_redundancies(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7440262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Cleanup Functions\n",
    "def should_keep_block(block: Dict[str, Any], strict_mode: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a block should be kept or removed.\n",
    "    \n",
    "    Args:\n",
    "        block: Block dictionary\n",
    "        strict_mode: If True, apply more aggressive filtering\n",
    "    \n",
    "    Returns:\n",
    "        True if block should be kept, False otherwise\n",
    "    \"\"\"\n",
    "    block_type = block.get('type', 'unknown')\n",
    "    text = block.get('text', '').strip()\n",
    "    char_count = block.get('char_count', 0)\n",
    "    word_count = block.get('word_count', 0)\n",
    "    \n",
    "    # RULE 1: Remove single-dot paragraphs\n",
    "    if text == '.' and block_type == 'paragraph':\n",
    "        return False\n",
    "    \n",
    "    # RULE 2: Remove very small meaningless text (< 3 chars, excluding numbers)\n",
    "    if block_type == 'paragraph' and char_count < 3:\n",
    "        # Keep if it's a number or meaningful\n",
    "        if not text.isdigit() and text not in ['-', '‚Äì', '‚Äî', '*', '‚Ä¢']:\n",
    "            return False\n",
    "    \n",
    "    # RULE 3: Remove standalone page number paragraphs (optional in strict mode)\n",
    "    if strict_mode and block_type == 'paragraph' and text.isdigit() and len(text) <= 2:\n",
    "        return False\n",
    "    \n",
    "    # RULE 4: Remove figures with only augmented captions (optional in strict mode)\n",
    "    if strict_mode and block_type == 'figure':\n",
    "        if block.get('caption_source') == 'augmented' and block.get('text') == '[Figure]':\n",
    "            return False\n",
    "    \n",
    "    # RULE 5: Remove blocks with no meaningful content\n",
    "    if text in ['', ' ', '\\n', '\\t']:\n",
    "        return False\n",
    "    \n",
    "    # RULE 6: Remove excessive ellipsis/dots patterns\n",
    "    if text.count('.') > 10 and len(text.replace('.', '').strip()) < 5:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_block_metadata(block: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Clean and optimize block metadata.\n",
    "    \"\"\"\n",
    "    cleaned = block.copy()\n",
    "    \n",
    "    # Round bbox coordinates to 2 decimal places (reduce precision bloat)\n",
    "    if 'bbox' in cleaned:\n",
    "        bbox = cleaned['bbox']\n",
    "        for key in ['x0', 'y0', 'x1', 'y1', 'width', 'height']:\n",
    "            if key in bbox and isinstance(bbox[key], (int, float)):\n",
    "                bbox[key] = round(bbox[key], 2)\n",
    "        cleaned['bbox'] = bbox\n",
    "    \n",
    "    # Remove sample_hash if it's just a placeholder\n",
    "    if cleaned.get('pdf_hash') == 'sample_hash':\n",
    "        cleaned.pop('pdf_hash', None)\n",
    "    \n",
    "    # Remove redundant caption_source for non-augmented captions\n",
    "    if cleaned.get('caption_source') == 'augmented' and 'figure_id' in cleaned:\n",
    "        # Keep it for tracking, but mark it\n",
    "        pass\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c834fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loaded 907 blocks\n",
      "üîß Strict mode: False\n",
      "üßπ Clean metadata: True\n",
      "\n",
      "‚úÖ CLEANUP COMPLETE\n",
      "============================================================\n",
      "Original blocks:  907\n",
      "Cleaned blocks:   431\n",
      "Removed blocks:   476 (52.5%)\n",
      "\n",
      "Removed by type:\n",
      "  paragraph      : 460\n",
      "  equation       : 15\n",
      "  table          : 1\n",
      "\n",
      "üíæ Saved to: ../data/final/docling_blocks_cleaned.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Execute Cleanup\n",
    "def cleanup_docling_blocks(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    strict_mode: bool = False,\n",
    "    clean_metadata: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Clean up the Docling-parsed JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Input JSONL file path\n",
    "        output_path: Output cleaned JSONL file path\n",
    "        strict_mode: Apply aggressive filtering\n",
    "        clean_metadata: Clean up metadata fields\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cleanup statistics\n",
    "    \"\"\"\n",
    "    # Load blocks\n",
    "    blocks = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                blocks.append(json.loads(line))\n",
    "    \n",
    "    print(f\"üìÇ Loaded {len(blocks)} blocks\")\n",
    "    print(f\"üîß Strict mode: {strict_mode}\")\n",
    "    print(f\"üßπ Clean metadata: {clean_metadata}\\n\")\n",
    "    \n",
    "    # Filter blocks\n",
    "    cleaned_blocks = []\n",
    "    removed_blocks = []\n",
    "    \n",
    "    for block in blocks:\n",
    "        if should_keep_block(block, strict_mode=strict_mode):\n",
    "            if clean_metadata:\n",
    "                block = clean_block_metadata(block)\n",
    "            cleaned_blocks.append(block)\n",
    "        else:\n",
    "            removed_blocks.append(block)\n",
    "    \n",
    "    # Reassign block_ids sequentially\n",
    "    for i, block in enumerate(cleaned_blocks):\n",
    "        block['block_id'] = i\n",
    "    \n",
    "    # Save cleaned blocks\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for block in cleaned_blocks:\n",
    "            json.dump(block, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {\n",
    "        'original_count': len(blocks),\n",
    "        'cleaned_count': len(cleaned_blocks),\n",
    "        'removed_count': len(removed_blocks),\n",
    "        'reduction_pct': (len(removed_blocks) / len(blocks)) * 100,\n",
    "        'removed_types': Counter(b.get('type') for b in removed_blocks),\n",
    "        'removed_sample': removed_blocks[:10]  # First 10 removed blocks\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ CLEANUP COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Original blocks:  {stats['original_count']}\")\n",
    "    print(f\"Cleaned blocks:   {stats['cleaned_count']}\")\n",
    "    print(f\"Removed blocks:   {stats['removed_count']} ({stats['reduction_pct']:.1f}%)\")\n",
    "    print(f\"\\nRemoved by type:\")\n",
    "    for btype, count in stats['removed_types'].items():\n",
    "        print(f\"  {btype:15s}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüíæ Saved to: {output_path}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run cleanup\n",
    "cleanup_stats = cleanup_docling_blocks(\n",
    "    INPUT_PATH,\n",
    "    OUTPUT_PATH,\n",
    "    strict_mode=False,  # Set to True for aggressive cleanup\n",
    "    clean_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6ed8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Report saved to: ../data/final/cleanup_report.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Save Cleanup Report\n",
    "report = {\n",
    "    'input_file': INPUT_PATH,\n",
    "    'output_file': OUTPUT_PATH,\n",
    "    'analysis': stats,\n",
    "    'cleanup': cleanup_stats,\n",
    "    'rules_applied': [\n",
    "        \"Remove single-dot paragraphs\",\n",
    "        \"Remove very small meaningless text (<3 chars)\",\n",
    "        \"Remove excessive ellipsis patterns\",\n",
    "        \"Round bbox coordinates to 2 decimals\",\n",
    "        \"Remove placeholder pdf_hash\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(REPORT_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"üìã Report saved to: {REPORT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd38b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0,
           1
          ]
         },
         "labels": [
          "heading",
          "figure",
          "paragraph",
          "table",
          "code",
          "equation",
          "list"
         ],
         "name": "Before",
         "type": "pie",
         "values": [
          54,
          8,
          742,
          13,
          40,
          15,
          35
         ]
        },
        {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "labels": [
          "heading",
          "figure",
          "paragraph",
          "table",
          "code",
          "list"
         ],
         "name": "After",
         "type": "pie",
         "values": [
          54,
          8,
          282,
          12,
          40,
          35
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Before Cleanup",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "After Cleanup",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Document Blocks: Before vs After Cleanup"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 6: Visualize Before/After\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_cleanup(before_stats, after_stats):\n",
    "    \"\"\"Visualize the cleanup results\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Before Cleanup', 'After Cleanup'),\n",
    "        specs=[[{'type': 'pie'}, {'type': 'pie'}]]\n",
    "    )\n",
    "    \n",
    "    # Before cleanup\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(before_stats['by_type'].keys()),\n",
    "            values=list(before_stats['by_type'].values()),\n",
    "            name=\"Before\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # After cleanup (calculate from cleaned blocks)\n",
    "    # Load cleaned file\n",
    "    cleaned_blocks = []\n",
    "    with open(OUTPUT_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                cleaned_blocks.append(json.loads(line))\n",
    "    \n",
    "    after_types = Counter(b.get('type') for b in cleaned_blocks)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(after_types.keys()),\n",
    "            values=list(after_types.values()),\n",
    "            name=\"After\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Document Blocks: Before vs After Cleanup\",\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "visualize_cleanup(stats, cleanup_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b67568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóëÔ∏è  SAMPLE OF REMOVED BLOCKS\n",
      "============================================================\n",
      "\n",
      "1. Block ID: 37\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "2. Block ID: 38\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "3. Block ID: 39\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "4. Block ID: 40\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "5. Block ID: 41\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "6. Block ID: 42\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "7. Block ID: 43\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "8. Block ID: 44\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "9. Block ID: 45\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n",
      "\n",
      "10. Block ID: 46\n",
      "   Type: paragraph\n",
      "   Text: '.'\n",
      "   Char count: 1\n",
      "   Page: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Sample Removed Content\n",
    "def show_removed_samples(cleanup_stats, n=10):\n",
    "    \"\"\"Display sample of removed blocks for verification\"\"\"\n",
    "    \n",
    "    print(\"\\nüóëÔ∏è  SAMPLE OF REMOVED BLOCKS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, block in enumerate(cleanup_stats['removed_sample'][:n], 1):\n",
    "        print(f\"\\n{i}. Block ID: {block.get('block_id')}\")\n",
    "        print(f\"   Type: {block.get('type')}\")\n",
    "        print(f\"   Text: '{block.get('text')}'\")\n",
    "        print(f\"   Char count: {block.get('char_count')}\")\n",
    "        print(f\"   Page: {block.get('page')}\")\n",
    "\n",
    "show_removed_samples(cleanup_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfb4f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì VALIDATION RESULTS\n",
      "============================================================\n",
      "‚úì Block IDs sequential: 0 to 430\n",
      "‚úì All blocks have required fields\n",
      "‚úì Preserved 49 unique sections\n",
      "‚úì Content types: {'heading': 54, 'figure': 8, 'paragraph': 282, 'table': 12, 'code': 40, 'list': 35}\n",
      "\n",
      "‚úÖ Validation passed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Validate Cleaned Data\n",
    "def validate_cleaned_data(cleaned_path: str):\n",
    "    \"\"\"Ensure cleaned data maintains document integrity\"\"\"\n",
    "    \n",
    "    with open(cleaned_path, 'r') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    print(\"\\n‚úì VALIDATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check sequential block_ids\n",
    "    ids = [b['block_id'] for b in blocks]\n",
    "    assert ids == list(range(len(ids))), \"Block IDs not sequential!\"\n",
    "    print(f\"‚úì Block IDs sequential: 0 to {len(ids)-1}\")\n",
    "    \n",
    "    # Check all blocks have required fields\n",
    "    required_fields = ['block_id', 'type', 'text', 'page']\n",
    "    for i, block in enumerate(blocks):\n",
    "        for field in required_fields:\n",
    "            assert field in block, f\"Block {i} missing {field}\"\n",
    "    print(f\"‚úì All blocks have required fields\")\n",
    "    \n",
    "    # Check section paths preserved\n",
    "    sections = set(b.get('section_path') for b in blocks if 'section_path' in b)\n",
    "    print(f\"‚úì Preserved {len(sections)} unique sections\")\n",
    "    \n",
    "    # Check content types\n",
    "    types = Counter(b.get('type') for b in blocks)\n",
    "    print(f\"‚úì Content types: {dict(types)}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Validation passed!\")\n",
    "\n",
    "validate_cleaned_data(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d886a",
   "metadata": {},
   "source": [
    "### Method 1: Section-based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cdc4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6975cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path configuration\n",
    "PARSED_RESULT_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/section_based_chunks.jsonl'\n",
    "\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10c90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Chunk Data Structure\n",
    "@dataclass\n",
    "class SectionChunk:\n",
    "    \"\"\"Represents a section-based chunk with metadata\"\"\"\n",
    "    chunk_id: int\n",
    "    section_path: str\n",
    "    section_title: str\n",
    "    content: str\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad06961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_section(\n",
    "    jsonl_path: str,\n",
    "    max_chunk_size: int = None,\n",
    "    include_section_title: bool = True,\n",
    "    skip_types: List[str] = ['figure']\n",
    ") -> List[SectionChunk]:\n",
    "    \"\"\"\n",
    "    Chunk document by section_path, preserving semantic coherence.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to Docling-parsed JSONL file\n",
    "        max_chunk_size: Optional max size; if exceeded, section is split\n",
    "        include_section_title: Whether to add section title as header\n",
    "        skip_types: Block types to skip (e.g., figures)\n",
    "    \n",
    "    Returns:\n",
    "        List of SectionChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load and group blocks by section\n",
    "    sections = defaultdict(list)\n",
    "    \n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                block = json.loads(line)\n",
    "                section_path = block.get('section_path', 'Unknown Section')\n",
    "                sections[section_path].append(block)\n",
    "    \n",
    "    print(f\"üìö Found {len(sections)} unique sections\")\n",
    "    \n",
    "    # Step 2: Process each section\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    for section_path, blocks in sections.items():\n",
    "        # Sort blocks by page and block_id to maintain order\n",
    "        blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "        \n",
    "        # Extract section title (from first heading)\n",
    "        section_title = section_path  # Default to section path\n",
    "        heading_blocks = [b for b in blocks if b.get('type') == 'heading']\n",
    "        if heading_blocks:\n",
    "            section_title = heading_blocks[0].get('text', section_path)\n",
    "        \n",
    "        # Accumulate content for this section\n",
    "        section_content = []\n",
    "        section_metadata = {\n",
    "            'pages': set(),\n",
    "            'block_ids': [],\n",
    "            'block_types': set(),\n",
    "            'num_blocks': 0,\n",
    "            'has_tables': False,\n",
    "            'has_figures': False\n",
    "        }\n",
    "        \n",
    "        for block in blocks:\n",
    "            block_type = block.get('type', 'unknown')\n",
    "            \n",
    "            # Skip certain types\n",
    "            if block_type in skip_types:\n",
    "                section_metadata['has_figures'] = True\n",
    "                continue\n",
    "            \n",
    "            # Extract text based on block type\n",
    "            block_text = block.get('text', '')\n",
    "            \n",
    "            if block_type == 'heading':\n",
    "                # Skip if it's the main section heading (we'll add it separately)\n",
    "                if block.get('heading_level') == 1:\n",
    "                    continue\n",
    "                # Sub-headings get formatted\n",
    "                section_content.append(f\"\\n## {block_text}\\n\")\n",
    "                \n",
    "            elif block_type == 'paragraph':\n",
    "                section_content.append(block_text)\n",
    "                \n",
    "            elif block_type == 'table':\n",
    "                section_metadata['has_tables'] = True\n",
    "                caption = block.get('caption', 'Table')\n",
    "                section_content.append(f\"\\n### {caption}\\n```\\n{block_text}\\n```\\n\")\n",
    "            \n",
    "            else:\n",
    "                # Handle other types\n",
    "                section_content.append(block_text)\n",
    "            \n",
    "            # Update metadata\n",
    "            section_metadata['pages'].add(block.get('page', 0))\n",
    "            section_metadata['block_ids'].append(block.get('block_id', 0))\n",
    "            section_metadata['block_types'].add(block_type)\n",
    "            section_metadata['num_blocks'] += 1\n",
    "        \n",
    "        # Combine all content\n",
    "        combined_content = '\\n\\n'.join(section_content).strip()\n",
    "        \n",
    "        if not combined_content:\n",
    "            continue  # Skip empty sections\n",
    "        \n",
    "        # Add section title if requested\n",
    "        if include_section_title and section_title:\n",
    "            full_content = f\"# {section_title}\\n\\n{combined_content}\"\n",
    "        else:\n",
    "            full_content = combined_content\n",
    "        \n",
    "        # Convert sets to lists for JSON serialization\n",
    "        metadata_dict = {\n",
    "            'pages': sorted(list(section_metadata['pages'])),\n",
    "            'block_ids': section_metadata['block_ids'],\n",
    "            'block_types': list(section_metadata['block_types']),\n",
    "            'num_blocks': section_metadata['num_blocks'],\n",
    "            'has_tables': section_metadata['has_tables'],\n",
    "            'has_figures': section_metadata['has_figures'],\n",
    "            'char_count': len(full_content),\n",
    "            'word_count': len(full_content.split()),\n",
    "            'source': 'fintbx.pdf',\n",
    "            'chunking_method': 'section_based'\n",
    "        }\n",
    "        \n",
    "        # Check if we need to split (if max_chunk_size is set)\n",
    "        if max_chunk_size and len(full_content) > max_chunk_size:\n",
    "            # Split into smaller chunks while preserving section context\n",
    "            sub_chunks = split_large_section(\n",
    "                full_content, \n",
    "                section_path, \n",
    "                section_title,\n",
    "                max_chunk_size,\n",
    "                metadata_dict\n",
    "            )\n",
    "            \n",
    "            for sub_chunk in sub_chunks:\n",
    "                chunks.append(SectionChunk(\n",
    "                    chunk_id=chunk_id,\n",
    "                    section_path=section_path,\n",
    "                    section_title=section_title,\n",
    "                    content=sub_chunk['content'],\n",
    "                    metadata=sub_chunk['metadata']\n",
    "                ))\n",
    "                chunk_id += 1\n",
    "        else:\n",
    "            # Create single chunk for this section\n",
    "            chunks.append(SectionChunk(\n",
    "                chunk_id=chunk_id,\n",
    "                section_path=section_path,\n",
    "                section_title=section_title,\n",
    "                content=full_content,\n",
    "                metadata=metadata_dict\n",
    "            ))\n",
    "            chunk_id += 1\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def split_large_section(\n",
    "    content: str,\n",
    "    section_path: str,\n",
    "    section_title: str,\n",
    "    max_size: int,\n",
    "    base_metadata: Dict\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Split large sections while maintaining context\"\"\"\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_size,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    split_texts = splitter.split_text(content)\n",
    "    \n",
    "    sub_chunks = []\n",
    "    for i, text in enumerate(split_texts):\n",
    "        metadata = base_metadata.copy()\n",
    "        metadata.update({\n",
    "            'is_split': True,\n",
    "            'split_index': i,\n",
    "            'total_splits': len(split_texts),\n",
    "            'char_count': len(text),\n",
    "            'word_count': len(text.split())\n",
    "        })\n",
    "        \n",
    "        sub_chunks.append({\n",
    "            'content': text,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    \n",
    "    return sub_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940211a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Section-Based Chunking...\n",
      "üìÇ Input: ../data/final/docling_blocks_cleaned.jsonl\n",
      "üìù Output: ../data/chunks/section_based_chunks.jsonl\n",
      "\n",
      "üìö Found 49 unique sections\n",
      "\n",
      "‚úÖ Created 47 section-based chunks\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Section-Based Chunking...\")\n",
    "print(f\"üìÇ Input: {PARSED_RESULT_PATH}\")\n",
    "print(f\"üìù Output: {OUTPUT_PATH}\\n\")\n",
    "\n",
    "# Run chunking\n",
    "chunks = chunk_by_section(\n",
    "    jsonl_path=PARSED_RESULT_PATH,\n",
    "    max_chunk_size=None,  # Set to 2000 if you want to limit chunk size\n",
    "    include_section_title=True,\n",
    "    skip_types=['figure']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(chunks)} section-based chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fa4a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CHUNK STATISTICS\n",
      "============================================================\n",
      "Total Chunks: 47\n",
      "Average Characters: 1668\n",
      "Median Characters: 940\n",
      "Min Characters: 19\n",
      "Max Characters: 13267\n",
      "\n",
      "Average Words: 241\n",
      "Chunks with Tables: 10\n",
      "\n",
      "Top 5 Largest Chunks:\n",
      "    chunk_id                                  title  char_count  word_count\n",
      "4          4                       Revision History       13267        1965\n",
      "5          5                   Credit Risk Analysis        8687        1207\n",
      "16        16                       Related Examples        7822         762\n",
      "44        44                         Binomial Model        6324         571\n",
      "9          9  Solving Simultaneous Linear Equations        3493         628\n"
     ]
    }
   ],
   "source": [
    "def analyze_chunks(chunks: List[SectionChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate statistics about the chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'section': chunk.section_path,\n",
    "            'title': chunk.section_title[:50] + '...' if len(chunk.section_title) > 50 else chunk.section_title,\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'pages': ', '.join(map(str, chunk.metadata.get('pages', []))),\n",
    "            'num_blocks': chunk.metadata.get('num_blocks', 0),\n",
    "            'has_tables': chunk.metadata.get('has_tables', False),\n",
    "            'block_types': ', '.join(chunk.metadata.get('block_types', []))\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä CHUNK STATISTICS\\n\" + \"=\"*60)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    print(f\"Average Characters: {df['char_count'].mean():.0f}\")\n",
    "    print(f\"Median Characters: {df['char_count'].median():.0f}\")\n",
    "    print(f\"Min Characters: {df['char_count'].min()}\")\n",
    "    print(f\"Max Characters: {df['char_count'].max()}\")\n",
    "    print(f\"\\nAverage Words: {df['word_count'].mean():.0f}\")\n",
    "    print(f\"Chunks with Tables: {df['has_tables'].sum()}\")\n",
    "    print(f\"\\nTop 5 Largest Chunks:\")\n",
    "    print(df.nlargest(5, 'char_count')[['chunk_id', 'title', 'char_count', 'word_count']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "stats_df = analyze_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee4ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE CHUNKS\n",
      "============================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 0: MATLAB¬Æ\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Section Path: MATLAB¬Æ\n",
      "Pages: [1]\n",
      "Size: 19 chars, 5 words\n",
      "\n",
      "Content Preview (first 500 chars):\n",
      "# MATLAB¬Æ\n",
      "\n",
      "R 2025 b\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 1: How to Contact MathWorks\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Section Path: How to Contact MathWorks\n",
      "Pages: [2]\n",
      "Size: 1761 chars, 247 words\n",
      "\n",
      "Content Preview (first 500 chars):\n",
      "# How to Contact MathWorks\n",
      "\n",
      "Latest news:\n",
      "\n",
      "www.mathworks.com\n",
      "\n",
      "Sales and services:\n",
      "\n",
      "www.mathworks.com/sales_and_services\n",
      "\n",
      "User community:\n",
      "\n",
      "www.mathworks.com/matlabcentral\n",
      "\n",
      "Technical support:\n",
      "\n",
      "www.mathworks.com/support/contact_us\n",
      "\n",
      "Phone:\n",
      "\n",
      "508-647-7000\n",
      "\n",
      "The MathWorks, Inc. 1 Apple Hill Drive Natick, MA 01760-2098\n",
      "\n",
      "Financial Toolbox‚Ñ¢ User's Guide\n",
      "\n",
      "¬© COPYRIGHT 1995-2025 by The MathWorks, Inc.\n",
      "\n",
      "The software described in this document is furnished under a license agreement. The software may be used or c...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 2: Trademarks\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Section Path: Trademarks\n",
      "Pages: [2]\n",
      "Size: 253 chars, 35 words\n",
      "\n",
      "Content Preview (first 500 chars):\n",
      "# Trademarks\n",
      "\n",
      "MATLAB and Simulink are registered trademarks of The MathWorks, Inc. See www.mathworks.com/trademarks for a list of additional trademarks. Other product or brand names may be trademarks or registered trademarks of their respective holders.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_chunks(chunks: List[SectionChunk], num_samples: int = 3):\n",
    "    \"\"\"Display sample chunks for inspection\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE CHUNKS\\n\" + \"=\"*60)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:num_samples]):\n",
    "        print(f\"\\n{'‚îÄ'*60}\")\n",
    "        print(f\"CHUNK {chunk.chunk_id}: {chunk.section_title}\")\n",
    "        print(f\"{'‚îÄ'*60}\")\n",
    "        print(f\"Section Path: {chunk.section_path}\")\n",
    "        print(f\"Pages: {chunk.metadata.get('pages', [])}\")\n",
    "        print(f\"Size: {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"\\nContent Preview (first 500 chars):\")\n",
    "        print(chunk.content[:500] + \"...\" if len(chunk.content) > 500 else chunk.content)\n",
    "        print()\n",
    "\n",
    "# Preview first 3 chunks\n",
    "preview_chunks(chunks, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07fa6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved 47 chunks to: ../data/chunks/section_based_chunks.jsonl\n",
      "üìã Saved summary to: ../data/chunks/section_based_chunks_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_chunks(chunks: List[SectionChunk], output_path: str):\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk.to_dict(), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüíæ Saved {len(chunks)} chunks to: {output_path}\")\n",
    "    \n",
    "    # Also save metadata summary\n",
    "    summary_path = output_path.replace('.jsonl', '_summary.json')\n",
    "    summary = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'chunking_method': 'section_based',\n",
    "        'statistics': {\n",
    "            'avg_chars': sum(len(c.content) for c in chunks) / len(chunks),\n",
    "            'min_chars': min(len(c.content) for c in chunks),\n",
    "            'max_chars': max(len(c.content) for c in chunks),\n",
    "            'total_sections': len(set(c.section_path for c in chunks))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìã Saved summary to: {summary_path}\")\n",
    "\n",
    "# Save the chunks\n",
    "save_chunks(chunks, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e218b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "Characters=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 30,
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": {
          "bdata": "EwDhBv0AgwDTM+8h8wQwAY4EpQ1KAv4AgwjgBAwGbACOHg4DbgbdAmsMhwKYAAIEXwJtB5QINQRCAhUENgYoAawD9wBrAVMBuABZAMUAPAIpARcEswYrArQY+geHBw==",
          "dtype": "i2"
         },
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Chunk Size Distribution"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Characters"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "bingroup": "x",
         "hovertemplate": "Words=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 30,
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": {
          "bdata": "BQD3ACMAEgCtB7cE1AAvANYAdAJaACYAcAHOAAABFQD6AoQAEwFxAMEBagAXAJkAVAAUAWQBpQBdAKEAKwEoAJMAIwBCADwAIQARACUAXgAwAKAAFAFiADsCNQFQAQ==",
          "dtype": "i2"
         },
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Word Count Distribution"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Words"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Section=%{x}<br>Number of Chunks=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "MATLAB¬Æ",
          "Gamma",
          "Bond Portfolio Example",
          "Coupon Date Calculations",
          "Yield Conventions",
          "Pricing Functions",
          "Yield Functions",
          "Pricing and Analyzing Equity Derivatives",
          "Introduction",
          "Sensitivity Measures"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AQEBAQEBAQEBAQ==",
          "dtype": "i1"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 10 Sections by Number of Chunks"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Section"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Number of Chunks"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà VISUALIZATION SUMMARY\n",
      "Size range: 19 - 13267 characters\n",
      "Standard deviation: 2523 characters\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_chunks(stats_df: pd.DataFrame):\n",
    "    \"\"\"Create visualizations of chunk statistics\"\"\"\n",
    "    \n",
    "    # 1. Chunk size distribution\n",
    "    fig1 = px.histogram(\n",
    "        stats_df,\n",
    "        x='char_count',\n",
    "        nbins=30,\n",
    "        title='Chunk Size Distribution',\n",
    "        labels={'char_count': 'Characters', 'count': 'Number of Chunks'}\n",
    "    )\n",
    "    fig1.update_layout(showlegend=False)\n",
    "    fig1.show()\n",
    "    \n",
    "    # 2. Word count distribution\n",
    "    fig2 = px.histogram(\n",
    "        stats_df,\n",
    "        x='word_count',\n",
    "        nbins=30,\n",
    "        title='Word Count Distribution',\n",
    "        labels={'word_count': 'Words', 'count': 'Number of Chunks'}\n",
    "    )\n",
    "    fig2.update_layout(showlegend=False)\n",
    "    fig2.show()\n",
    "    \n",
    "    # 3. Chunks per section\n",
    "    section_counts = stats_df['section'].value_counts().head(10)\n",
    "    fig3 = px.bar(\n",
    "        x=section_counts.index,\n",
    "        y=section_counts.values,\n",
    "        title='Top 10 Sections by Number of Chunks',\n",
    "        labels={'x': 'Section', 'y': 'Number of Chunks'}\n",
    "    )\n",
    "    fig3.update_layout(xaxis_tickangle=-45)\n",
    "    fig3.show()\n",
    "    \n",
    "    # 4. Summary metrics\n",
    "    print(\"\\nüìà VISUALIZATION SUMMARY\")\n",
    "    print(f\"Size range: {stats_df['char_count'].min()} - {stats_df['char_count'].max()} characters\")\n",
    "    print(f\"Standard deviation: {stats_df['char_count'].std():.0f} characters\")\n",
    "\n",
    "# Generate visualizations\n",
    "visualize_chunks(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2571c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Exported 47 chunks for embedding: ../data/chunks/section_based_chunks_for_embedding.jsonl\n"
     ]
    }
   ],
   "source": [
    "def export_for_embedding(chunks: List[SectionChunk], output_path: str = None):\n",
    "    \"\"\"\n",
    "    Export chunks in a format ready for embedding generation\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = OUTPUT_PATH.replace('.jsonl', '_for_embedding.jsonl')\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.content,\n",
    "                'metadata': {\n",
    "                    'section': chunk.section_path,\n",
    "                    'title': chunk.section_title,\n",
    "                    'pages': chunk.metadata.get('pages', []),\n",
    "                    'source': 'fintbx_ex.pdf'\n",
    "                }\n",
    "            }\n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"üéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_for_embedding(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1656150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search Results for: 'portfolio'\n",
      "Found 8 matching chunks\n",
      "\n",
      "1. Revision History (Score: 25)\n",
      "   Pages: [3, 4, 5]\n",
      "   Preview: # Revision History\n",
      "\n",
      "October 1995 First printing January 1998 Second printing January 1999 Third printing November 2000 Fourth printing May 2003 Online only June 2004 Online only August 2004 Online onl...\n",
      "\n",
      "2. Multiplying Two Matrices (Score: 11)\n",
      "   Pages: [7]\n",
      "   Preview: # Multiplying Two Matrices\n",
      "\n",
      "Matrix multiplication also follows the rules of matrix algebra. In matrix algebra notation, if A is an m -byn matrix and B is an n -byp matrix\n",
      "\n",
      "then C = A * B is an m -byp ...\n",
      "\n",
      "3. Bond Portfolio Example (Score: 7)\n",
      "   Pages: [20, 21]\n",
      "   Preview: # Bond Portfolio Example\n",
      "\n",
      "Since the previous example included only a single bond, there was no difference between passing an empty matrix or passing a NaN for an optional input argument. For a portfol...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search_chunks(chunks: List[SectionChunk], query: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Simple keyword-based search for testing\n",
    "    (Replace with semantic search after embedding generation)\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Score chunks by keyword matches\n",
    "    scored_chunks = []\n",
    "    for chunk in chunks:\n",
    "        score = chunk.content.lower().count(query_lower)\n",
    "        if score > 0:\n",
    "            scored_chunks.append((chunk, score))\n",
    "    \n",
    "    # Sort by score\n",
    "    scored_chunks.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîç Search Results for: '{query}'\")\n",
    "    print(f\"Found {len(scored_chunks)} matching chunks\\n\")\n",
    "    \n",
    "    for i, (chunk, score) in enumerate(scored_chunks[:top_k], 1):\n",
    "        print(f\"{i}. {chunk.section_title} (Score: {score})\")\n",
    "        print(f\"   Pages: {chunk.metadata.get('pages', [])}\")\n",
    "        print(f\"   Preview: {chunk.content[:200]}...\")\n",
    "        print()\n",
    "\n",
    "# Test search\n",
    "search_chunks(chunks, \"portfolio\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1747b3e",
   "metadata": {},
   "source": [
    "### Method 2: Hierarchical Chunking with Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58eb1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Hierarchical Chunking Setup\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "CLEANED_DATA_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/hierarchical_chunks.jsonl'\n",
    "OUTPUT_EMBEDDING_PATH = '../data/chunks/hierarchical_chunks_for_embedding.jsonl'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6ff308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Hierarchical Chunk Data Structure\n",
    "@dataclass\n",
    "class HierarchicalChunk:\n",
    "    \"\"\"\n",
    "    Represents a chunk with hierarchical context preserved.\n",
    "    \"\"\"\n",
    "    chunk_id: int\n",
    "    content: str\n",
    "    heading_hierarchy: List[str]  # Breadcrumb trail\n",
    "    heading_levels: List[int]     # Level of each heading\n",
    "    section_path: str\n",
    "    context_header: str           # Full breadcrumb string\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    @property\n",
    "    def full_text(self):\n",
    "        \"\"\"Content with context header\"\"\"\n",
    "        if self.context_header:\n",
    "            return f\"{self.context_header}\\n\\n{self.content}\"\n",
    "        return self.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbe40ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_hierarchical(\n",
    "    jsonl_path: str,\n",
    "    max_chunk_size: int = 1500,\n",
    "    include_context_header: bool = True,\n",
    "    context_separator: str = \" > \",\n",
    "    skip_types: List[str] = ['figure']\n",
    ") -> List[HierarchicalChunk]:\n",
    "    \"\"\"\n",
    "    Create hierarchical chunks that preserve document structure.\n",
    "    \n",
    "    Features:\n",
    "    - Maintains heading hierarchy stack\n",
    "    - Adds breadcrumb context to each chunk\n",
    "    - Preserves parent-child relationships\n",
    "    - Respects heading levels (h1, h2, h3, etc.)\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to cleaned JSONL file\n",
    "        max_chunk_size: Maximum chunk size in characters\n",
    "        include_context_header: Whether to prepend context breadcrumbs\n",
    "        context_separator: String to join heading hierarchy\n",
    "        skip_types: Block types to skip\n",
    "    \n",
    "    Returns:\n",
    "        List of HierarchicalChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load blocks\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    # Sort by page and block_id to maintain document order\n",
    "    blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "    \n",
    "    print(f\"üìö Processing {len(blocks)} blocks for hierarchical chunking...\")\n",
    "    print(f\"üìè Max chunk size: {max_chunk_size} characters\")\n",
    "    print(f\"üîó Context separator: '{context_separator}'\\n\")\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    # Heading hierarchy stack\n",
    "    heading_stack = []  # List of {'level': int, 'text': str, 'section': str}\n",
    "    \n",
    "    # Current chunk accumulation\n",
    "    current_chunk_content = []\n",
    "    current_chunk_metadata = {\n",
    "        'pages': set(),\n",
    "        'block_ids': [],\n",
    "        'block_types': set(),\n",
    "        'has_tables': False,\n",
    "        'has_code': False,\n",
    "        'has_equations': False,\n",
    "        'has_lists': False\n",
    "    }\n",
    "    \n",
    "    def create_chunk():\n",
    "        \"\"\"Helper to create and save current chunk\"\"\"\n",
    "        nonlocal chunk_id, current_chunk_content, current_chunk_metadata, heading_stack, chunks\n",
    "        \n",
    "        if not current_chunk_content:\n",
    "            return\n",
    "        \n",
    "        # Combine content\n",
    "        content = '\\n\\n'.join(current_chunk_content).strip()\n",
    "        \n",
    "        if not content:\n",
    "            return\n",
    "        \n",
    "        # Build context header from heading hierarchy\n",
    "        hierarchy_text = [h['text'] for h in heading_stack]\n",
    "        hierarchy_levels = [h['level'] for h in heading_stack]\n",
    "        context_header = \"\"\n",
    "        \n",
    "        if include_context_header and hierarchy_text:\n",
    "            context_header = f\"[Context: {context_separator.join(hierarchy_text)}]\"\n",
    "        \n",
    "        # Get section path\n",
    "        section_path = heading_stack[-1]['section'] if heading_stack else 'Unknown'\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'pages': sorted(list(current_chunk_metadata['pages'])),\n",
    "            'block_ids': current_chunk_metadata['block_ids'].copy(),\n",
    "            'block_types': list(current_chunk_metadata['block_types']),\n",
    "            'num_blocks': len(current_chunk_metadata['block_ids']),\n",
    "            'has_tables': current_chunk_metadata['has_tables'],\n",
    "            'has_code': current_chunk_metadata['has_code'],\n",
    "            'has_equations': current_chunk_metadata['has_equations'],\n",
    "            'has_lists': current_chunk_metadata['has_lists'],\n",
    "            'char_count': len(content),\n",
    "            'word_count': len(content.split()),\n",
    "            'hierarchy_depth': len(heading_stack),\n",
    "            'source': 'fintbx.pdf',\n",
    "            'chunking_method': 'hierarchical'\n",
    "        }\n",
    "        \n",
    "        # Create chunk\n",
    "        chunk = HierarchicalChunk(\n",
    "            chunk_id=chunk_id,\n",
    "            content=content,\n",
    "            heading_hierarchy=hierarchy_text.copy(),\n",
    "            heading_levels=hierarchy_levels.copy(),\n",
    "            section_path=section_path,\n",
    "            context_header=context_header,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        chunks.append(chunk)\n",
    "        chunk_id += 1\n",
    "        \n",
    "        # Reset accumulation\n",
    "        current_chunk_content = []\n",
    "        current_chunk_metadata = {\n",
    "            'pages': set(),\n",
    "            'block_ids': [],\n",
    "            'block_types': set(),\n",
    "            'has_tables': False,\n",
    "            'has_code': False,\n",
    "            'has_equations': False,\n",
    "            'has_lists': False\n",
    "        }\n",
    "        \n",
    "        return current_chunk_content, current_chunk_metadata\n",
    "    \n",
    "    # Process blocks\n",
    "    for block in blocks:\n",
    "        block_type = block.get('type', 'unknown')\n",
    "        block_id = block.get('block_id')\n",
    "        text = block.get('text', '').strip()\n",
    "        \n",
    "        # Handle headings - update hierarchy\n",
    "        if block_type == 'heading':\n",
    "            heading_level = block.get('heading_level', 1)\n",
    "            section_path = block.get('section_path', text)\n",
    "            \n",
    "            # Flush current chunk before changing context\n",
    "            if current_chunk_content:\n",
    "                current_chunk_content, current_chunk_metadata = create_chunk()\n",
    "            \n",
    "            # Pop headings at same or deeper level\n",
    "            heading_stack = [h for h in heading_stack if h['level'] < heading_level]\n",
    "            \n",
    "            # Add new heading to stack\n",
    "            heading_stack.append({\n",
    "                'level': heading_level,\n",
    "                'text': text,\n",
    "                'section': section_path\n",
    "            })\n",
    "            \n",
    "            # Don't add heading text to content (it's in context)\n",
    "            continue\n",
    "        \n",
    "        # Skip certain types\n",
    "        if block_type in skip_types:\n",
    "            continue\n",
    "        \n",
    "        # Prepare block text\n",
    "        block_text = \"\"\n",
    "        \n",
    "        if block_type == 'table':\n",
    "            current_chunk_metadata['has_tables'] = True\n",
    "            caption = block.get('caption', 'Table')\n",
    "            block_text = f\"### {caption}\\n```\\n{text}\\n```\"\n",
    "            \n",
    "        elif block_type == 'code':\n",
    "            current_chunk_metadata['has_code'] = True\n",
    "            block_text = f\"```\\n{text}\\n```\"\n",
    "            \n",
    "        elif block_type == 'equation':\n",
    "            current_chunk_metadata['has_equations'] = True\n",
    "            block_text = f\"$$\\n{text}\\n$$\"\n",
    "            \n",
    "        elif block_type == 'list':\n",
    "            current_chunk_metadata['has_lists'] = True\n",
    "            block_text = text\n",
    "            \n",
    "        elif block_type == 'paragraph':\n",
    "            block_text = text\n",
    "            \n",
    "        else:\n",
    "            block_text = text\n",
    "        \n",
    "        # Check if adding this block would exceed max size\n",
    "        current_size = sum(len(c) for c in current_chunk_content)\n",
    "        if current_size + len(block_text) > max_chunk_size and current_chunk_content:\n",
    "            # Create chunk with current content\n",
    "            current_chunk_content, current_chunk_metadata = create_chunk()\n",
    "        \n",
    "        # Add block to current chunk\n",
    "        current_chunk_content.append(block_text)\n",
    "        current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "        current_chunk_metadata['block_ids'].append(block_id)\n",
    "        current_chunk_metadata['block_types'].add(block_type)\n",
    "    \n",
    "    # Create final chunk\n",
    "    create_chunk()\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} hierarchical chunks\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6968df48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Hierarchical Chunking with Context...\n",
      "\n",
      "üìö Processing 431 blocks for hierarchical chunking...\n",
      "üìè Max chunk size: 1500 characters\n",
      "üîó Context separator: ' > '\n",
      "\n",
      "‚úÖ Created 72 hierarchical chunks\n",
      "\n",
      "‚úÖ Hierarchical chunking complete!\n",
      "üìä Total chunks: 72\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Hierarchical Chunking with Context...\\n\")\n",
    "\n",
    "hierarchical_chunks = chunk_hierarchical(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    max_chunk_size=1500,\n",
    "    include_context_header=True,\n",
    "    context_separator=\" > \",\n",
    "    skip_types=['figure']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Hierarchical chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(hierarchical_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc41dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HIERARCHICAL CHUNK STATISTICS\n",
      "======================================================================\n",
      "Total Chunks: 72\n",
      "\n",
      "Size Distribution:\n",
      "  Average Characters: 1078\n",
      "  Median Characters:  734\n",
      "  Min Characters:     8\n",
      "  Max Characters:     8800\n",
      "  Std Dev:            1602\n",
      "\n",
      "Hierarchy Depth Distribution:\n",
      "  Level 1: 72 chunks\n",
      "\n",
      "Content Type Distribution:\n",
      "  Chunks with Tables:    11\n",
      "  Chunks with Code:      24\n",
      "  Chunks with Equations: 0\n",
      "\n",
      "Top 5 Largest Chunks:\n",
      "    chunk_id                          context  char_count  word_count\n",
      "7          7      [Context: Revision History]        8800        1111\n",
      "10        10  [Context: Credit Risk Analysis]        7627        1012\n",
      "34        34      [Context: Related Examples]        7612         730\n",
      "64        64        [Context: Binomial Model]        4391         238\n",
      "31        31             [Context: Annuities]        2199         283\n"
     ]
    }
   ],
   "source": [
    "def analyze_hierarchical_chunks(chunks: List[HierarchicalChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive statistics about hierarchical chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'hierarchy_depth': len(chunk.heading_hierarchy),\n",
    "            'context': chunk.context_header[:80] + '...' if len(chunk.context_header) > 80 else chunk.context_header,\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'pages': ', '.join(map(str, chunk.metadata.get('pages', []))),\n",
    "            'num_blocks': chunk.metadata.get('num_blocks', 0),\n",
    "            'has_tables': chunk.metadata.get('has_tables', False),\n",
    "            'has_code': chunk.metadata.get('has_code', False),\n",
    "            'has_equations': chunk.metadata.get('has_equations', False),\n",
    "            'section_path': chunk.section_path[:50] + '...' if len(chunk.section_path) > 50 else chunk.section_path\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä HIERARCHICAL CHUNK STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    print(f\"\\nSize Distribution:\")\n",
    "    print(f\"  Average Characters: {df['char_count'].mean():.0f}\")\n",
    "    print(f\"  Median Characters:  {df['char_count'].median():.0f}\")\n",
    "    print(f\"  Min Characters:     {df['char_count'].min()}\")\n",
    "    print(f\"  Max Characters:     {df['char_count'].max()}\")\n",
    "    print(f\"  Std Dev:            {df['char_count'].std():.0f}\")\n",
    "    \n",
    "    print(f\"\\nHierarchy Depth Distribution:\")\n",
    "    depth_counts = df['hierarchy_depth'].value_counts().sort_index()\n",
    "    for depth, count in depth_counts.items():\n",
    "        print(f\"  Level {depth}: {count} chunks\")\n",
    "    \n",
    "    print(f\"\\nContent Type Distribution:\")\n",
    "    print(f\"  Chunks with Tables:    {df['has_tables'].sum()}\")\n",
    "    print(f\"  Chunks with Code:      {df['has_code'].sum()}\")\n",
    "    print(f\"  Chunks with Equations: {df['has_equations'].sum()}\")\n",
    "    \n",
    "    print(f\"\\nTop 5 Largest Chunks:\")\n",
    "    print(df.nlargest(5, 'char_count')[['chunk_id', 'context', 'char_count', 'word_count']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "hierarchical_stats_df = analyze_hierarchical_chunks(hierarchical_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c564fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE HIERARCHICAL CHUNKS\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîó Hierarchy:\n",
      "‚ñ∫ H1: MATLAB¬Æ\n",
      "\n",
      "üìç Context Header:\n",
      "  [Context: MATLAB¬Æ]\n",
      "\n",
      "üìÑ Metadata:\n",
      "  Pages: [1]\n",
      "  Blocks: 1\n",
      "  Size: 8 chars, 3 words\n",
      "  Depth: 1\n",
      "  Section: MATLAB¬Æ\n",
      "\n",
      "üìù Content Preview (first 400 chars):\n",
      "  R 2025 b...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 1\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîó Hierarchy:\n",
      "‚ñ∫ H1: How to Contact MathWorks\n",
      "\n",
      "üìç Context Header:\n",
      "  [Context: How to Contact MathWorks]\n",
      "\n",
      "üìÑ Metadata:\n",
      "  Pages: [2]\n",
      "  Blocks: 14\n",
      "  Size: 647 chars, 84 words\n",
      "  Depth: 1\n",
      "  Section: How to Contact MathWorks\n",
      "\n",
      "üìù Content Preview (first 400 chars):\n",
      "  Latest news:\n",
      "\n",
      "www.mathworks.com\n",
      "\n",
      "Sales and services:\n",
      "\n",
      "www.mathworks.com/sales_and_services\n",
      "\n",
      "User community:\n",
      "\n",
      "www.mathworks.com/matlabcentral\n",
      "\n",
      "Technical support:\n",
      "\n",
      "www.mathworks.com/support/contact_us\n",
      "\n",
      "Phone:\n",
      "\n",
      "508-647-7000\n",
      "\n",
      "The MathWorks, Inc. 1 Apple Hill Drive Natick, MA 01760-2098\n",
      "\n",
      "Financial Toolbox‚Ñ¢ User's Guide\n",
      "\n",
      "¬© COPYRIGHT 1995-2025 by The MathWorks, Inc.\n",
      "\n",
      "The software described in this docume...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 2\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîó Hierarchy:\n",
      "‚ñ∫ H1: How to Contact MathWorks\n",
      "\n",
      "üìç Context Header:\n",
      "  [Context: How to Contact MathWorks]\n",
      "\n",
      "üìÑ Metadata:\n",
      "  Pages: [2]\n",
      "  Blocks: 1\n",
      "  Size: 1084 chars, 158 words\n",
      "  Depth: 1\n",
      "  Section: How to Contact MathWorks\n",
      "\n",
      "üìù Content Preview (first 400 chars):\n",
      "  FEDERAL ACQUISITION: This provision applies to all acquisitions of the Program and Documentation by, for, or through the federal government of the United States. By accepting delivery of the Program or Documentation, the government hereby agrees that this software or documentation qualifies as commercial computer software or commercial computer software documentation as such terms are used or defi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_hierarchical_chunks(chunks: List[HierarchicalChunk], num_samples: int = 3):\n",
    "    \"\"\"Display sample chunks with full context\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE HIERARCHICAL CHUNKS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:num_samples]):\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"CHUNK {chunk.chunk_id}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        print(f\"\\nüîó Hierarchy:\")\n",
    "        for level, heading in zip(chunk.heading_levels, chunk.heading_hierarchy):\n",
    "            indent = \"  \" * (level - 1)\n",
    "            print(f\"{indent}{'‚îî‚îÄ' if level > 1 else '‚ñ∫'} H{level}: {heading}\")\n",
    "        \n",
    "        print(f\"\\nüìç Context Header:\")\n",
    "        print(f\"  {chunk.context_header}\")\n",
    "        \n",
    "        print(f\"\\nüìÑ Metadata:\")\n",
    "        print(f\"  Pages: {chunk.metadata.get('pages', [])}\")\n",
    "        print(f\"  Blocks: {chunk.metadata.get('num_blocks', 0)}\")\n",
    "        print(f\"  Size: {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"  Depth: {chunk.metadata.get('hierarchy_depth', 0)}\")\n",
    "        print(f\"  Section: {chunk.section_path}\")\n",
    "        \n",
    "        print(f\"\\nüìù Content Preview (first 400 chars):\")\n",
    "        print(f\"  {chunk.content[:400]}...\")\n",
    "        print()\n",
    "\n",
    "# Preview first 3 chunks\n",
    "preview_hierarchical_chunks(hierarchical_chunks, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e8f3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved 72 chunks to: ../data/chunks/hierarchical_chunks.jsonl\n",
      "üìã Saved summary to: ../data/chunks/hierarchical_chunks_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_hierarchical_chunks(chunks: List[HierarchicalChunk], output_path: str):\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk.to_dict(), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüíæ Saved {len(chunks)} chunks to: {output_path}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = output_path.replace('.jsonl', '_summary.json')\n",
    "    summary = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'chunking_method': 'hierarchical_with_context',\n",
    "        'statistics': {\n",
    "            'avg_chars': sum(len(c.content) for c in chunks) / len(chunks),\n",
    "            'min_chars': min(len(c.content) for c in chunks),\n",
    "            'max_chars': max(len(c.content) for c in chunks),\n",
    "            'avg_depth': sum(len(c.heading_hierarchy) for c in chunks) / len(chunks),\n",
    "            'max_depth': max(len(c.heading_hierarchy) for c in chunks),\n",
    "            'chunks_with_tables': sum(1 for c in chunks if c.metadata.get('has_tables')),\n",
    "            'chunks_with_code': sum(1 for c in chunks if c.metadata.get('has_code')),\n",
    "            'chunks_with_equations': sum(1 for c in chunks if c.metadata.get('has_equations'))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìã Saved summary to: {summary_path}\")\n",
    "\n",
    "# Save the chunks\n",
    "save_hierarchical_chunks(hierarchical_chunks, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b19f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Exported 72 chunks for embedding: ../data/chunks/hierarchical_chunks_for_embedding.jsonl\n",
      "üìù Each chunk includes hierarchical context in the text field\n"
     ]
    }
   ],
   "source": [
    "def export_hierarchical_for_embedding(chunks: List[HierarchicalChunk], output_path: str):\n",
    "    \"\"\"\n",
    "    Export hierarchical chunks in format ready for embedding generation.\n",
    "    Includes full context in the text field.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.full_text,  # Includes context header + content\n",
    "                'metadata': {\n",
    "                    'hierarchy': chunk.heading_hierarchy,\n",
    "                    'levels': chunk.heading_levels,\n",
    "                    'section': chunk.section_path,\n",
    "                    'pages': chunk.metadata.get('pages', []),\n",
    "                    'depth': len(chunk.heading_hierarchy),\n",
    "                    'has_tables': chunk.metadata.get('has_tables', False),\n",
    "                    'has_code': chunk.metadata.get('has_code', False),\n",
    "                    'source': 'fintbx.pdf'\n",
    "                }\n",
    "            }\n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "    print(f\"üìù Each chunk includes hierarchical context in the text field\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_hierarchical_for_embedding(hierarchical_chunks, OUTPUT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad7c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Depth",
         "type": "bar",
         "x": {
          "bdata": "AQ==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "SA==",
          "dtype": "i1"
         },
         "yaxis": "y"
        },
        {
         "name": "Size",
         "nbinsx": 30,
         "type": "histogram",
         "x": [
          8,
          647,
          1084,
          239,
          120,
          1210,
          1834,
          8800,
          1394,
          893,
          7627,
          145,
          1255,
          276,
          1153,
          1406,
          1393,
          669,
          562,
          203,
          1440,
          742,
          1254,
          704,
          838,
          21,
          776,
          1152,
          488,
          725,
          980,
          2199,
          51,
          111,
          7612,
          386,
          237,
          139,
          999,
          587,
          1098,
          794,
          1221,
          971,
          1049,
          557,
          1048,
          1443,
          150,
          252,
          924,
          223,
          354,
          330,
          174,
          82,
          188,
          564,
          275,
          1028,
          1277,
          421,
          546,
          1115,
          4391,
          794,
          1575,
          444,
          1487,
          416,
          43,
          50
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "marker": {
          "opacity": 0.6,
          "size": 8
         },
         "mode": "markers",
         "name": "Chunks",
         "type": "scatter",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x3",
         "y": [
          8,
          647,
          1084,
          239,
          120,
          1210,
          1834,
          8800,
          1394,
          893,
          7627,
          145,
          1255,
          276,
          1153,
          1406,
          1393,
          669,
          562,
          203,
          1440,
          742,
          1254,
          704,
          838,
          21,
          776,
          1152,
          488,
          725,
          980,
          2199,
          51,
          111,
          7612,
          386,
          237,
          139,
          999,
          587,
          1098,
          794,
          1221,
          971,
          1049,
          557,
          1048,
          1443,
          150,
          252,
          924,
          223,
          354,
          330,
          174,
          82,
          188,
          564,
          275,
          1028,
          1277,
          421,
          546,
          1115,
          4391,
          794,
          1575,
          444,
          1487,
          416,
          43,
          50
         ],
         "yaxis": "y3"
        },
        {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0,
           0.375
          ]
         },
         "labels": [
          "Tables",
          "Code",
          "Equations",
          "Text Only"
         ],
         "type": "pie",
         "values": [
          11,
          24,
          0,
          39
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Hierarchy Depth Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunk Size Distribution",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Size vs Depth",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunks by Content Type",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hierarchical Chunk Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Hierarchy Depth"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Characters"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Hierarchy Depth"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Number of Chunks"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_hierarchical_structure(chunks: List[HierarchicalChunk]):\n",
    "    \"\"\"Visualize the hierarchical structure of chunks\"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    depths = [len(c.heading_hierarchy) for c in chunks]\n",
    "    sizes = [len(c.content) for c in chunks]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Hierarchy Depth Distribution',\n",
    "            'Chunk Size Distribution',\n",
    "            'Size vs Depth',\n",
    "            'Chunks by Content Type'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'histogram'}],\n",
    "            [{'type': 'scatter'}, {'type': 'pie'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Hierarchy depth distribution\n",
    "    depth_counts = pd.Series(depths).value_counts().sort_index()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=depth_counts.index, y=depth_counts.values, name='Depth'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Hierarchy Depth\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Chunks\", row=1, col=1)\n",
    "    \n",
    "    # 2. Chunk size distribution\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=sizes, nbinsx=30, name='Size'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Characters\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "    \n",
    "    # 3. Size vs Depth scatter\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=depths,\n",
    "            y=sizes,\n",
    "            mode='markers',\n",
    "            marker=dict(size=8, opacity=0.6),\n",
    "            name='Chunks'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Hierarchy Depth\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=2, col=1)\n",
    "    \n",
    "    # 4. Content type pie\n",
    "    content_types = {\n",
    "        'Tables': sum(1 for c in chunks if c.metadata.get('has_tables')),\n",
    "        'Code': sum(1 for c in chunks if c.metadata.get('has_code')),\n",
    "        'Equations': sum(1 for c in chunks if c.metadata.get('has_equations')),\n",
    "        'Text Only': sum(1 for c in chunks if not any([\n",
    "            c.metadata.get('has_tables'),\n",
    "            c.metadata.get('has_code'),\n",
    "            c.metadata.get('has_equations')\n",
    "        ]))\n",
    "    }\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=list(content_types.keys()), values=list(content_types.values())),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Hierarchical Chunk Analysis\",\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_hierarchical_structure(hierarchical_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e20745a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e89b87",
   "metadata": {},
   "source": [
    "#### üéØ **Key Features of Hierarchical Chunking:**\n",
    "\n",
    "1. **Context Preservation**: Each chunk includes a breadcrumb trail (e.g., `[Context: Getting Started > Portfolio Analysis > Risk Metrics]`)\n",
    "\n",
    "2. **Hierarchy Tracking**: Maintains heading levels and parent-child relationships\n",
    "\n",
    "3. **Smart Splitting**: Only creates new chunks when:\n",
    "   - Context changes (new section)\n",
    "   - Size limit exceeded\n",
    "\n",
    "4. **Rich Metadata**: Tracks content types, depth, and structure\n",
    "\n",
    "5. **Embedding-Ready**: Exports with full context included in text\n",
    "\n",
    "This approach is **perfect for RAG systems** where you need to understand the document structure and provide contextual answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4b45d",
   "metadata": {},
   "source": [
    "### Method 3: Type-Aware Chunking üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6c42c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Type-Aware Chunking Setup\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "CLEANED_DATA_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/type_aware_chunks.jsonl'\n",
    "OUTPUT_EMBEDDING_PATH = '../data/chunks/type_aware_chunks_for_embedding.jsonl'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b7ebbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Type-Aware Chunk Data Structure\n",
    "@dataclass\n",
    "class TypeAwareChunk:\n",
    "    \"\"\"\n",
    "    Represents a chunk with content-type awareness.\n",
    "    \"\"\"\n",
    "    chunk_id: int\n",
    "    content: str\n",
    "    primary_type: str           # Main content type in this chunk\n",
    "    content_types: List[str]    # All types present\n",
    "    section_path: str\n",
    "    section_heading: str\n",
    "    is_special_content: bool    # True for tables, code, equations\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    @property\n",
    "    def is_table_chunk(self):\n",
    "        return self.primary_type == 'table'\n",
    "    \n",
    "    @property\n",
    "    def is_code_chunk(self):\n",
    "        return self.primary_type == 'code'\n",
    "    \n",
    "    @property\n",
    "    def is_mixed_content(self):\n",
    "        return len(self.content_types) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3310922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_type_aware(\n",
    "    jsonl_path: str,\n",
    "    max_chunk_size: int = 1500,\n",
    "    keep_tables_whole: bool = True,\n",
    "    keep_code_whole: bool = True,\n",
    "    keep_equations_whole: bool = True,\n",
    "    group_lists: bool = True,\n",
    "    skip_types: List[str] = ['figure']\n",
    ") -> List[TypeAwareChunk]:\n",
    "    \"\"\"\n",
    "    Create type-aware chunks that handle different content types intelligently.\n",
    "    \n",
    "    Key Features:\n",
    "    - Tables kept as complete standalone chunks (unless too large)\n",
    "    - Code blocks preserved whole\n",
    "    - Equations kept intact\n",
    "    - Lists grouped together\n",
    "    - Text content chunked normally\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to cleaned JSONL file\n",
    "        max_chunk_size: Maximum chunk size for regular text\n",
    "        keep_tables_whole: Don't split tables across chunks\n",
    "        keep_code_whole: Keep code blocks complete\n",
    "        keep_equations_whole: Keep equations complete\n",
    "        group_lists: Try to keep list items together\n",
    "        skip_types: Block types to skip\n",
    "    \n",
    "    Returns:\n",
    "        List of TypeAwareChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load blocks\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    # Sort by page and block_id\n",
    "    blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "    \n",
    "    print(f\"üìö Processing {len(blocks)} blocks for type-aware chunking...\")\n",
    "    print(f\"üìè Max chunk size: {max_chunk_size} characters\")\n",
    "    print(f\"‚öôÔ∏è  Settings:\")\n",
    "    print(f\"   - Keep tables whole: {keep_tables_whole}\")\n",
    "    print(f\"   - Keep code whole: {keep_code_whole}\")\n",
    "    print(f\"   - Keep equations whole: {keep_equations_whole}\")\n",
    "    print(f\"   - Group lists: {group_lists}\\n\")\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    # Current state tracking\n",
    "    current_section = None\n",
    "    current_section_heading = \"\"\n",
    "    current_chunk_content = []\n",
    "    current_chunk_metadata = {\n",
    "        'pages': set(),\n",
    "        'block_ids': [],\n",
    "        'content_types': set(),\n",
    "        'type_counts': {},\n",
    "        'num_blocks': 0\n",
    "    }\n",
    "    \n",
    "    def create_chunk(primary_type: str = 'text', is_special: bool = False):\n",
    "        \"\"\"Helper to create and save current chunk\"\"\"\n",
    "        nonlocal chunk_id, current_chunk_content, current_chunk_metadata, chunks\n",
    "        \n",
    "        if not current_chunk_content:\n",
    "            return\n",
    "        \n",
    "        # Combine content\n",
    "        content = '\\n\\n'.join(current_chunk_content).strip()\n",
    "        \n",
    "        if not content:\n",
    "            return\n",
    "        \n",
    "        # Determine primary type (most frequent or special)\n",
    "        if is_special:\n",
    "            # Already specified\n",
    "            pass\n",
    "        else:\n",
    "            # Use most common type in chunk\n",
    "            type_counts = current_chunk_metadata.get('type_counts', {})\n",
    "            primary_type = max(type_counts, key=type_counts.get) if type_counts else 'text'\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'pages': sorted(list(current_chunk_metadata['pages'])),\n",
    "            'block_ids': current_chunk_metadata['block_ids'].copy(),\n",
    "            'content_types': list(current_chunk_metadata['content_types']),\n",
    "            'type_counts': current_chunk_metadata['type_counts'].copy(),\n",
    "            'num_blocks': current_chunk_metadata['num_blocks'],\n",
    "            'char_count': len(content),\n",
    "            'word_count': len(content.split()),\n",
    "            'is_pure_type': len(current_chunk_metadata['content_types']) == 1,\n",
    "            'source': 'fintbx.pdf',\n",
    "            'chunking_method': 'type_aware'\n",
    "        }\n",
    "        \n",
    "        # Create chunk\n",
    "        chunk = TypeAwareChunk(\n",
    "            chunk_id=chunk_id,\n",
    "            content=content,\n",
    "            primary_type=primary_type,\n",
    "            content_types=list(current_chunk_metadata['content_types']),\n",
    "            section_path=current_section or 'Unknown',\n",
    "            section_heading=current_section_heading,\n",
    "            is_special_content=is_special,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        chunks.append(chunk)\n",
    "        chunk_id += 1\n",
    "        \n",
    "        # Reset\n",
    "        current_chunk_content.clear()\n",
    "        current_chunk_metadata = {\n",
    "            'pages': set(),\n",
    "            'block_ids': [],\n",
    "            'content_types': set(),\n",
    "            'type_counts': {},\n",
    "            'num_blocks': 0\n",
    "        }\n",
    "    \n",
    "    # Process blocks\n",
    "    for block in blocks:\n",
    "        block_type = block.get('type', 'unknown')\n",
    "        block_id = block.get('block_id')\n",
    "        text = block.get('text', '').strip()\n",
    "        \n",
    "        # Update current section from headings\n",
    "        if block_type == 'heading':\n",
    "            current_section = block.get('section_path', text)\n",
    "            if not current_section_heading:  # Take first heading as section heading\n",
    "                current_section_heading = text\n",
    "            \n",
    "            # Optionally flush before heading\n",
    "            if current_chunk_content:\n",
    "                create_chunk()\n",
    "                current_section_heading = text  # Reset for new section\n",
    "            continue\n",
    "        \n",
    "        # Skip certain types\n",
    "        if block_type in skip_types:\n",
    "            continue\n",
    "        \n",
    "        # --- SPECIAL TYPE HANDLING ---\n",
    "        \n",
    "        # TABLES: Keep whole as separate chunks\n",
    "        if block_type == 'table':\n",
    "            # Flush current chunk first\n",
    "            if current_chunk_content:\n",
    "                create_chunk()\n",
    "            \n",
    "            # Create standalone table chunk\n",
    "            caption = block.get('caption', 'Table')\n",
    "            num_rows = block.get('num_rows', 0)\n",
    "            num_cols = block.get('num_cols', 0)\n",
    "            \n",
    "            table_content = f\"## {caption}\\n\\n```\\n{text}\\n```\"\n",
    "            \n",
    "            if keep_tables_whole or len(text) < max_chunk_size * 1.5:\n",
    "                # Create single table chunk\n",
    "                current_chunk_content = [table_content]\n",
    "                current_chunk_metadata = {\n",
    "                    'pages': {block.get('page', 0)},\n",
    "                    'block_ids': [block_id],\n",
    "                    'content_types': {'table'},\n",
    "                    'type_counts': {'table': 1},\n",
    "                    'num_blocks': 1,\n",
    "                    'table_info': {\n",
    "                        'caption': caption,\n",
    "                        'num_rows': num_rows,\n",
    "                        'num_cols': num_cols,\n",
    "                        'table_id': block.get('table_id', '')\n",
    "                    }\n",
    "                }\n",
    "                create_chunk(primary_type='table', is_special=True)\n",
    "            else:\n",
    "                # Very large table - add to regular chunking\n",
    "                current_chunk_content.append(table_content)\n",
    "                current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "                current_chunk_metadata['block_ids'].append(block_id)\n",
    "                current_chunk_metadata['content_types'].add('table')\n",
    "                current_chunk_metadata['type_counts']['table'] = current_chunk_metadata['type_counts'].get('table', 0) + 1\n",
    "                current_chunk_metadata['num_blocks'] += 1\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # CODE: Keep whole blocks\n",
    "        if block_type == 'code':\n",
    "            code_content = f\"```\\n{text}\\n```\"\n",
    "            \n",
    "            if keep_code_whole and len(text) < max_chunk_size * 1.5:\n",
    "                # Flush current\n",
    "                if current_chunk_content:\n",
    "                    create_chunk()\n",
    "                \n",
    "                # Create code chunk\n",
    "                current_chunk_content = [code_content]\n",
    "                current_chunk_metadata = {\n",
    "                    'pages': {block.get('page', 0)},\n",
    "                    'block_ids': [block_id],\n",
    "                    'content_types': {'code'},\n",
    "                    'type_counts': {'code': 1},\n",
    "                    'num_blocks': 1\n",
    "                }\n",
    "                create_chunk(primary_type='code', is_special=True)\n",
    "            else:\n",
    "                # Add to regular chunking\n",
    "                current_chunk_content.append(code_content)\n",
    "                current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "                current_chunk_metadata['block_ids'].append(block_id)\n",
    "                current_chunk_metadata['content_types'].add('code')\n",
    "                current_chunk_metadata['type_counts']['code'] = current_chunk_metadata['type_counts'].get('code', 0) + 1\n",
    "                current_chunk_metadata['num_blocks'] += 1\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # EQUATIONS: Keep intact\n",
    "        if block_type == 'equation':\n",
    "            equation_content = f\"$$\\n{text}\\n$$\"\n",
    "            \n",
    "            if keep_equations_whole:\n",
    "                # Check if current chunk size allows adding equation\n",
    "                current_size = sum(len(c) for c in current_chunk_content)\n",
    "                if current_size + len(equation_content) > max_chunk_size and current_chunk_content:\n",
    "                    create_chunk()\n",
    "                \n",
    "                current_chunk_content.append(equation_content)\n",
    "            else:\n",
    "                current_chunk_content.append(equation_content)\n",
    "            \n",
    "            current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "            current_chunk_metadata['block_ids'].append(block_id)\n",
    "            current_chunk_metadata['content_types'].add('equation')\n",
    "            current_chunk_metadata['type_counts']['equation'] = current_chunk_metadata['type_counts'].get('equation', 0) + 1\n",
    "            current_chunk_metadata['num_blocks'] += 1\n",
    "            continue\n",
    "        \n",
    "        # LISTS: Try to keep together\n",
    "        if block_type == 'list':\n",
    "            list_content = text\n",
    "            \n",
    "            if group_lists:\n",
    "                # Check if adding would exceed size\n",
    "                current_size = sum(len(c) for c in current_chunk_content)\n",
    "                if current_size + len(list_content) > max_chunk_size and current_chunk_content:\n",
    "                    # Only split if current chunk isn't also a list\n",
    "                    if 'list' not in current_chunk_metadata['content_types']:\n",
    "                        create_chunk()\n",
    "            \n",
    "            current_chunk_content.append(list_content)\n",
    "            current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "            current_chunk_metadata['block_ids'].append(block_id)\n",
    "            current_chunk_metadata['content_types'].add('list')\n",
    "            current_chunk_metadata['type_counts']['list'] = current_chunk_metadata['type_counts'].get('list', 0) + 1\n",
    "            current_chunk_metadata['num_blocks'] += 1\n",
    "            continue\n",
    "        \n",
    "        # --- REGULAR TEXT HANDLING (paragraphs) ---\n",
    "        \n",
    "        block_text = text\n",
    "        \n",
    "        # Check size before adding\n",
    "        current_size = sum(len(c) for c in current_chunk_content)\n",
    "        if current_size + len(block_text) > max_chunk_size and current_chunk_content:\n",
    "            create_chunk()\n",
    "        \n",
    "        # Add paragraph\n",
    "        current_chunk_content.append(block_text)\n",
    "        current_chunk_metadata['pages'].add(block.get('page', 0))\n",
    "        current_chunk_metadata['block_ids'].append(block_id)\n",
    "        current_chunk_metadata['content_types'].add('paragraph')\n",
    "        current_chunk_metadata['type_counts']['paragraph'] = current_chunk_metadata['type_counts'].get('paragraph', 0) + 1\n",
    "        current_chunk_metadata['num_blocks'] += 1\n",
    "    \n",
    "    # Create final chunk\n",
    "    if current_chunk_content:\n",
    "        create_chunk()\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} type-aware chunks\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90d93151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Type-Aware Chunking...\n",
      "\n",
      "üìö Processing 431 blocks for type-aware chunking...\n",
      "üìè Max chunk size: 1500 characters\n",
      "‚öôÔ∏è  Settings:\n",
      "   - Keep tables whole: True\n",
      "   - Keep code whole: True\n",
      "   - Keep equations whole: True\n",
      "   - Group lists: True\n",
      "\n",
      "‚úÖ Created 141 type-aware chunks\n",
      "\n",
      "‚úÖ Type-aware chunking complete!\n",
      "üìä Total chunks: 141\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Type-Aware Chunking...\\n\")\n",
    "\n",
    "type_aware_chunks = chunk_type_aware(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    max_chunk_size=1500,\n",
    "    keep_tables_whole=True,\n",
    "    keep_code_whole=True,\n",
    "    keep_equations_whole=True,\n",
    "    group_lists=True,\n",
    "    skip_types=['figure']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Type-aware chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(type_aware_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "354f6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä TYPE-AWARE CHUNK STATISTICS\n",
      "======================================================================\n",
      "Total Chunks: 141\n",
      "\n",
      "üìã Primary Type Distribution:\n",
      "  paragraph      :   81 chunks ( 57.4%)\n",
      "  code           :   40 chunks ( 28.4%)\n",
      "  table          :   12 chunks (  8.5%)\n",
      "  list           :    8 chunks (  5.7%)\n",
      "\n",
      "üéØ Special Content Chunks:\n",
      "  Tables:       12\n",
      "  Code:         40\n",
      "  Special Total: 52\n",
      "\n",
      "üîÄ Content Mixing:\n",
      "  Pure (single type):  134\n",
      "  Mixed (multi-type):  7\n",
      "\n",
      "üìè Size Distribution:\n",
      "  Average Characters: 550\n",
      "  Median Characters:  203\n",
      "  Min Characters:     4\n",
      "  Max Characters:     8800\n",
      "  Std Dev:            1225\n",
      "\n",
      "üîù Top 5 Largest Chunks:\n",
      "     chunk_id primary_type  is_special  char_count               section\n",
      "7           7        table        True        8800      Revision History\n",
      "11         11        table        True        7627  Credit Risk Analysis\n",
      "81         81        table        True        7612      Related Examples\n",
      "133       133        table        True        4391        Binomial Model\n",
      "78         78        table        True        2199             Annuities\n",
      "\n",
      "üìä Chunks by Number of Content Types:\n",
      "  1 type(s): 134 chunks\n",
      "  2 type(s): 7 chunks\n"
     ]
    }
   ],
   "source": [
    "def analyze_type_aware_chunks(chunks: List[TypeAwareChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive statistics about type-aware chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'primary_type': chunk.primary_type,\n",
    "            'is_special': chunk.is_special_content,\n",
    "            'is_mixed': chunk.is_mixed_content,\n",
    "            'num_types': len(chunk.content_types),\n",
    "            'content_types': ', '.join(sorted(chunk.content_types)),\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'pages': ', '.join(map(str, chunk.metadata.get('pages', []))),\n",
    "            'num_blocks': chunk.metadata.get('num_blocks', 0),\n",
    "            'section': chunk.section_path[:40] + '...' if len(chunk.section_path) > 40 else chunk.section_path\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä TYPE-AWARE CHUNK STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    \n",
    "    print(f\"\\nüìã Primary Type Distribution:\")\n",
    "    type_dist = df['primary_type'].value_counts()\n",
    "    for ptype, count in type_dist.items():\n",
    "        pct = (count / len(chunks)) * 100\n",
    "        print(f\"  {ptype:15s}: {count:4d} chunks ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Special Content Chunks:\")\n",
    "    print(f\"  Tables:       {sum(1 for c in chunks if c.is_table_chunk)}\")\n",
    "    print(f\"  Code:         {sum(1 for c in chunks if c.is_code_chunk)}\")\n",
    "    print(f\"  Special Total: {df['is_special'].sum()}\")\n",
    "    \n",
    "    print(f\"\\nüîÄ Content Mixing:\")\n",
    "    print(f\"  Pure (single type):  {sum(1 for c in chunks if not c.is_mixed_content)}\")\n",
    "    print(f\"  Mixed (multi-type):  {sum(1 for c in chunks if c.is_mixed_content)}\")\n",
    "    \n",
    "    print(f\"\\nüìè Size Distribution:\")\n",
    "    print(f\"  Average Characters: {df['char_count'].mean():.0f}\")\n",
    "    print(f\"  Median Characters:  {df['char_count'].median():.0f}\")\n",
    "    print(f\"  Min Characters:     {df['char_count'].min()}\")\n",
    "    print(f\"  Max Characters:     {df['char_count'].max()}\")\n",
    "    print(f\"  Std Dev:            {df['char_count'].std():.0f}\")\n",
    "    \n",
    "    print(f\"\\nüîù Top 5 Largest Chunks:\")\n",
    "    print(df.nlargest(5, 'char_count')[['chunk_id', 'primary_type', 'is_special', 'char_count', 'section']])\n",
    "    \n",
    "    print(f\"\\nüìä Chunks by Number of Content Types:\")\n",
    "    type_count_dist = df['num_types'].value_counts().sort_index()\n",
    "    for num_types, count in type_count_dist.items():\n",
    "        print(f\"  {num_types} type(s): {count} chunks\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "type_aware_stats_df = analyze_type_aware_chunks(type_aware_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1114cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE TYPE-AWARE CHUNKS\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[TABLE] CHUNK 7 - Primary Type: TABLE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Metadata:\n",
      "  Content Types: table\n",
      "  Is Special:    True\n",
      "  Is Mixed:      False\n",
      "  Pages:         [4]\n",
      "  Blocks:        1\n",
      "  Size:          8800 chars, 1111 words\n",
      "  Section:       Revision History\n",
      "\n",
      "üìù Content Preview (first 300 chars):\n",
      "  ## Revision History\n",
      "\n",
      "```\n",
      "| Working with Average Turnover Constraints Using PortfolioMAD Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   | 6-74                                                                |\n",
      "|----------------...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[CODE] CHUNK 12 - Primary Type: CODE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Metadata:\n",
      "  Content Types: code\n",
      "  Is Special:    True\n",
      "  Is Mixed:      False\n",
      "  Pages:         [7]\n",
      "  Blocks:        1\n",
      "  Size:          28 chars, 5 words\n",
      "  Section:       Credit Risk Analysis\n",
      "\n",
      "üìù Content Preview (first 300 chars):\n",
      "  ```\n",
      "3.5475 3.5550 3.5513\n",
      "```\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[TEXT] CHUNK 0 - Primary Type: PARAGRAPH\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Metadata:\n",
      "  Content Types: paragraph\n",
      "  Is Special:    False\n",
      "  Is Mixed:      False\n",
      "  Pages:         [1]\n",
      "  Blocks:        1\n",
      "  Size:          8 chars, 3 words\n",
      "  Section:       How to Contact MathWorks\n",
      "\n",
      "üìù Content Preview (first 300 chars):\n",
      "  R 2025 b\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[MIXED] CHUNK 60 - Primary Type: LIST\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Metadata:\n",
      "  Content Types: paragraph, list\n",
      "  Is Special:    False\n",
      "  Is Mixed:      True\n",
      "  Pages:         [13, 15]\n",
      "  Blocks:        4\n",
      "  Size:          575 chars, 97 words\n",
      "  Section:       More About\n",
      "\n",
      "üìù Content Preview (first 300 chars):\n",
      "  'Analyze Sets of Numbers Using Matrix Functions' on page 1-4\n",
      "\n",
      "'Matrix Algebra Refresher' on page 1-7\n",
      "\n",
      "equals the initial investment. If all the cf n s are positive there is only one solution. Every time there is a change of sign between coefficients, up to two additional real roots are possible.\n",
      "\n",
      "An...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[SAMPLE] CHUNK 0 - Primary Type: PARAGRAPH\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìã Metadata:\n",
      "  Content Types: paragraph\n",
      "  Is Special:    False\n",
      "  Is Mixed:      False\n",
      "  Pages:         [1]\n",
      "  Blocks:        1\n",
      "  Size:          8 chars, 3 words\n",
      "  Section:       How to Contact MathWorks\n",
      "\n",
      "üìù Content Preview (first 300 chars):\n",
      "  R 2025 b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_type_aware_chunks(chunks: List[TypeAwareChunk], num_samples: int = 5):\n",
    "    \"\"\"Display sample chunks of different types\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE TYPE-AWARE CHUNKS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get diverse samples\n",
    "    table_chunks = [c for c in chunks if c.is_table_chunk]\n",
    "    code_chunks = [c for c in chunks if c.is_code_chunk]\n",
    "    text_chunks = [c for c in chunks if c.primary_type == 'paragraph']\n",
    "    mixed_chunks = [c for c in chunks if c.is_mixed_content]\n",
    "    \n",
    "    samples = []\n",
    "    if table_chunks: samples.append(('TABLE', table_chunks[0]))\n",
    "    if code_chunks: samples.append(('CODE', code_chunks[0]))\n",
    "    if text_chunks: samples.append(('TEXT', text_chunks[0]))\n",
    "    if mixed_chunks: samples.append(('MIXED', mixed_chunks[0]))\n",
    "    \n",
    "    # Add a few more\n",
    "    for chunk in chunks[:2]:\n",
    "        if ('SAMPLE', chunk) not in samples:\n",
    "            samples.append(('SAMPLE', chunk))\n",
    "    \n",
    "    for label, chunk in samples[:num_samples]:\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"[{label}] CHUNK {chunk.chunk_id} - Primary Type: {chunk.primary_type.upper()}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        print(f\"\\nüìã Metadata:\")\n",
    "        print(f\"  Content Types: {', '.join(chunk.content_types)}\")\n",
    "        print(f\"  Is Special:    {chunk.is_special_content}\")\n",
    "        print(f\"  Is Mixed:      {chunk.is_mixed_content}\")\n",
    "        print(f\"  Pages:         {chunk.metadata.get('pages', [])}\")\n",
    "        print(f\"  Blocks:        {chunk.metadata.get('num_blocks', 0)}\")\n",
    "        print(f\"  Size:          {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"  Section:       {chunk.section_path}\")\n",
    "        \n",
    "        if 'table_info' in chunk.metadata:\n",
    "            tinfo = chunk.metadata['table_info']\n",
    "            print(f\"  Table Info:    {tinfo.get('num_rows', 0)}x{tinfo.get('num_cols', 0)} - {tinfo.get('caption', 'N/A')}\")\n",
    "        \n",
    "        print(f\"\\nüìù Content Preview (first 300 chars):\")\n",
    "        preview = chunk.content[:300]\n",
    "        if len(chunk.content) > 300:\n",
    "            preview += \"...\"\n",
    "        print(f\"  {preview}\")\n",
    "        print()\n",
    "\n",
    "# Preview diverse samples\n",
    "preview_type_aware_chunks(type_aware_chunks, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved 141 chunks to: ../data/chunks/type_aware_chunks.jsonl\n",
      "üìã Saved summary to: ../data/chunks/type_aware_chunks_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_type_aware_chunks(chunks: List[TypeAwareChunk], output_path: str):\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk.to_dict(), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüíæ Saved {len(chunks)} chunks to: {output_path}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = output_path.replace('.jsonl', '_summary.json')\n",
    "    \n",
    "    type_counts = {}\n",
    "    for chunk in chunks:\n",
    "        type_counts[chunk.primary_type] = type_counts.get(chunk.primary_type, 0) + 1\n",
    "    \n",
    "    summary = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'chunking_method': 'type_aware',\n",
    "        'statistics': {\n",
    "            'avg_chars': sum(len(c.content) for c in chunks) / len(chunks),\n",
    "            'min_chars': min(len(c.content) for c in chunks),\n",
    "            'max_chars': max(len(c.content) for c in chunks),\n",
    "            'special_content_chunks': sum(1 for c in chunks if c.is_special_content),\n",
    "            'mixed_content_chunks': sum(1 for c in chunks if c.is_mixed_content),\n",
    "            'pure_content_chunks': sum(1 for c in chunks if not c.is_mixed_content),\n",
    "            'chunks_by_primary_type': type_counts,\n",
    "            'table_chunks': sum(1 for c in chunks if c.is_table_chunk),\n",
    "            'code_chunks': sum(1 for c in chunks if c.is_code_chunk)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìã Saved summary to: {summary_path}\")\n",
    "\n",
    "# Save the chunks\n",
    "save_type_aware_chunks(type_aware_chunks, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10af2a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Exported 141 chunks for embedding: ../data/chunks/type_aware_chunks_for_embedding.jsonl\n",
      "üìù Metadata includes content type for filtered retrieval\n",
      "   Example: Search only in tables, code, or equations\n"
     ]
    }
   ],
   "source": [
    "def export_type_aware_for_embedding(chunks: List[TypeAwareChunk], output_path: str):\n",
    "    \"\"\"\n",
    "    Export type-aware chunks for embedding generation.\n",
    "    Includes type information in metadata for filtered retrieval.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.content,\n",
    "                'metadata': {\n",
    "                    'primary_type': chunk.primary_type,\n",
    "                    'content_types': chunk.content_types,\n",
    "                    'is_special': chunk.is_special_content,\n",
    "                    'is_table': chunk.is_table_chunk,\n",
    "                    'is_code': chunk.is_code_chunk,\n",
    "                    'is_mixed': chunk.is_mixed_content,\n",
    "                    'section': chunk.section_path,\n",
    "                    'pages': chunk.metadata.get('pages', []),\n",
    "                    'source': 'fintbx.pdf'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add table-specific metadata if present\n",
    "            if 'table_info' in chunk.metadata:\n",
    "                embedding_doc['metadata']['table_info'] = chunk.metadata['table_info']\n",
    "            \n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "    print(f\"üìù Metadata includes content type for filtered retrieval\")\n",
    "    print(f\"   Example: Search only in tables, code, or equations\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_type_aware_for_embedding(type_aware_chunks, OUTPUT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ed87914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0.625,
           1
          ]
         },
         "labels": [
          "paragraph",
          "code",
          "table",
          "list"
         ],
         "name": "Primary Type",
         "type": "pie",
         "values": {
          "bdata": "USgMCA==",
          "dtype": "i1"
         }
        },
        {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0.625,
           1
          ]
         },
         "labels": [
          "Special (Table/Code)",
          "Regular Content"
         ],
         "type": "pie",
         "values": [
          52,
          89
         ]
        },
        {
         "marker": {
          "color": [
           "green",
           "orange"
          ]
         },
         "type": "bar",
         "x": [
          "Pure (Single Type)",
          "Mixed (Multiple Types)"
         ],
         "xaxis": "x",
         "y": [
          134,
          7
         ],
         "yaxis": "y"
        },
        {
         "name": "paragraph",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "CACHAjwE7wB4ALoEKgcEAH0DcwByAaAA9AF9AF0CzwENBOcDEwAUAXMAewC9AdEEVADOALYBygCsASABewCVAJIARwSZAH4CQgAKAegBWQGTAEkBvQD3ADMAggGLAOMBWAF0AEcAOgPvAKUBZACVA5IBGQQtApgACQELAegAXwDfAGIBSgGuAFIAvAA0AhMBBARSAFsEGgMnBrwBzwWgASsA",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "name": "table",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "YCJsBcsdSQFBAcsAlwi8He0AAgL8ACcR",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "name": "code",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "HAA1AKQAlQBRACMAXgBoAHMASgArADMAKQApAFgAMAAWADAAYgAsAFUAJgAxAOUAhQBKAHsAxQApAkoAwQBLAL8ARQBeAKwAZQCWAKUBTgA=",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "name": "list",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "FQA/Am8AQwOcA/0EfgEyAA==",
          "dtype": "i2"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunks by Primary Type",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Special vs Regular Content",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Content Purity Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Size Distribution by Type",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Type-Aware Chunking Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Content Purity"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Number of Chunks"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_type_aware_chunks(chunks: List[TypeAwareChunk], stats_df: pd.DataFrame):\n",
    "    \"\"\"Visualize the type-aware chunking results\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Chunks by Primary Type',\n",
    "            'Special vs Regular Content',\n",
    "            'Content Purity Distribution',\n",
    "            'Size Distribution by Type'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'pie'}, {'type': 'pie'}],\n",
    "            [{'type': 'bar'}, {'type': 'box'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Primary type distribution\n",
    "    type_counts = stats_df['primary_type'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=type_counts.index, values=type_counts.values, name='Primary Type'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Special vs Regular\n",
    "    special_counts = {\n",
    "        'Special (Table/Code)': stats_df['is_special'].sum(),\n",
    "        'Regular Content': (~stats_df['is_special']).sum()\n",
    "    }\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=list(special_counts.keys()), values=list(special_counts.values())),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Content purity\n",
    "    purity_counts = stats_df['is_mixed'].value_counts()\n",
    "    purity_labels = ['Pure (Single Type)', 'Mixed (Multiple Types)']\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=purity_labels,\n",
    "            y=[purity_counts.get(False, 0), purity_counts.get(True, 0)],\n",
    "            marker_color=['green', 'orange']\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Content Purity\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Chunks\", row=2, col=1)\n",
    "    \n",
    "    # 4. Size distribution by type\n",
    "    for ptype in stats_df['primary_type'].unique():\n",
    "        type_data = stats_df[stats_df['primary_type'] == ptype]\n",
    "        fig.add_trace(\n",
    "            go.Box(y=type_data['char_count'], name=ptype),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Type-Aware Chunking Analysis\",\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_type_aware_chunks(type_aware_chunks, type_aware_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a98a0e",
   "metadata": {},
   "source": [
    "#### **Key Features of Type-Aware Chunking:**\n",
    "\n",
    "1. **Table Preservation**: Tables kept whole as standalone chunks (unless massive)\n",
    "2. **Code Block Integrity**: Code blocks preserved completely\n",
    "3. **Equation Handling**: Mathematical equations kept intact\n",
    "4. **List Grouping**: List items kept together when possible\n",
    "5. **Content Type Metadata**: Each chunk tagged with content types for filtered retrieval\n",
    "6. **Special Content Flagging**: Easy to identify chunks with tables/code/equations\n",
    "\n",
    " üí° **Use Cases:**\n",
    "\n",
    "- **Table Search**: \"Find all financial tables\" ‚Üí Filter by `is_table: true`\n",
    "- **Code Retrieval**: \"Show me MATLAB code examples\" ‚Üí Filter by `primary_type: code`\n",
    "- **Mixed Content**: Chunks with both text and equations\n",
    "- **Pure Content**: Single-type chunks for focused retrieval\n",
    "\n",
    "This method is **perfect for technical/financial documents** with diverse content types!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396cdf2f",
   "metadata": {},
   "source": [
    "### Method 4: Fixed-Size with Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10ee0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Fixed-Size with Overlap Chunking Setup\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Paths\n",
    "CLEANED_DATA_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/fixed_overlap_chunks.jsonl'\n",
    "OUTPUT_EMBEDDING_PATH = '../data/chunks/fixed_overlap_chunks_for_embedding.jsonl'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20c7ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Fixed-Size Chunk Data Structure\n",
    "@dataclass\n",
    "class FixedSizeChunk:\n",
    "    \"\"\"\n",
    "    Represents a fixed-size chunk with overlap.\n",
    "    \"\"\"\n",
    "    chunk_id: int\n",
    "    content: str\n",
    "    overlap_with_previous: bool\n",
    "    overlap_with_next: bool\n",
    "    source_block_range: List[int]  # Original block IDs\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    @property\n",
    "    def has_overlap(self):\n",
    "        return self.overlap_with_previous or self.overlap_with_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef8f917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_fixed_size_with_overlap(\n",
    "    jsonl_path: str,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    separators: List[str] = None,\n",
    "    skip_types: List[str] = ['figure'],\n",
    "    add_section_markers: bool = True\n",
    ") -> List[FixedSizeChunk]:\n",
    "    \"\"\"\n",
    "    Create fixed-size chunks with overlap using RecursiveCharacterTextSplitter.\n",
    "    \n",
    "    This method:\n",
    "    - Creates consistent-sized chunks (important for many embedding models)\n",
    "    - Adds overlap between chunks to preserve context\n",
    "    - Uses intelligent separators (paragraphs > sentences > words)\n",
    "    - Maintains traceability to source blocks\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to cleaned JSONL file\n",
    "        chunk_size: Target chunk size in characters\n",
    "        chunk_overlap: Number of characters to overlap between chunks\n",
    "        separators: Custom separators (default: paragraphs, newlines, sentences, spaces)\n",
    "        skip_types: Block types to skip\n",
    "        add_section_markers: Add section headers as markdown\n",
    "    \n",
    "    Returns:\n",
    "        List of FixedSizeChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default separators prioritize semantic boundaries\n",
    "    if separators is None:\n",
    "        separators = [\n",
    "            \"\\n\\n\",      # Paragraphs (highest priority)\n",
    "            \"\\n\",        # Line breaks\n",
    "            \". \",        # Sentences\n",
    "            \"! \",        # Sentences\n",
    "            \"? \",        # Sentences\n",
    "            \"; \",        # Clauses\n",
    "            \", \",        # Phrases\n",
    "            \" \",         # Words\n",
    "            \"\"           # Characters (last resort)\n",
    "        ]\n",
    "    \n",
    "    print(f\"üìö Processing blocks for fixed-size chunking...\")\n",
    "    print(f\"üìè Chunk size: {chunk_size} characters\")\n",
    "    print(f\"üîÑ Overlap: {chunk_overlap} characters ({chunk_overlap/chunk_size*100:.1f}%)\")\n",
    "    print(f\"üî™ Separators: {len(separators)} levels\")\n",
    "    print(f\"   Priority: {' > '.join(repr(s) if s else 'chars' for s in separators[:4])}\\n\")\n",
    "    \n",
    "    # Load blocks\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    # Sort by page and block_id\n",
    "    blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "    \n",
    "    # Build document text with markers\n",
    "    full_text = \"\"\n",
    "    block_map = []  # Track which characters belong to which blocks\n",
    "    section_boundaries = []  # Track section changes\n",
    "    \n",
    "    current_section = None\n",
    "    \n",
    "    for block in blocks:\n",
    "        block_type = block.get('type', 'unknown')\n",
    "        block_id = block.get('block_id')\n",
    "        text = block.get('text', '').strip()\n",
    "        section = block.get('section_path', '')\n",
    "        \n",
    "        # Skip certain types\n",
    "        if block_type in skip_types or not text:\n",
    "            continue\n",
    "        \n",
    "        # Track section changes\n",
    "        if section != current_section:\n",
    "            if add_section_markers and section:\n",
    "                section_marker = f\"\\n## {section}\\n\\n\"\n",
    "                start_pos = len(full_text)\n",
    "                full_text += section_marker\n",
    "                section_boundaries.append({\n",
    "                    'position': start_pos,\n",
    "                    'section': section,\n",
    "                    'marker_length': len(section_marker)\n",
    "                })\n",
    "            current_section = section\n",
    "        \n",
    "        # Record block position in text\n",
    "        start_pos = len(full_text)\n",
    "        \n",
    "        # Format text based on type\n",
    "        if block_type == 'heading':\n",
    "            formatted_text = f\"\\n### {text}\\n\\n\"\n",
    "        elif block_type == 'table':\n",
    "            caption = block.get('caption', 'Table')\n",
    "            formatted_text = f\"\\n#### {caption}\\n```\\n{text}\\n```\\n\\n\"\n",
    "        elif block_type == 'code':\n",
    "            formatted_text = f\"\\n```\\n{text}\\n```\\n\\n\"\n",
    "        elif block_type == 'equation':\n",
    "            formatted_text = f\"\\n$$\\n{text}\\n$$\\n\\n\"\n",
    "        elif block_type == 'list':\n",
    "            formatted_text = text + \"\\n\\n\"\n",
    "        else:  # paragraph\n",
    "            formatted_text = text + \"\\n\\n\"\n",
    "        \n",
    "        full_text += formatted_text\n",
    "        end_pos = len(full_text)\n",
    "        \n",
    "        # Map this block's text range\n",
    "        block_map.append({\n",
    "            'block_id': block_id,\n",
    "            'block_type': block_type,\n",
    "            'start': start_pos,\n",
    "            'end': end_pos,\n",
    "            'page': block.get('page', 0),\n",
    "            'section': section\n",
    "        })\n",
    "    \n",
    "    print(f\"üìÑ Combined {len(blocks)} blocks into {len(full_text):,} characters\")\n",
    "    print(f\"üóÇÔ∏è  Identified {len(set(b['section'] for b in block_map))} unique sections\\n\")\n",
    "    \n",
    "    # Create text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=separators,\n",
    "        keep_separator=True  # Keep separators to maintain readability\n",
    "    )\n",
    "    \n",
    "    # Split the text\n",
    "    raw_chunks = text_splitter.split_text(full_text)\n",
    "    \n",
    "    print(f\"‚úÇÔ∏è  Split into {len(raw_chunks)} chunks\\n\")\n",
    "    \n",
    "    # Create FixedSizeChunk objects with metadata\n",
    "    chunks = []\n",
    "    \n",
    "    for chunk_id, chunk_text in enumerate(raw_chunks):\n",
    "        # Find which blocks this chunk overlaps with\n",
    "        chunk_start = full_text.find(chunk_text)\n",
    "        chunk_end = chunk_start + len(chunk_text)\n",
    "        \n",
    "        # Get overlapping blocks\n",
    "        overlapping_blocks = []\n",
    "        pages = set()\n",
    "        sections = set()\n",
    "        block_types = set()\n",
    "        \n",
    "        for block_info in block_map:\n",
    "            # Check if chunk overlaps with this block\n",
    "            if not (chunk_end <= block_info['start'] or chunk_start >= block_info['end']):\n",
    "                overlapping_blocks.append(block_info['block_id'])\n",
    "                pages.add(block_info['page'])\n",
    "                sections.add(block_info['section'])\n",
    "                block_types.add(block_info['block_type'])\n",
    "        \n",
    "        # Check overlap with previous/next chunks\n",
    "        overlap_with_previous = chunk_id > 0\n",
    "        overlap_with_next = chunk_id < len(raw_chunks) - 1\n",
    "        \n",
    "        # Calculate actual overlap amounts\n",
    "        if overlap_with_previous and chunk_id > 0:\n",
    "            prev_chunk = raw_chunks[chunk_id - 1]\n",
    "            # Find common substring\n",
    "            overlap_chars = 0\n",
    "            for i in range(1, min(len(prev_chunk), len(chunk_text)) + 1):\n",
    "                if prev_chunk[-i:] == chunk_text[:i]:\n",
    "                    overlap_chars = i\n",
    "            actual_prev_overlap = overlap_chars\n",
    "        else:\n",
    "            actual_prev_overlap = 0\n",
    "        \n",
    "        if overlap_with_next and chunk_id < len(raw_chunks) - 1:\n",
    "            next_chunk = raw_chunks[chunk_id + 1]\n",
    "            overlap_chars = 0\n",
    "            for i in range(1, min(len(chunk_text), len(next_chunk)) + 1):\n",
    "                if chunk_text[-i:] == next_chunk[:i]:\n",
    "                    overlap_chars = i\n",
    "            actual_next_overlap = overlap_chars\n",
    "        else:\n",
    "            actual_next_overlap = 0\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'char_count': len(chunk_text),\n",
    "            'word_count': len(chunk_text.split()),\n",
    "            'pages': sorted(list(pages)),\n",
    "            'sections': sorted(list(sections)),\n",
    "            'block_types': sorted(list(block_types)),\n",
    "            'num_source_blocks': len(overlapping_blocks),\n",
    "            'overlap_previous_chars': actual_prev_overlap,\n",
    "            'overlap_next_chars': actual_next_overlap,\n",
    "            'chunk_position': chunk_id + 1,\n",
    "            'total_chunks': len(raw_chunks),\n",
    "            'is_first': chunk_id == 0,\n",
    "            'is_last': chunk_id == len(raw_chunks) - 1,\n",
    "            'source': 'fintbx.pdf',\n",
    "            'chunking_method': 'fixed_size_overlap',\n",
    "            'chunk_size': chunk_size,\n",
    "            'chunk_overlap': chunk_overlap\n",
    "        }\n",
    "        \n",
    "        # Create chunk\n",
    "        chunk = FixedSizeChunk(\n",
    "            chunk_id=chunk_id,\n",
    "            content=chunk_text.strip(),\n",
    "            overlap_with_previous=overlap_with_previous,\n",
    "            overlap_with_next=overlap_with_next,\n",
    "            source_block_range=overlapping_blocks,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} fixed-size chunks with overlap\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d6e5343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Fixed-Size with Overlap Chunking...\n",
      "\n",
      "======================================================================\n",
      "Configuration 1: Standard (1000 chars, 200 overlap)\n",
      "======================================================================\n",
      "üìö Processing blocks for fixed-size chunking...\n",
      "üìè Chunk size: 1000 characters\n",
      "üîÑ Overlap: 200 characters (20.0%)\n",
      "üî™ Separators: 9 levels\n",
      "   Priority: '\\n\\n' > '\\n' > '. ' > '! '\n",
      "\n",
      "üìÑ Combined 431 blocks into 80,370 characters\n",
      "üóÇÔ∏è  Identified 49 unique sections\n",
      "\n",
      "‚úÇÔ∏è  Split into 104 chunks\n",
      "\n",
      "‚úÖ Created 104 fixed-size chunks with overlap\n",
      "\n",
      "‚úÖ Standard chunking complete!\n",
      "üìä Total chunks: 104\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Fixed-Size with Overlap Chunking...\\n\")\n",
    "\n",
    "# Configuration 1: Standard (1000 chars, 200 overlap)\n",
    "print(\"=\" * 70)\n",
    "print(\"Configuration 1: Standard (1000 chars, 200 overlap)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fixed_chunks_standard = chunk_fixed_size_with_overlap(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    skip_types=['figure'],\n",
    "    add_section_markers=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Standard chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(fixed_chunks_standard)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "143287bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Configuration 2: Large Chunks (1500 chars, 150 overlap)\n",
      "======================================================================\n",
      "üìö Processing blocks for fixed-size chunking...\n",
      "üìè Chunk size: 1500 characters\n",
      "üîÑ Overlap: 150 characters (10.0%)\n",
      "üî™ Separators: 9 levels\n",
      "   Priority: '\\n\\n' > '\\n' > '. ' > '! '\n",
      "\n",
      "üìÑ Combined 431 blocks into 80,370 characters\n",
      "üóÇÔ∏è  Identified 49 unique sections\n",
      "\n",
      "‚úÇÔ∏è  Split into 64 chunks\n",
      "\n",
      "‚úÖ Created 64 fixed-size chunks with overlap\n",
      "\n",
      "‚úÖ Large chunking complete!\n",
      "üìä Total chunks: 64\n",
      "\n",
      "======================================================================\n",
      "Configuration 3: Small Chunks (500 chars, 100 overlap)\n",
      "======================================================================\n",
      "üìö Processing blocks for fixed-size chunking...\n",
      "üìè Chunk size: 500 characters\n",
      "üîÑ Overlap: 100 characters (20.0%)\n",
      "üî™ Separators: 9 levels\n",
      "   Priority: '\\n\\n' > '\\n' > '. ' > '! '\n",
      "\n",
      "üìÑ Combined 431 blocks into 80,370 characters\n",
      "üóÇÔ∏è  Identified 49 unique sections\n",
      "\n",
      "‚úÇÔ∏è  Split into 235 chunks\n",
      "\n",
      "‚úÖ Created 235 fixed-size chunks with overlap\n",
      "\n",
      "‚úÖ Small chunking complete!\n",
      "üìä Total chunks: 235\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Configuration 2: Large Chunks (1500 chars, 150 overlap)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fixed_chunks_large = chunk_fixed_size_with_overlap(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    skip_types=['figure'],\n",
    "    add_section_markers=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Large chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(fixed_chunks_large)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Configuration 3: Small Chunks (500 chars, 100 overlap)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fixed_chunks_small = chunk_fixed_size_with_overlap(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    skip_types=['figure'],\n",
    "    add_section_markers=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Small chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(fixed_chunks_small)}\")\n",
    "\n",
    "# Use standard for rest of analysis\n",
    "fixed_chunks = fixed_chunks_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12b324f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä FIXED-SIZE CHUNK STATISTICS\n",
      "======================================================================\n",
      "Total Chunks: 104\n",
      "\n",
      "üìè Size Consistency:\n",
      "  Target Size:        1000 characters\n",
      "  Average Actual:     821 characters\n",
      "  Median Actual:      877 characters\n",
      "  Min Size:           4 characters\n",
      "  Max Size:           999 characters\n",
      "  Std Dev:            204 characters\n",
      "  Coefficient of Var: 24.88%\n",
      "\n",
      "üîÑ Overlap Analysis:\n",
      "  Target Overlap:     200 characters\n",
      "  Chunks with Overlap:104 (100.0%)\n",
      "  Avg Prev Overlap:   50 characters\n",
      "  Avg Next Overlap:   50 characters\n",
      "  Max Overlap:        199 characters\n",
      "\n",
      "üìÑ Coverage:\n",
      "  Avg Source Blocks:  5.1 blocks per chunk\n",
      "  Avg Sections:       1.5 sections per chunk\n",
      "  Multi-section:      35 chunks\n",
      "\n",
      "üìä Word Count Distribution:\n",
      "  Average Words:      120\n",
      "  Median Words:       130\n",
      "  Words Range:        2 - 263\n"
     ]
    }
   ],
   "source": [
    "def analyze_fixed_size_chunks(chunks: List[FixedSizeChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive statistics about fixed-size chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'has_overlap': chunk.has_overlap,\n",
    "            'overlap_prev': chunk.metadata.get('overlap_previous_chars', 0),\n",
    "            'overlap_next': chunk.metadata.get('overlap_next_chars', 0),\n",
    "            'pages': ', '.join(map(str, chunk.metadata.get('pages', []))),\n",
    "            'num_blocks': chunk.metadata.get('num_source_blocks', 0),\n",
    "            'sections': len(chunk.metadata.get('sections', [])),\n",
    "            'position': f\"{chunk.metadata['chunk_position']}/{chunk.metadata['total_chunks']}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä FIXED-SIZE CHUNK STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    \n",
    "    print(f\"\\nüìè Size Consistency:\")\n",
    "    print(f\"  Target Size:        {chunks[0].metadata['chunk_size']} characters\")\n",
    "    print(f\"  Average Actual:     {df['char_count'].mean():.0f} characters\")\n",
    "    print(f\"  Median Actual:      {df['char_count'].median():.0f} characters\")\n",
    "    print(f\"  Min Size:           {df['char_count'].min()} characters\")\n",
    "    print(f\"  Max Size:           {df['char_count'].max()} characters\")\n",
    "    print(f\"  Std Dev:            {df['char_count'].std():.0f} characters\")\n",
    "    print(f\"  Coefficient of Var: {(df['char_count'].std() / df['char_count'].mean()):.2%}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Overlap Analysis:\")\n",
    "    print(f\"  Target Overlap:     {chunks[0].metadata['chunk_overlap']} characters\")\n",
    "    print(f\"  Chunks with Overlap:{df['has_overlap'].sum()} ({df['has_overlap'].sum()/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"  Avg Prev Overlap:   {df['overlap_prev'].mean():.0f} characters\")\n",
    "    print(f\"  Avg Next Overlap:   {df['overlap_next'].mean():.0f} characters\")\n",
    "    print(f\"  Max Overlap:        {max(df['overlap_prev'].max(), df['overlap_next'].max())} characters\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Coverage:\")\n",
    "    print(f\"  Avg Source Blocks:  {df['num_blocks'].mean():.1f} blocks per chunk\")\n",
    "    print(f\"  Avg Sections:       {df['sections'].mean():.1f} sections per chunk\")\n",
    "    print(f\"  Multi-section:      {sum(1 for x in df['sections'] if x > 1)} chunks\")\n",
    "    \n",
    "    print(f\"\\nüìä Word Count Distribution:\")\n",
    "    print(f\"  Average Words:      {df['word_count'].mean():.0f}\")\n",
    "    print(f\"  Median Words:       {df['word_count'].median():.0f}\")\n",
    "    print(f\"  Words Range:        {df['word_count'].min()} - {df['word_count'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "fixed_stats_df = analyze_fixed_size_chunks(fixed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5025a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE FIXED-SIZE CHUNKS (with overlap visualization)\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 0 [1]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 819 chars, 111 words\n",
      "  Pages: [1, 2]\n",
      "  Sections: 3\n",
      "  Source Blocks: 18\n",
      "\n",
      "üîÑ Overlap Info:\n",
      "  Overlaps with Previous: False (0 chars)\n",
      "  Overlaps with Next:     True (0 chars)\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 1 [2]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 872 chars, 125 words\n",
      "  Pages: [2]\n",
      "  Sections: 1\n",
      "  Source Blocks: 1\n",
      "\n",
      "üîÑ Overlap Info:\n",
      "  Overlaps with Previous: True (0 chars)\n",
      "  Overlaps with Next:     True (0 chars)\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "CHUNK 2 [3]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 212 chars, 34 words\n",
      "  Pages: [2]\n",
      "  Sections: 1\n",
      "  Source Blocks: 1\n",
      "\n",
      "üîÑ Overlap Info:\n",
      "  Overlaps with Previous: True (0 chars)\n",
      "  Overlaps with Next:     True (0 chars)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_fixed_size_chunks(chunks: List[FixedSizeChunk], num_samples: int = 3):\n",
    "    \"\"\"Display sample chunks showing overlap behavior\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE FIXED-SIZE CHUNKS (with overlap visualization)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i in range(min(num_samples, len(chunks) - 1)):\n",
    "        chunk = chunks[i]\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"CHUNK {chunk.chunk_id} [{chunk.metadata['chunk_position']}]\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        print(f\"\\nüìä Stats:\")\n",
    "        print(f\"  Size: {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"  Pages: {chunk.metadata.get('pages', [])}\")\n",
    "        print(f\"  Sections: {len(chunk.metadata.get('sections', []))}\")\n",
    "        print(f\"  Source Blocks: {chunk.metadata.get('num_source_blocks', 0)}\")\n",
    "        \n",
    "        print(f\"\\nüîÑ Overlap Info:\")\n",
    "        print(f\"  Overlaps with Previous: {chunk.overlap_with_previous} ({chunk.metadata.get('overlap_previous_chars', 0)} chars)\")\n",
    "        print(f\"  Overlaps with Next:     {chunk.overlap_with_next} ({chunk.metadata.get('overlap_next_chars', 0)} chars)\")\n",
    "        \n",
    "        # Show overlap with next chunk\n",
    "        if chunk.overlap_with_next and i < len(chunks) - 1:\n",
    "            next_chunk = chunks[i + 1]\n",
    "            overlap_size = chunk.metadata.get('overlap_next_chars', 0)\n",
    "            \n",
    "            if overlap_size > 0:\n",
    "                print(f\"\\nüìù Content (showing overlap with next):\")\n",
    "                content_preview = chunk.content[:400]\n",
    "                print(f\"  Start: {content_preview}...\")\n",
    "                \n",
    "                overlap_text = chunk.content[-min(overlap_size, 100):]\n",
    "                print(f\"\\n  üîó Overlap region (last {min(overlap_size, 100)} chars):\")\n",
    "                print(f\"  \\\"{overlap_text}\\\"\")\n",
    "                \n",
    "                print(f\"\\n  ‚¨áÔ∏è  [This text continues in Chunk {chunk.chunk_id + 1}]\")\n",
    "        else:\n",
    "            print(f\"\\nüìù Content Preview:\")\n",
    "            print(f\"  {chunk.content[:400]}...\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Preview chunks showing overlap\n",
    "preview_fixed_size_chunks(fixed_chunks, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5818c078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "name": "Chunk Size",
         "nbinsx": 30,
         "type": "histogram",
         "x": {
          "bdata": "MwNoA9QA0QHmA5sB5wPlA+gAHwMFAwUDBQMFAwUDBQMFAwUDBQMFAwUBBADAA1YCsQP8AtMD0wPTA9MD0wPTA9cDwwNmA8kDwwPRAxID1gLkAmADjgPfA9QDbAPOAyoCyAPHA94DAgKbA2wDigLaA8cD9QDtAM0DswOzA7MDswOzA7MDtwOeA8oCegMCAzoDogNUA2wCzAO7Ar8CJANpA24DqwPhAtoDpQJ6A7kDMQLSA8IDnQO9A9kBgANoA2gDaANsA+MDowNaA9MDnQNVAw==",
          "dtype": "i2"
         },
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "green"
         },
         "name": "Overlap Size",
         "nbinsx": 20,
         "type": "histogram",
         "x": [
          199,
          199,
          195,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          169,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          3,
          164,
          163,
          17,
          192,
          104,
          176,
          74,
          25,
          141,
          196,
          127,
          194,
          153,
          49,
          133,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          196,
          64,
          136,
          76,
          54,
          193,
          175,
          68,
          44,
          175,
          162,
          61,
          101,
          34,
          23,
          20,
          18,
          40,
          103,
          190,
          1,
          1,
          1,
          1,
          175,
          191,
          188,
          199,
          199,
          195,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          169,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          3,
          164,
          163,
          17,
          192,
          104,
          176,
          74,
          25,
          141,
          196,
          127,
          194,
          153,
          49,
          133,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          196,
          64,
          136,
          76,
          54,
          193,
          175,
          68,
          44,
          175,
          162,
          61,
          101,
          34,
          23,
          20,
          18,
          40,
          103,
          190,
          1,
          1,
          1,
          1,
          175,
          191,
          188
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "purple"
         },
         "name": "Size Distribution",
         "type": "box",
         "xaxis": "x3",
         "y": {
          "bdata": "MwNoA9QA0QHmA5sB5wPlA+gAHwMFAwUDBQMFAwUDBQMFAwUDBQMFAwUBBADAA1YCsQP8AtMD0wPTA9MD0wPTA9cDwwNmA8kDwwPRAxID1gLkAmADjgPfA9QDbAPOAyoCyAPHA94DAgKbA2wDigLaA8cD9QDtAM0DswOzA7MDswOzA7MDtwOeA8oCegMCAzoDogNUA2wCzAO7Ar8CJANpA24DqwPhAtoDpQJ6A7kDMQLSA8IDnQO9A9kBgANoA2gDaANsA+MDowNaA9MDnQNVAw==",
          "dtype": "i2"
         },
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": {
           "bdata": "MwNoA9QA0QHmA5sB5wPlA+gAHwMFAwUDBQMFAwUDBQMFAwUDBQMFAwUBBADAA1YCsQP8AtMD0wPTA9MD0wPTA9cDwwNmA8kDwwPRAxID1gLkAmADjgPfA9QDbAPOAyoCyAPHA94DAgKbA2wDigLaA8cD9QDtAM0DswOzA7MDswOzA7MDtwOeA8oCegMCAzoDogNUA2wCzAO7Ar8CJANpA24DqwPhAtoDpQJ6A7kDMQLSA8IDnQO9A9kBgANoA2gDaANsA+MDowNaA9MDnQNVAw==",
           "dtype": "i2"
          },
          "colorbar": {
           "title": {
            "text": "Chars"
           }
          },
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "showscale": true,
          "size": 6
         },
         "mode": "markers",
         "name": "Chunks",
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmc=",
          "dtype": "i1"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "MwNoA9QA0QHmA5sB5wPlA+gAHwMFAwUDBQMFAwUDBQMFAwUDBQMFAwUBBADAA1YCsQP8AtMD0wPTA9MD0wPTA9cDwwNmA8kDwwPRAxID1gLkAmADjgPfA9QDbAPOAyoCyAPHA94DAgKbA2wDigLaA8cD9QDtAM0DswOzA7MDswOzA7MDtwOeA8oCegMCAzoDogNUA2wCzAO7Ar8CJANpA24DqwPhAtoDpQJ6A7kDMQLSA8IDnQO9A9kBgANoA2gDaANsA+MDowNaA9MDnQNVAw==",
          "dtype": "i2"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunk Size Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Overlap Distribution",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Size Consistency",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunks by Position",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "showarrow": false,
          "text": "Target: 1000",
          "x": 1000,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yanchor": "top",
          "yref": "y domain"
         },
         {
          "showarrow": false,
          "text": "Target: 200",
          "x": 200,
          "xanchor": "left",
          "xref": "x2",
          "y": 1,
          "yanchor": "top",
          "yref": "y2 domain"
         }
        ],
        "height": 800,
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 1000,
          "x1": 1000,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 200,
          "x1": 200,
          "xref": "x2",
          "y0": 0,
          "y1": 1,
          "yref": "y2 domain"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Fixed-Size with Overlap Chunking Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Characters"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Overlap (chars)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Chunk Position"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_fixed_size_chunks(chunks: List[FixedSizeChunk], stats_df: pd.DataFrame):\n",
    "    \"\"\"Visualize fixed-size chunking results\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Chunk Size Distribution',\n",
    "            'Overlap Distribution',\n",
    "            'Size Consistency',\n",
    "            'Chunks by Position'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'histogram'}, {'type': 'histogram'}],\n",
    "            [{'type': 'box'}, {'type': 'scatter'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Chunk size distribution\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=stats_df['char_count'],\n",
    "            nbinsx=30,\n",
    "            name='Chunk Size',\n",
    "            marker_color='blue'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    target_size = chunks[0].metadata['chunk_size']\n",
    "    fig.add_vline(x=target_size, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=f\"Target: {target_size}\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Characters\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "    \n",
    "    # 2. Overlap distribution\n",
    "    overlaps = list(stats_df['overlap_prev']) + list(stats_df['overlap_next'])\n",
    "    overlaps = [o for o in overlaps if o > 0]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=overlaps,\n",
    "            nbinsx=20,\n",
    "            name='Overlap Size',\n",
    "            marker_color='green'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    target_overlap = chunks[0].metadata['chunk_overlap']\n",
    "    fig.add_vline(x=target_overlap, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Target: {target_overlap}\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Overlap (chars)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "    \n",
    "    # 3. Size consistency (box plot)\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=stats_df['char_count'],\n",
    "            name='Size Distribution',\n",
    "            marker_color='purple'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=2, col=1)\n",
    "    \n",
    "    # 4. Size by position (to see if edges are different)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=stats_df.index,\n",
    "            y=stats_df['char_count'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=stats_df['char_count'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Chars\")\n",
    "            ),\n",
    "            name='Chunks'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Chunk Position\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Fixed-Size with Overlap Chunking Analysis\",\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_fixed_size_chunks(fixed_chunks, fixed_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95ddc476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CHUNK SIZE CONFIGURATION COMPARISON\n",
      "======================================================================\n",
      "\n",
      "          Configuration  Total Chunks  Avg Size  Std Dev  Avg Words  \\\n",
      "0      Small (500/100)           235     357.8    126.3       52.3   \n",
      "1  Standard (1000/200)           104     821.3    203.4      119.9   \n",
      "2     Large (1500/150)            64    1280.5    272.0      185.8   \n",
      "\n",
      "   Total Chars  \n",
      "0        84072  \n",
      "1        85419  \n",
      "2        81950  \n",
      "\n",
      "üí° Recommendations:\n",
      "  Small (500):    ‚úì Fine-grained retrieval, precise matching\n",
      "  Standard (1000): ‚úì Balanced, good for most embedding models\n",
      "  Large (1500):    ‚úì More context, fewer chunks, longer generation\n"
     ]
    }
   ],
   "source": [
    "def compare_chunk_sizes():\n",
    "    \"\"\"Compare the three configurations\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä CHUNK SIZE CONFIGURATION COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    configs = {\n",
    "        'Small (500/100)': fixed_chunks_small,\n",
    "        'Standard (1000/200)': fixed_chunks_standard,\n",
    "        'Large (1500/150)': fixed_chunks_large\n",
    "    }\n",
    "    \n",
    "    comparison = []\n",
    "    \n",
    "    for name, chunks in configs.items():\n",
    "        sizes = [len(c.content) for c in chunks]\n",
    "        comparison.append({\n",
    "            'Configuration': name,\n",
    "            'Total Chunks': len(chunks),\n",
    "            'Avg Size': np.mean(sizes),\n",
    "            'Std Dev': np.std(sizes),\n",
    "            'Avg Words': np.mean([len(c.content.split()) for c in chunks]),\n",
    "            'Total Chars': sum(sizes)\n",
    "        })\n",
    "    \n",
    "    comp_df = pd.DataFrame(comparison)\n",
    "    print(\"\\n\", comp_df.round(1))\n",
    "    \n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    print(f\"  Small (500):    ‚úì Fine-grained retrieval, precise matching\")\n",
    "    print(f\"  Standard (1000): ‚úì Balanced, good for most embedding models\")\n",
    "    print(f\"  Large (1500):    ‚úì More context, fewer chunks, longer generation\")\n",
    "\n",
    "# Run comparison\n",
    "compare_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c50d3b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved 104 chunks to: ../data/chunks/fixed_overlap_chunks.jsonl\n",
      "üìã Saved summary to: ../data/chunks/fixed_overlap_chunks_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_fixed_size_chunks(chunks: List[FixedSizeChunk], output_path: str):\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk.to_dict(), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüíæ Saved {len(chunks)} chunks to: {output_path}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = output_path.replace('.jsonl', '_summary.json')\n",
    "    \n",
    "    sizes = [len(c.content) for c in chunks]\n",
    "    overlaps = [c.metadata.get('overlap_previous_chars', 0) + c.metadata.get('overlap_next_chars', 0) \n",
    "                for c in chunks]\n",
    "    \n",
    "    summary = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'chunking_method': 'fixed_size_with_overlap',\n",
    "        'configuration': {\n",
    "            'chunk_size': chunks[0].metadata['chunk_size'],\n",
    "            'chunk_overlap': chunks[0].metadata['chunk_overlap']\n",
    "        },\n",
    "        'statistics': {\n",
    "            'avg_size': np.mean(sizes),\n",
    "            'median_size': np.median(sizes),\n",
    "            'std_size': np.std(sizes),\n",
    "            'min_size': min(sizes),\n",
    "            'max_size': max(sizes),\n",
    "            'avg_overlap': np.mean([o for o in overlaps if o > 0]),\n",
    "            'chunks_with_overlap': sum(1 for c in chunks if c.has_overlap),\n",
    "            'avg_words': np.mean([len(c.content.split()) for c in chunks]),\n",
    "            'total_characters': sum(sizes)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìã Saved summary to: {summary_path}\")\n",
    "\n",
    "# Save the chunks (standard configuration)\n",
    "save_fixed_size_chunks(fixed_chunks, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bf0af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Exported 104 chunks for embedding: ../data/chunks/fixed_overlap_chunks_for_embedding.jsonl\n",
      "üìù Consistent sizes ideal for embedding models\n",
      "üîÑ Overlap preserves context between chunks\n"
     ]
    }
   ],
   "source": [
    "def export_fixed_size_for_embedding(chunks: List[FixedSizeChunk], output_path: str):\n",
    "    \"\"\"\n",
    "    Export fixed-size chunks for embedding generation.\n",
    "    These are ideal for embedding models that expect consistent sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.content,\n",
    "                'metadata': {\n",
    "                    'chunk_position': chunk.metadata['chunk_position'],\n",
    "                    'total_chunks': chunk.metadata['total_chunks'],\n",
    "                    'char_count': len(chunk.content),\n",
    "                    'word_count': len(chunk.content.split()),\n",
    "                    'has_overlap': chunk.has_overlap,\n",
    "                    'pages': chunk.metadata.get('pages', []),\n",
    "                    'sections': chunk.metadata.get('sections', []),\n",
    "                    'is_first': chunk.metadata.get('is_first', False),\n",
    "                    'is_last': chunk.metadata.get('is_last', False),\n",
    "                    'source': 'fintbx.pdf'\n",
    "                }\n",
    "            }\n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "    print(f\"üìù Consistent sizes ideal for embedding models\")\n",
    "    print(f\"üîÑ Overlap preserves context between chunks\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_fixed_size_for_embedding(fixed_chunks, OUTPUT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f729fb3",
   "metadata": {},
   "source": [
    "#### üéØ **Key Features of Fixed-Size with Overlap:**\n",
    "\n",
    "1. **Consistent Sizes**: All chunks close to target size (important for many embedding models)\n",
    "2. **Context Overlap**: Prevents information loss at chunk boundaries\n",
    "3. **Intelligent Splitting**: Uses RecursiveCharacterTextSplitter to break at semantic boundaries\n",
    "4. **Traceability**: Maps chunks back to source blocks\n",
    "5. **Configurable**: Easy to adjust size and overlap for different use cases\n",
    "\n",
    " üìä **Overlap Benefits:**\n",
    "\n",
    "- **Context Preservation**: Adjacent chunks share text, maintaining continuity\n",
    "- **Better Retrieval**: Related concepts aren't split between chunks\n",
    "- **Redundancy**: Same information in multiple chunks increases recall\n",
    "\n",
    "‚öôÔ∏è **Configuration Recommendations:**\n",
    "\n",
    "- **Small (500/100)**: Precise retrieval, question answering\n",
    "- **Standard (1000/200)**: Balanced, works for most embedding models\n",
    "- **Large (1500/150)**: More context, fewer chunks, RAG generation\n",
    "\n",
    "This is the **most popular chunking method** for RAG systems with embedding models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6427ae",
   "metadata": {},
   "source": [
    "### Method 5: Semantic Chunking by Page üìÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "508ccaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Page-Based Chunking Setup\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Paths\n",
    "CLEANED_DATA_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/page_based_chunks.jsonl'\n",
    "OUTPUT_EMBEDDING_PATH = '../data/chunks/page_based_chunks_for_embedding.jsonl'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51c458bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Page-Based Chunk Data Structure\n",
    "@dataclass\n",
    "class PageBasedChunk:\n",
    "    \"\"\"\n",
    "    Represents a chunk created from page content.\n",
    "    \"\"\"\n",
    "    chunk_id: int\n",
    "    page_number: int\n",
    "    content: str\n",
    "    is_split_page: bool  # True if page was split into multiple chunks\n",
    "    split_index: Optional[int]  # Index if this is part of a split page\n",
    "    total_splits: Optional[int]  # Total splits for this page\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    @property\n",
    "    def page_reference(self):\n",
    "        \"\"\"Human-readable page reference\"\"\"\n",
    "        if self.is_split_page:\n",
    "            return f\"Page {self.page_number} (part {self.split_index + 1}/{self.total_splits})\"\n",
    "        return f\"Page {self.page_number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6b8afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_page(\n",
    "    jsonl_path: str,\n",
    "    max_chunk_size: int = 3000,\n",
    "    split_large_pages: bool = True,\n",
    "    split_overlap: int = 200,\n",
    "    preserve_page_headers: bool = True,\n",
    "    skip_types: List[str] = ['figure']\n",
    ") -> List[PageBasedChunk]:\n",
    "    \"\"\"\n",
    "    Create chunks grouped by page number.\n",
    "    \n",
    "    This method:\n",
    "    - Groups all content from each page together\n",
    "    - Maintains perfect page-level citation\n",
    "    - Optionally splits large pages into multiple chunks\n",
    "    - Preserves document order\n",
    "    - Easy to trace back to source PDF\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to cleaned JSONL file\n",
    "        max_chunk_size: Maximum chunk size (splits page if exceeded)\n",
    "        split_large_pages: Whether to split pages that exceed max_chunk_size\n",
    "        split_overlap: Overlap between splits of the same page\n",
    "        preserve_page_headers: Add page number as header\n",
    "        skip_types: Block types to skip\n",
    "    \n",
    "    Returns:\n",
    "        List of PageBasedChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üìö Processing blocks for page-based chunking...\")\n",
    "    print(f\"üìÑ Max page size: {max_chunk_size} characters\")\n",
    "    print(f\"‚úÇÔ∏è  Split large pages: {split_large_pages}\")\n",
    "    if split_large_pages:\n",
    "        print(f\"üîÑ Split overlap: {split_overlap} characters\")\n",
    "    print()\n",
    "    \n",
    "    # Load blocks\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    # Sort by page and block_id\n",
    "    blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "    \n",
    "    # Group blocks by page\n",
    "    pages = {}\n",
    "    for block in blocks:\n",
    "        page_num = block.get('page', 0)\n",
    "        if page_num not in pages:\n",
    "            pages[page_num] = []\n",
    "        pages[page_num].append(block)\n",
    "    \n",
    "    print(f\"üìñ Found {len(pages)} pages\")\n",
    "    print(f\"üìä Page range: {min(pages.keys())} to {max(pages.keys())}\\n\")\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in sorted(pages.keys()):\n",
    "        page_blocks = pages[page_num]\n",
    "        \n",
    "        # Build page content\n",
    "        page_content = []\n",
    "        page_metadata = {\n",
    "            'block_ids': [],\n",
    "            'block_types': set(),\n",
    "            'sections': set(),\n",
    "            'num_blocks': 0,\n",
    "            'has_tables': False,\n",
    "            'has_code': False,\n",
    "            'has_equations': False,\n",
    "            'has_lists': False\n",
    "        }\n",
    "        \n",
    "        for block in page_blocks:\n",
    "            block_type = block.get('type', 'unknown')\n",
    "            block_id = block.get('block_id')\n",
    "            text = block.get('text', '').strip()\n",
    "            section = block.get('section_path', '')\n",
    "            \n",
    "            # Skip certain types\n",
    "            if block_type in skip_types or not text:\n",
    "                continue\n",
    "            \n",
    "            # Format based on type\n",
    "            if block_type == 'heading':\n",
    "                heading_level = block.get('heading_level', 1)\n",
    "                formatted_text = f\"\\n{'#' * (heading_level + 1)} {text}\\n\"\n",
    "                \n",
    "            elif block_type == 'table':\n",
    "                page_metadata['has_tables'] = True\n",
    "                caption = block.get('caption', 'Table')\n",
    "                num_rows = block.get('num_rows', 0)\n",
    "                num_cols = block.get('num_cols', 0)\n",
    "                formatted_text = f\"\\n#### {caption} ({num_rows}√ó{num_cols})\\n```\\n{text}\\n```\\n\"\n",
    "                \n",
    "            elif block_type == 'code':\n",
    "                page_metadata['has_code'] = True\n",
    "                formatted_text = f\"\\n```\\n{text}\\n```\\n\"\n",
    "                \n",
    "            elif block_type == 'equation':\n",
    "                page_metadata['has_equations'] = True\n",
    "                formatted_text = f\"\\n$$\\n{text}\\n$$\\n\"\n",
    "                \n",
    "            elif block_type == 'list':\n",
    "                page_metadata['has_lists'] = True\n",
    "                formatted_text = f\"\\n{text}\\n\"\n",
    "                \n",
    "            else:  # paragraph\n",
    "                formatted_text = f\"{text}\\n\"\n",
    "            \n",
    "            page_content.append(formatted_text)\n",
    "            page_metadata['block_ids'].append(block_id)\n",
    "            page_metadata['block_types'].add(block_type)\n",
    "            if section:\n",
    "                page_metadata['sections'].add(section)\n",
    "            page_metadata['num_blocks'] += 1\n",
    "        \n",
    "        # Combine page content\n",
    "        combined_content = '\\n'.join(page_content).strip()\n",
    "        \n",
    "        if not combined_content:\n",
    "            continue  # Skip empty pages\n",
    "        \n",
    "        # Add page header if requested\n",
    "        if preserve_page_headers:\n",
    "            page_header = f\"# Page {page_num}\\n\\n\"\n",
    "            combined_content = page_header + combined_content\n",
    "        \n",
    "        # Check if page needs splitting\n",
    "        if split_large_pages and len(combined_content) > max_chunk_size:\n",
    "            # Split this page into multiple chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=max_chunk_size,\n",
    "                chunk_overlap=split_overlap,\n",
    "                length_function=len,\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "                keep_separator=True\n",
    "            )\n",
    "            \n",
    "            page_splits = text_splitter.split_text(combined_content)\n",
    "            \n",
    "            # Create multiple chunks for this page\n",
    "            for split_idx, split_text in enumerate(page_splits):\n",
    "                metadata = {\n",
    "                    'page': page_num,\n",
    "                    'block_ids': page_metadata['block_ids'].copy(),\n",
    "                    'block_types': list(page_metadata['block_types']),\n",
    "                    'sections': list(page_metadata['sections']),\n",
    "                    'num_blocks': page_metadata['num_blocks'],\n",
    "                    'has_tables': page_metadata['has_tables'],\n",
    "                    'has_code': page_metadata['has_code'],\n",
    "                    'has_equations': page_metadata['has_equations'],\n",
    "                    'has_lists': page_metadata['has_lists'],\n",
    "                    'char_count': len(split_text),\n",
    "                    'word_count': len(split_text.split()),\n",
    "                    'is_split': True,\n",
    "                    'split_index': split_idx,\n",
    "                    'total_splits': len(page_splits),\n",
    "                    'original_page_size': len(combined_content),\n",
    "                    'source': 'fintbx.pdf',\n",
    "                    'chunking_method': 'page_based'\n",
    "                }\n",
    "                \n",
    "                chunk = PageBasedChunk(\n",
    "                    chunk_id=chunk_id,\n",
    "                    page_number=page_num,\n",
    "                    content=split_text.strip(),\n",
    "                    is_split_page=True,\n",
    "                    split_index=split_idx,\n",
    "                    total_splits=len(page_splits),\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                chunks.append(chunk)\n",
    "                chunk_id += 1\n",
    "        \n",
    "        else:\n",
    "            # Single chunk for this page\n",
    "            metadata = {\n",
    "                'page': page_num,\n",
    "                'block_ids': page_metadata['block_ids'],\n",
    "                'block_types': list(page_metadata['block_types']),\n",
    "                'sections': list(page_metadata['sections']),\n",
    "                'num_blocks': page_metadata['num_blocks'],\n",
    "                'has_tables': page_metadata['has_tables'],\n",
    "                'has_code': page_metadata['has_code'],\n",
    "                'has_equations': page_metadata['has_equations'],\n",
    "                'has_lists': page_metadata['has_lists'],\n",
    "                'char_count': len(combined_content),\n",
    "                'word_count': len(combined_content.split()),\n",
    "                'is_split': False,\n",
    "                'source': 'fintbx.pdf',\n",
    "                'chunking_method': 'page_based'\n",
    "            }\n",
    "            \n",
    "            chunk = PageBasedChunk(\n",
    "                chunk_id=chunk_id,\n",
    "                page_number=page_num,\n",
    "                content=combined_content.strip(),\n",
    "                is_split_page=False,\n",
    "                split_index=None,\n",
    "                total_splits=None,\n",
    "                metadata=metadata\n",
    "            )\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "            chunk_id += 1\n",
    "    \n",
    "    # Statistics\n",
    "    split_pages = sum(1 for c in chunks if c.is_split_page)\n",
    "    unique_pages = len(set(c.page_number for c in chunks))\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} chunks from {unique_pages} pages\")\n",
    "    print(f\"üìÑ Whole pages: {unique_pages - len([p for p in pages if any(c.page_number == p and c.is_split_page for c in chunks)])}\")\n",
    "    print(f\"‚úÇÔ∏è  Split pages: {len(set(c.page_number for c in chunks if c.is_split_page))}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "337e5fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Page-Based Chunking...\n",
      "\n",
      "üìö Processing blocks for page-based chunking...\n",
      "üìÑ Max page size: 3000 characters\n",
      "‚úÇÔ∏è  Split large pages: True\n",
      "üîÑ Split overlap: 200 characters\n",
      "\n",
      "üìñ Found 28 pages\n",
      "üìä Page range: 1 to 29\n",
      "\n",
      "‚úÖ Created 43 chunks from 28 pages\n",
      "üìÑ Whole pages: 22\n",
      "‚úÇÔ∏è  Split pages: 6\n",
      "\n",
      "‚úÖ Page-based chunking complete!\n",
      "üìä Total chunks: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Page-Based Chunking...\\n\")\n",
    "\n",
    "page_chunks = chunk_by_page(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    max_chunk_size=3000,\n",
    "    split_large_pages=True,\n",
    "    split_overlap=200,\n",
    "    preserve_page_headers=True,\n",
    "    skip_types=['figure']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Page-based chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(page_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8eaa16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PAGE-BASED CHUNK STATISTICS\n",
      "======================================================================\n",
      "Total Chunks: 43\n",
      "\n",
      "üìÑ Page Coverage:\n",
      "  Unique Pages:       28\n",
      "  Page Range:         1 to 29\n",
      "  Avg Chunks/Page:    1.54\n",
      "\n",
      "‚úÇÔ∏è  Page Splitting:\n",
      "  Whole Pages:        22 (78.6%)\n",
      "  Split Pages:        6 (21.4%)\n",
      "  Split Chunks:       21\n",
      "\n",
      "  Pages requiring splits:\n",
      "    Page 3: 2 chunks\n",
      "    Page 4: 5 chunks\n",
      "    Page 6: 4 chunks\n",
      "    Page 18: 4 chunks\n",
      "    Page 27: 4 chunks\n",
      "    Page 28: 2 chunks\n",
      "\n",
      "üìè Size Distribution:\n",
      "  Average Characters: 1851\n",
      "  Median Characters:  2030\n",
      "  Min Characters:     8\n",
      "  Max Characters:     2976\n",
      "  Std Dev:            936\n",
      "\n",
      "üìù Content Distribution:\n",
      "  Avg Blocks/Chunk:   13.0\n",
      "  Avg Sections/Chunk: 2.1\n",
      "  Chunks with Tables: 24\n",
      "  Chunks with Code:   18\n",
      "  Chunks with Equations: 0\n",
      "\n",
      "üîù Top 5 Largest Chunks:\n",
      "    chunk_id            page_ref  char_count  word_count  is_split\n",
      "11        11   Page 6 (part 2/4)        2976         354      True\n",
      "37        37  Page 27 (part 2/4)        2940         173      True\n",
      "12        12   Page 6 (part 3/4)        2939         403      True\n",
      "40        40  Page 28 (part 1/2)        2928         451      True\n",
      "25        25  Page 18 (part 2/4)        2876         202      True\n"
     ]
    }
   ],
   "source": [
    "def analyze_page_chunks(chunks: List[PageBasedChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive statistics about page-based chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'page': chunk.page_number,\n",
    "            'page_ref': chunk.page_reference,\n",
    "            'is_split': chunk.is_split_page,\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'num_blocks': chunk.metadata.get('num_blocks', 0),\n",
    "            'num_sections': len(chunk.metadata.get('sections', [])),\n",
    "            'has_tables': chunk.metadata.get('has_tables', False),\n",
    "            'has_code': chunk.metadata.get('has_code', False),\n",
    "            'has_equations': chunk.metadata.get('has_equations', False),\n",
    "            'block_types': ', '.join(sorted(chunk.metadata.get('block_types', [])))\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä PAGE-BASED CHUNK STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Page Coverage:\")\n",
    "    unique_pages = df['page'].nunique()\n",
    "    page_range = f\"{df['page'].min()} to {df['page'].max()}\"\n",
    "    print(f\"  Unique Pages:       {unique_pages}\")\n",
    "    print(f\"  Page Range:         {page_range}\")\n",
    "    print(f\"  Avg Chunks/Page:    {len(chunks) / unique_pages:.2f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÇÔ∏è  Page Splitting:\")\n",
    "    split_count = df['is_split'].sum()\n",
    "    split_pages = df[df['is_split']]['page'].nunique()\n",
    "    whole_pages = unique_pages - split_pages\n",
    "    print(f\"  Whole Pages:        {whole_pages} ({whole_pages/unique_pages*100:.1f}%)\")\n",
    "    print(f\"  Split Pages:        {split_pages} ({split_pages/unique_pages*100:.1f}%)\")\n",
    "    print(f\"  Split Chunks:       {split_count}\")\n",
    "    \n",
    "    if split_pages > 0:\n",
    "        print(f\"\\n  Pages requiring splits:\")\n",
    "        split_page_stats = df[df['is_split']].groupby('page').size()\n",
    "        for page, count in split_page_stats.items():\n",
    "            print(f\"    Page {page}: {count} chunks\")\n",
    "    \n",
    "    print(f\"\\nüìè Size Distribution:\")\n",
    "    print(f\"  Average Characters: {df['char_count'].mean():.0f}\")\n",
    "    print(f\"  Median Characters:  {df['char_count'].median():.0f}\")\n",
    "    print(f\"  Min Characters:     {df['char_count'].min()}\")\n",
    "    print(f\"  Max Characters:     {df['char_count'].max()}\")\n",
    "    print(f\"  Std Dev:            {df['char_count'].std():.0f}\")\n",
    "    \n",
    "    print(f\"\\nüìù Content Distribution:\")\n",
    "    print(f\"  Avg Blocks/Chunk:   {df['num_blocks'].mean():.1f}\")\n",
    "    print(f\"  Avg Sections/Chunk: {df['num_sections'].mean():.1f}\")\n",
    "    print(f\"  Chunks with Tables: {df['has_tables'].sum()}\")\n",
    "    print(f\"  Chunks with Code:   {df['has_code'].sum()}\")\n",
    "    print(f\"  Chunks with Equations: {df['has_equations'].sum()}\")\n",
    "    \n",
    "    print(f\"\\nüîù Top 5 Largest Chunks:\")\n",
    "    print(df.nlargest(5, 'char_count')[['chunk_id', 'page_ref', 'char_count', 'word_count', 'is_split']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "page_stats_df = analyze_page_chunks(page_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6e8f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE PAGE-BASED CHUNKS\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[WHOLE PAGE] CHUNK 0 - Page 1\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Page Info:\n",
      "  Page Number:    1\n",
      "  Is Split:       False\n",
      "\n",
      "üìä Content Stats:\n",
      "  Size:           67 chars, 13 words\n",
      "  Blocks:         3\n",
      "  Sections:       2\n",
      "  Block Types:    heading, paragraph\n",
      "\n",
      "üìã Special Content:\n",
      "  Tables:    False\n",
      "  Code:      False\n",
      "  Equations: False\n",
      "\n",
      "üìù Content Preview (first 350 chars):\n",
      "  # Page 1\n",
      "\n",
      "## Financial Toolbox‚Ñ¢ User's Guide\n",
      "\n",
      "\n",
      "## MATLAB¬Æ\n",
      "\n",
      "R 2025 b\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[SPLIT PAGE (Part 1)] CHUNK 2 - Page 3 (part 1/2)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Page Info:\n",
      "  Page Number:    3\n",
      "  Is Split:       True\n",
      "  Split Position: Part 1 of 2\n",
      "  Original Size:  3077 chars\n",
      "\n",
      "üìä Content Stats:\n",
      "  Size:           1241 chars, 198 words\n",
      "  Blocks:         3\n",
      "  Sections:       1\n",
      "  Block Types:    heading, paragraph\n",
      "\n",
      "üìã Special Content:\n",
      "  Tables:    False\n",
      "  Code:      False\n",
      "  Equations: False\n",
      "\n",
      "üìù Content Preview (first 350 chars):\n",
      "  # Page 3\n",
      "\n",
      "## Revision History\n",
      "\n",
      "October 1995 First printing January 1998 Second printing January 1999 Third printing November 2000 Fourth printing May 2003 Online only June 2004 Online only August 2004 Online only September 2005 Fifth printing March 2006 Online only September 2006 Sixth printing March 2007 Online only September 2007 Online only Marc...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[SPLIT PAGE (Part 2)] CHUNK 3 - Page 3 (part 2/2)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Page Info:\n",
      "  Page Number:    3\n",
      "  Is Split:       True\n",
      "  Split Position: Part 2 of 2\n",
      "  Original Size:  3077 chars\n",
      "\n",
      "üìä Content Stats:\n",
      "  Size:           1834 chars, 275 words\n",
      "  Blocks:         3\n",
      "  Sections:       1\n",
      "  Block Types:    heading, paragraph\n",
      "\n",
      "üìã Special Content:\n",
      "  Tables:    False\n",
      "  Code:      False\n",
      "  Equations: False\n",
      "\n",
      "üìù Content Preview (first 350 chars):\n",
      "  Revised for Version 1.1 Revised for Version 2.0 (Release 11) Revised for Version 2.1.2 (Release 12) Revised for Version 2.3 (Release 13) Revised for Version 2.4 (Release 14) Revised for Version 2.4.1 (Release 14+) Revised for Version 2.5 (Release 14SP3) Revised for Version 3.0 (Release 2006a) Revised for Version 3.1 (Release 2006b) Revised for Vers...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[SAMPLE] CHUNK 1 - Page 2\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Page Info:\n",
      "  Page Number:    2\n",
      "  Is Split:       False\n",
      "\n",
      "üìä Content Stats:\n",
      "  Size:           2164 chars, 303 words\n",
      "  Blocks:         20\n",
      "  Sections:       3\n",
      "  Block Types:    heading, paragraph\n",
      "\n",
      "üìã Special Content:\n",
      "  Tables:    False\n",
      "  Code:      False\n",
      "  Equations: False\n",
      "\n",
      "üìù Content Preview (first 350 chars):\n",
      "  # Page 2\n",
      "\n",
      "## How to Contact MathWorks\n",
      "\n",
      "Latest news:\n",
      "\n",
      "www.mathworks.com\n",
      "\n",
      "Sales and services:\n",
      "\n",
      "www.mathworks.com/sales_and_services\n",
      "\n",
      "User community:\n",
      "\n",
      "www.mathworks.com/matlabcentral\n",
      "\n",
      "Technical support:\n",
      "\n",
      "www.mathworks.com/support/contact_us\n",
      "\n",
      "Phone:\n",
      "\n",
      "508-647-7000\n",
      "\n",
      "The MathWorks, Inc. 1 Apple Hill Drive Natick, MA 01760-2098\n",
      "\n",
      "Financial Toolbox‚Ñ¢ User's G...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_page_chunks(chunks: List[PageBasedChunk], num_samples: int = 4):\n",
    "    \"\"\"Display sample chunks including whole and split pages\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE PAGE-BASED CHUNKS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get diverse samples\n",
    "    whole_page_chunks = [c for c in chunks if not c.is_split_page]\n",
    "    split_page_chunks = [c for c in chunks if c.is_split_page]\n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    # Add examples of both types\n",
    "    if whole_page_chunks:\n",
    "        samples.append(('WHOLE PAGE', whole_page_chunks[0]))\n",
    "    if split_page_chunks:\n",
    "        # Get first split and next split from same page\n",
    "        first_split = split_page_chunks[0]\n",
    "        samples.append(('SPLIT PAGE (Part 1)', first_split))\n",
    "        # Find next part of same page\n",
    "        same_page_splits = [c for c in split_page_chunks \n",
    "                           if c.page_number == first_split.page_number \n",
    "                           and c.split_index == first_split.split_index + 1]\n",
    "        if same_page_splits:\n",
    "            samples.append(('SPLIT PAGE (Part 2)', same_page_splits[0]))\n",
    "    \n",
    "    # Add a few more diverse examples\n",
    "    for chunk in chunks[1:3]:\n",
    "        samples.append(('SAMPLE', chunk))\n",
    "    \n",
    "    for label, chunk in samples[:num_samples]:\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"[{label}] CHUNK {chunk.chunk_id} - {chunk.page_reference}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        print(f\"\\nüìÑ Page Info:\")\n",
    "        print(f\"  Page Number:    {chunk.page_number}\")\n",
    "        print(f\"  Is Split:       {chunk.is_split_page}\")\n",
    "        if chunk.is_split_page:\n",
    "            print(f\"  Split Position: Part {chunk.split_index + 1} of {chunk.total_splits}\")\n",
    "            print(f\"  Original Size:  {chunk.metadata.get('original_page_size', 0)} chars\")\n",
    "        \n",
    "        print(f\"\\nüìä Content Stats:\")\n",
    "        print(f\"  Size:           {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"  Blocks:         {chunk.metadata.get('num_blocks', 0)}\")\n",
    "        print(f\"  Sections:       {len(chunk.metadata.get('sections', []))}\")\n",
    "        print(f\"  Block Types:    {', '.join(chunk.metadata.get('block_types', []))}\")\n",
    "        \n",
    "        print(f\"\\nüìã Special Content:\")\n",
    "        print(f\"  Tables:    {chunk.metadata.get('has_tables', False)}\")\n",
    "        print(f\"  Code:      {chunk.metadata.get('has_code', False)}\")\n",
    "        print(f\"  Equations: {chunk.metadata.get('has_equations', False)}\")\n",
    "        \n",
    "        print(f\"\\nüìù Content Preview (first 350 chars):\")\n",
    "        preview = chunk.content[:350]\n",
    "        if len(chunk.content) > 350:\n",
    "            preview += \"...\"\n",
    "        print(f\"  {preview}\")\n",
    "        print()\n",
    "\n",
    "# Preview diverse samples\n",
    "preview_page_chunks(page_chunks, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb68404f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "blue",
           "blue",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "blue"
          ],
          "opacity": 0.6,
          "size": 8
         },
         "mode": "markers",
         "name": "Chunks",
         "text": [
          "Page 1",
          "Page 2",
          "Page 3 (part 1/2)",
          "Page 3 (part 2/2)",
          "Page 4 (part 1/5)",
          "Page 4 (part 2/5)",
          "Page 4 (part 3/5)",
          "Page 4 (part 4/5)",
          "Page 4 (part 5/5)",
          "Page 5",
          "Page 6 (part 1/4)",
          "Page 6 (part 2/4)",
          "Page 6 (part 3/4)",
          "Page 6 (part 4/4)",
          "Page 7",
          "Page 8",
          "Page 9",
          "Page 10",
          "Page 11",
          "Page 12",
          "Page 13",
          "Page 15",
          "Page 16",
          "Page 17",
          "Page 18 (part 1/4)",
          "Page 18 (part 2/4)",
          "Page 18 (part 3/4)",
          "Page 18 (part 4/4)",
          "Page 19",
          "Page 20",
          "Page 21",
          "Page 22",
          "Page 23",
          "Page 24",
          "Page 25",
          "Page 26",
          "Page 27 (part 1/4)",
          "Page 27 (part 2/4)",
          "Page 27 (part 3/4)",
          "Page 27 (part 4/4)",
          "Page 28 (part 1/2)",
          "Page 28 (part 2/2)",
          "Page 29"
         ],
         "type": "scatter",
         "x": {
          "bdata": "AQIDAwQEBAQEBQYGBgYHCAkKCwwNDxAREhISEhMUFRYXGBkaGxsbGxwcHQ==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "QwB0CNkEKgcIADYLFQsVCwUBGwkLAKALewu2BkkGmglZBX4G7gdoCGoFOwkiBi4KCQA8CxsLawfGCQEKgQowCLYEyQkRC7EFHgV8C7IFsgFwC7QBJAU=",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0.625,
           1
          ]
         },
         "labels": [
          "Whole Pages",
          "Split Pages"
         ],
         "marker": {
          "colors": [
           "green",
           "orange"
          ]
         },
         "type": "pie",
         "values": [
          22,
          21
         ]
        },
        {
         "marker": {
          "color": "purple"
         },
         "name": "Chunks/Page",
         "nbinsx": 10,
         "type": "histogram",
         "x": {
          "bdata": "AQECBQEEAQEBAQEBAQEBAQQBAQEBAQEBAQQCAQ==",
          "dtype": "i1"
         },
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           "blue",
           "green",
           "red",
           "gray"
          ]
         },
         "type": "bar",
         "x": [
          "Tables",
          "Code",
          "Equations",
          "Text Only"
         ],
         "xaxis": "x3",
         "y": [
          24,
          18,
          0,
          8
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunk Size by Page",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Whole vs Split Pages",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunks per Page Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Content Type Distribution",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Page-Based Chunking Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Page Number"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Chunks per Page"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Content Type"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Number of Pages"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Number of Chunks"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_page_chunks(chunks: List[PageBasedChunk], stats_df: pd.DataFrame):\n",
    "    \"\"\"Visualize page-based chunking results\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Chunk Size by Page',\n",
    "            'Whole vs Split Pages',\n",
    "            'Chunks per Page Distribution',\n",
    "            'Content Type Distribution'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'scatter'}, {'type': 'pie'}],\n",
    "            [{'type': 'histogram'}, {'type': 'bar'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Chunk size by page\n",
    "    colors = ['red' if split else 'blue' for split in stats_df['is_split']]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=stats_df['page'],\n",
    "            y=stats_df['char_count'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=colors,\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            text=stats_df['page_ref'],\n",
    "            name='Chunks'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Page Number\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=1, col=1)\n",
    "    \n",
    "    # 2. Whole vs Split\n",
    "    split_counts = {\n",
    "        'Whole Pages': (~stats_df['is_split']).sum(),\n",
    "        'Split Pages': stats_df['is_split'].sum()\n",
    "    }\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(split_counts.keys()),\n",
    "            values=list(split_counts.values()),\n",
    "            marker_colors=['green', 'orange']\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Chunks per page distribution\n",
    "    chunks_per_page = stats_df.groupby('page').size()\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=chunks_per_page.values,\n",
    "            nbinsx=10,\n",
    "            name='Chunks/Page',\n",
    "            marker_color='purple'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Chunks per Page\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Pages\", row=2, col=1)\n",
    "    \n",
    "    # 4. Content type distribution\n",
    "    content_types = {\n",
    "        'Tables': stats_df['has_tables'].sum(),\n",
    "        'Code': stats_df['has_code'].sum(),\n",
    "        'Equations': stats_df['has_equations'].sum(),\n",
    "        'Text Only': len(stats_df) - stats_df[['has_tables', 'has_code', 'has_equations']].any(axis=1).sum()\n",
    "    }\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(content_types.keys()),\n",
    "            y=list(content_types.values()),\n",
    "            marker_color=['blue', 'green', 'red', 'gray']\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Content Type\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Number of Chunks\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Page-Based Chunking Analysis\",\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_page_chunks(page_chunks, page_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca6c1dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ PAGE-LEVEL STATISTICS\n",
      "======================================================================\n",
      "\n",
      "üìè Page Size Distribution:\n",
      "  Average: 2843 chars\n",
      "  Median:  2347 chars\n",
      "  Min:     67 chars\n",
      "  Max:     8813 chars\n",
      "\n",
      "üîù Top 5 Largest Pages:\n",
      "  Page 4: 8,813 chars, 5 chunk(s), 1 section(s)\n",
      "  Page 6: 7,644 chars, 4 chunk(s), 1 section(s)\n",
      "  Page 18: 7,627 chars, 4 chunk(s), 1 section(s)\n",
      "  Page 27: 6,142 chars, 4 chunk(s), 2 section(s)\n",
      "  Page 28: 3,364 chars, 2 chunk(s), 3 section(s)\n",
      "\n",
      "üìä Pages with Special Content:\n",
      "  With Tables: 11 pages\n",
      "  With Code:   15 pages\n"
     ]
    }
   ],
   "source": [
    "def page_level_statistics(chunks: List[PageBasedChunk]):\n",
    "    \"\"\"Analyze statistics at the page level\"\"\"\n",
    "    \n",
    "    print(\"\\nüìÑ PAGE-LEVEL STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Group by page\n",
    "    pages_data = {}\n",
    "    for chunk in chunks:\n",
    "        page = chunk.page_number\n",
    "        if page not in pages_data:\n",
    "            pages_data[page] = {\n",
    "                'chunks': [],\n",
    "                'total_chars': 0,\n",
    "                'total_words': 0,\n",
    "                'has_tables': False,\n",
    "                'has_code': False,\n",
    "                'sections': set()\n",
    "            }\n",
    "        \n",
    "        pages_data[page]['chunks'].append(chunk)\n",
    "        pages_data[page]['total_chars'] += len(chunk.content)\n",
    "        pages_data[page]['total_words'] += len(chunk.content.split())\n",
    "        pages_data[page]['has_tables'] = pages_data[page]['has_tables'] or chunk.metadata.get('has_tables', False)\n",
    "        pages_data[page]['has_code'] = pages_data[page]['has_code'] or chunk.metadata.get('has_code', False)\n",
    "        pages_data[page]['sections'].update(chunk.metadata.get('sections', []))\n",
    "    \n",
    "    # Page size distribution\n",
    "    page_sizes = [data['total_chars'] for data in pages_data.values()]\n",
    "    \n",
    "    print(f\"\\nüìè Page Size Distribution:\")\n",
    "    print(f\"  Average: {np.mean(page_sizes):.0f} chars\")\n",
    "    print(f\"  Median:  {np.median(page_sizes):.0f} chars\")\n",
    "    print(f\"  Min:     {min(page_sizes)} chars\")\n",
    "    print(f\"  Max:     {max(page_sizes)} chars\")\n",
    "    \n",
    "    # Largest pages\n",
    "    print(f\"\\nüîù Top 5 Largest Pages:\")\n",
    "    sorted_pages = sorted(pages_data.items(), key=lambda x: x[1]['total_chars'], reverse=True)\n",
    "    for page, data in sorted_pages[:5]:\n",
    "        chunks_on_page = len(data['chunks'])\n",
    "        print(f\"  Page {page}: {data['total_chars']:,} chars, {chunks_on_page} chunk(s), {len(data['sections'])} section(s)\")\n",
    "    \n",
    "    # Pages with special content\n",
    "    print(f\"\\nüìä Pages with Special Content:\")\n",
    "    table_pages = [p for p, d in pages_data.items() if d['has_tables']]\n",
    "    code_pages = [p for p, d in pages_data.items() if d['has_code']]\n",
    "    print(f\"  With Tables: {len(table_pages)} pages\")\n",
    "    print(f\"  With Code:   {len(code_pages)} pages\")\n",
    "\n",
    "# Run page-level analysis\n",
    "page_level_statistics(page_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Exported 43 chunks for embedding: ../data/chunks/page_based_chunks_for_embedding.jsonl\n",
      "üìÑ Perfect for page-level citation and traceability\n",
      "üîç Easy to map results back to PDF pages\n"
     ]
    }
   ],
   "source": [
    "def export_page_chunks_for_embedding(chunks: List[PageBasedChunk], output_path: str):\n",
    "    \"\"\"\n",
    "    Export page-based chunks for embedding generation.\n",
    "    Perfect for systems that need precise page citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.content,\n",
    "                'metadata': {\n",
    "                    'page': chunk.page_number,\n",
    "                    'page_reference': chunk.page_reference,\n",
    "                    'is_split': chunk.is_split_page,\n",
    "                    'sections': chunk.metadata.get('sections', []),\n",
    "                    'has_tables': chunk.metadata.get('has_tables', False),\n",
    "                    'has_code': chunk.metadata.get('has_code', False),\n",
    "                    'has_equations': chunk.metadata.get('has_equations', False),\n",
    "                    'char_count': len(chunk.content),\n",
    "                    'word_count': len(chunk.content.split()),\n",
    "                    'source': 'fintbx.pdf'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add split info if applicable\n",
    "            if chunk.is_split_page:\n",
    "                embedding_doc['metadata']['split_index'] = chunk.split_index\n",
    "                embedding_doc['metadata']['total_splits'] = chunk.total_splits\n",
    "            \n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "    print(f\"üìÑ Perfect for page-level citation and traceability\")\n",
    "    print(f\"üîç Easy to map results back to PDF pages\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_page_chunks_for_embedding(page_chunks, OUTPUT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52719a20",
   "metadata": {},
   "source": [
    "#### üéØ **Key Features of Page-Based Chunking:**\n",
    "\n",
    "1. **Perfect Citations**: Every chunk maps directly to a page number\n",
    "2. **Easy Traceability**: Simple to find content in original PDF\n",
    "3. **Natural Boundaries**: Pages are intuitive organizational units\n",
    "4. **Flexible**: Can split large pages while maintaining page reference\n",
    "5. **Simple**: Easiest to understand and implement\n",
    "\n",
    "üìÑ **Use Cases:**\n",
    "\n",
    "- **Legal Documents**: \"This appears on page 5\" ‚Üí precise citation\n",
    "- **Academic Papers**: Easy to reference page numbers\n",
    "- **Regulatory Documents**: Compliance requires page-level citations\n",
    "- **Source Verification**: Users can easily verify claims\n",
    "\n",
    "‚öñÔ∏è **Advantages:**\n",
    "\n",
    "- ‚úÖ Simplest citation system\n",
    "- ‚úÖ Natural document organization\n",
    "- ‚úÖ Easy to implement\n",
    "- ‚úÖ User-friendly references\n",
    "\n",
    "‚ö†Ô∏è **Limitations:**\n",
    "\n",
    "- Variable chunk sizes (some pages much larger)\n",
    "- May split related content across pages\n",
    "- Page breaks might be arbitrary\n",
    "\n",
    "This completes all **5 major chunking methods**! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041d99d",
   "metadata": {},
   "source": [
    "### Method 6: Hybrid Intelligent Chunking üß†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1c931c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Hybrid Intelligent Chunking Setup\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Paths\n",
    "CLEANED_DATA_PATH = '../data/final/docling_blocks_cleaned.jsonl'\n",
    "OUTPUT_PATH = '../data/chunks/hybrid_intelligent_chunks.jsonl'\n",
    "OUTPUT_EMBEDDING_PATH = '../data/chunks/hybrid_intelligent_chunks_for_embedding.jsonl'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c5d760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Hybrid Chunk Data Structure\n",
    "@dataclass\n",
    "class HybridChunk:\n",
    "    \"\"\"\n",
    "    Represents an intelligently created hybrid chunk.\n",
    "    Combines multiple strategies for optimal chunking.\n",
    "    \"\"\"\n",
    "    chunk_id: int\n",
    "    content: str\n",
    "    primary_strategy: str  # Which strategy created this chunk\n",
    "    strategies_applied: List[str]  # All strategies used\n",
    "    \n",
    "    # Context information\n",
    "    section_path: str\n",
    "    heading_hierarchy: List[str]\n",
    "    page_numbers: List[int]\n",
    "    \n",
    "    # Content classification\n",
    "    content_types: List[str]\n",
    "    is_special_content: bool\n",
    "    \n",
    "    # Chunking metadata\n",
    "    is_semantic_unit: bool  # True if kept whole for semantic reasons\n",
    "    was_split: bool  # True if larger unit was split\n",
    "    has_overlap: bool  # True if overlaps with neighbors\n",
    "    \n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "    \n",
    "    @property\n",
    "    def full_text_with_context(self):\n",
    "        \"\"\"Content with hierarchical context\"\"\"\n",
    "        if self.heading_hierarchy:\n",
    "            context = \" > \".join(self.heading_hierarchy)\n",
    "            return f\"[Context: {context}]\\n\\n{self.content}\"\n",
    "        return self.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a17180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_hybrid_intelligent(\n",
    "    jsonl_path: str,\n",
    "    target_size: int = 1500,\n",
    "    overlap: int = 150,\n",
    "    max_size: int = 2500,\n",
    "    min_size: int = 300,\n",
    "    keep_tables_whole: bool = True,\n",
    "    keep_code_whole: bool = True,\n",
    "    respect_sections: bool = True,\n",
    "    add_context: bool = True,\n",
    "    skip_types: List[str] = ['figure']\n",
    ") -> List[HybridChunk]:\n",
    "    \"\"\"\n",
    "    Create hybrid intelligent chunks using multiple strategies:\n",
    "    \n",
    "    Strategy Priority:\n",
    "    1. Preserve special content (tables, code, equations) whole\n",
    "    2. Keep semantic sections together when possible\n",
    "    3. Add hierarchical context to all chunks\n",
    "    4. Apply size-based splitting only when necessary\n",
    "    5. Add overlap for split chunks\n",
    "    6. Track pages for citation\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to cleaned JSONL file\n",
    "        target_size: Target chunk size in characters\n",
    "        overlap: Overlap size for split chunks\n",
    "        max_size: Maximum chunk size before forcing split\n",
    "        min_size: Minimum chunk size (merge if smaller)\n",
    "        keep_tables_whole: Preserve table integrity\n",
    "        keep_code_whole: Preserve code block integrity\n",
    "        respect_sections: Try to keep sections together\n",
    "        add_context: Add hierarchical breadcrumbs\n",
    "        skip_types: Block types to skip\n",
    "    \n",
    "    Returns:\n",
    "        List of HybridChunk objects\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üß† Starting Hybrid Intelligent Chunking...\")\n",
    "    print(f\"üìè Target size: {target_size} chars (range: {min_size}-{max_size})\")\n",
    "    print(f\"üîÑ Overlap: {overlap} chars\")\n",
    "    print(f\"‚öôÔ∏è  Strategies:\")\n",
    "    print(f\"   ‚úì Special content preservation: {keep_tables_whole or keep_code_whole}\")\n",
    "    print(f\"   ‚úì Semantic sections: {respect_sections}\")\n",
    "    print(f\"   ‚úì Hierarchical context: {add_context}\")\n",
    "    print(f\"   ‚úì Intelligent splitting: Always\")\n",
    "    print()\n",
    "    \n",
    "    # Load blocks\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        blocks = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    blocks.sort(key=lambda x: (x.get('page', 0), x.get('block_id', 0)))\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    # State tracking\n",
    "    heading_stack = []  # Current heading hierarchy\n",
    "    current_section = None\n",
    "    current_section_content = []\n",
    "    current_section_metadata = {\n",
    "        'pages': set(),\n",
    "        'block_ids': [],\n",
    "        'content_types': set(),\n",
    "        'has_special': False,\n",
    "        'blocks': []\n",
    "    }\n",
    "    \n",
    "    # Text splitter for when we need it\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=target_size,\n",
    "        chunk_overlap=overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    \n",
    "    def create_chunk(\n",
    "        content: str,\n",
    "        strategy: str,\n",
    "        strategies_list: List[str],\n",
    "        is_special: bool = False,\n",
    "        is_semantic: bool = False,\n",
    "        was_split: bool = False,\n",
    "        has_overlap: bool = False\n",
    "    ):\n",
    "        \"\"\"Helper to create a hybrid chunk\"\"\"\n",
    "        nonlocal chunk_id, chunks\n",
    "        \n",
    "        if not content.strip():\n",
    "            return\n",
    "        \n",
    "        # Build context\n",
    "        context_header = \"\"\n",
    "        if add_context and heading_stack:\n",
    "            hierarchy = [h['text'] for h in heading_stack]\n",
    "            context_header = f\"[Context: {' > '.join(hierarchy)}]\\n\\n\"\n",
    "        \n",
    "        # Determine content types\n",
    "        content_types = list(current_section_metadata['content_types'])\n",
    "        if not content_types:\n",
    "            content_types = ['text']\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'char_count': len(content),\n",
    "            'word_count': len(content.split()),\n",
    "            'pages': sorted(list(current_section_metadata['pages'])),\n",
    "            'block_ids': current_section_metadata['block_ids'].copy(),\n",
    "            'num_blocks': len(current_section_metadata['block_ids']),\n",
    "            'strategy': strategy,\n",
    "            'strategies_applied': strategies_list,\n",
    "            'target_size': target_size,\n",
    "            'is_semantic_unit': is_semantic,\n",
    "            'was_split': was_split,\n",
    "            'has_overlap': has_overlap,\n",
    "            'is_special_content': is_special,\n",
    "            'size_category': 'optimal' if min_size <= len(content) <= max_size else \n",
    "                           ('small' if len(content) < min_size else 'large'),\n",
    "            'source': 'fintbx.pdf',\n",
    "            'chunking_method': 'hybrid_intelligent'\n",
    "        }\n",
    "        \n",
    "        # Create chunk\n",
    "        chunk = HybridChunk(\n",
    "            chunk_id=chunk_id,\n",
    "            content=content.strip(),\n",
    "            primary_strategy=strategy,\n",
    "            strategies_applied=strategies_list,\n",
    "            section_path=current_section or 'Unknown',\n",
    "            heading_hierarchy=[h['text'] for h in heading_stack],\n",
    "            page_numbers=sorted(list(current_section_metadata['pages'])),\n",
    "            content_types=content_types,\n",
    "            is_special_content=is_special,\n",
    "            is_semantic_unit=is_semantic,\n",
    "            was_split=was_split,\n",
    "            has_overlap=has_overlap,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        \n",
    "        chunks.append(chunk)\n",
    "        chunk_id += 1\n",
    "    \n",
    "    def process_accumulated_content():\n",
    "        \"\"\"Process accumulated section content with intelligent strategy\"\"\"\n",
    "        nonlocal current_section_content, current_section_metadata\n",
    "        \n",
    "        if not current_section_content:\n",
    "            return\n",
    "        \n",
    "        combined = '\\n\\n'.join(current_section_content).strip()\n",
    "        if not combined:\n",
    "            return\n",
    "        \n",
    "        content_size = len(combined)\n",
    "        strategies = []\n",
    "        \n",
    "        # STRATEGY 1: Small enough - keep as is (semantic)\n",
    "        if content_size <= max_size:\n",
    "            strategies.append('semantic_section')\n",
    "            if respect_sections:\n",
    "                strategies.append('section_preservation')\n",
    "            \n",
    "            create_chunk(\n",
    "                content=combined,\n",
    "                strategy='semantic_section',\n",
    "                strategies_list=strategies,\n",
    "                is_semantic=True,\n",
    "                is_special=current_section_metadata['has_special']\n",
    "            )\n",
    "        \n",
    "        # STRATEGY 2: Too large - intelligent split\n",
    "        else:\n",
    "            strategies.append('intelligent_split')\n",
    "            if add_context:\n",
    "                strategies.append('context_preservation')\n",
    "            \n",
    "            # Use recursive splitter\n",
    "            split_texts = text_splitter.split_text(combined)\n",
    "            \n",
    "            for i, split_text in enumerate(split_texts):\n",
    "                chunk_strategies = strategies.copy()\n",
    "                if i > 0 or i < len(split_texts) - 1:\n",
    "                    chunk_strategies.append('overlap')\n",
    "                \n",
    "                create_chunk(\n",
    "                    content=split_text,\n",
    "                    strategy='intelligent_split',\n",
    "                    strategies_list=chunk_strategies,\n",
    "                    was_split=True,\n",
    "                    has_overlap=len(split_texts) > 1\n",
    "                )\n",
    "        \n",
    "        # Reset\n",
    "        current_section_content = []\n",
    "        current_section_metadata = {\n",
    "            'pages': set(),\n",
    "            'block_ids': [],\n",
    "            'content_types': set(),\n",
    "            'has_special': False,\n",
    "            'blocks': []\n",
    "        }\n",
    "    \n",
    "    # Process blocks\n",
    "    for block in blocks:\n",
    "        block_type = block.get('type', 'unknown')\n",
    "        block_id = block.get('block_id')\n",
    "        text = block.get('text', '').strip()\n",
    "        section = block.get('section_path', '')\n",
    "        page = block.get('page', 0)\n",
    "        \n",
    "        # Skip certain types\n",
    "        if block_type in skip_types or not text:\n",
    "            continue\n",
    "        \n",
    "        # HEADING: Update hierarchy and potentially flush\n",
    "        if block_type == 'heading':\n",
    "            level = block.get('heading_level', 1)\n",
    "            \n",
    "            # Flush accumulated content before hierarchy change\n",
    "            if current_section_content and respect_sections:\n",
    "                process_accumulated_content()\n",
    "            \n",
    "            # Update heading stack\n",
    "            heading_stack = [h for h in heading_stack if h['level'] < level]\n",
    "            heading_stack.append({\n",
    "                'level': level,\n",
    "                'text': text,\n",
    "                'section': section\n",
    "            })\n",
    "            \n",
    "            current_section = section\n",
    "            continue\n",
    "        \n",
    "        # TABLE: Keep whole as special content\n",
    "        if block_type == 'table' and keep_tables_whole:\n",
    "            # Flush current content first\n",
    "            process_accumulated_content()\n",
    "            \n",
    "            caption = block.get('caption', 'Table')\n",
    "            table_content = f\"## {caption}\\n\\n```\\n{text}\\n```\"\n",
    "            \n",
    "            # Create standalone table chunk\n",
    "            current_section_content = [table_content]\n",
    "            current_section_metadata = {\n",
    "                'pages': {page},\n",
    "                'block_ids': [block_id],\n",
    "                'content_types': {'table'},\n",
    "                'has_special': True,\n",
    "                'blocks': [block]\n",
    "            }\n",
    "            \n",
    "            create_chunk(\n",
    "                content=table_content,\n",
    "                strategy='special_content_table',\n",
    "                strategies_list=['special_content', 'table_preservation'],\n",
    "                is_special=True,\n",
    "                is_semantic=True\n",
    "            )\n",
    "            \n",
    "            # Reset\n",
    "            current_section_content = []\n",
    "            current_section_metadata = {\n",
    "                'pages': set(),\n",
    "                'block_ids': [],\n",
    "                'content_types': set(),\n",
    "                'has_special': False,\n",
    "                'blocks': []\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # CODE: Keep whole as special content\n",
    "        if block_type == 'code' and keep_code_whole:\n",
    "            # Flush current content first\n",
    "            process_accumulated_content()\n",
    "            \n",
    "            code_content = f\"```\\n{text}\\n```\"\n",
    "            \n",
    "            # Create standalone code chunk\n",
    "            current_section_content = [code_content]\n",
    "            current_section_metadata = {\n",
    "                'pages': {page},\n",
    "                'block_ids': [block_id],\n",
    "                'content_types': {'code'},\n",
    "                'has_special': True,\n",
    "                'blocks': [block]\n",
    "            }\n",
    "            \n",
    "            create_chunk(\n",
    "                content=code_content,\n",
    "                strategy='special_content_code',\n",
    "                strategies_list=['special_content', 'code_preservation'],\n",
    "                is_special=True,\n",
    "                is_semantic=True\n",
    "            )\n",
    "            \n",
    "            # Reset\n",
    "            current_section_content = []\n",
    "            current_section_metadata = {\n",
    "                'pages': set(),\n",
    "                'block_ids': [],\n",
    "                'content_types': set(),\n",
    "                'has_special': False,\n",
    "                'blocks': []\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # REGULAR CONTENT: Accumulate\n",
    "        formatted_text = \"\"\n",
    "        \n",
    "        if block_type == 'equation':\n",
    "            formatted_text = f\"$$\\n{text}\\n$$\"\n",
    "        elif block_type == 'list':\n",
    "            formatted_text = text\n",
    "        elif block_type == 'table':\n",
    "            # Table but not keeping whole\n",
    "            formatted_text = f\"```\\n{text}\\n```\"\n",
    "            current_section_metadata['has_special'] = True\n",
    "        else:\n",
    "            formatted_text = text\n",
    "        \n",
    "        # Check if adding would exceed max size\n",
    "        current_size = sum(len(c) for c in current_section_content)\n",
    "        \n",
    "        if current_size + len(formatted_text) > max_size and current_section_content:\n",
    "            # Process what we have\n",
    "            process_accumulated_content()\n",
    "        \n",
    "        # Add to accumulation\n",
    "        current_section_content.append(formatted_text)\n",
    "        current_section_metadata['pages'].add(page)\n",
    "        current_section_metadata['block_ids'].append(block_id)\n",
    "        current_section_metadata['content_types'].add(block_type)\n",
    "        current_section_metadata['blocks'].append(block)\n",
    "    \n",
    "    # Process final accumulated content\n",
    "    process_accumulated_content()\n",
    "    \n",
    "    # Statistics\n",
    "    strategies_used = {}\n",
    "    for chunk in chunks:\n",
    "        strategies_used[chunk.primary_strategy] = strategies_used.get(chunk.primary_strategy, 0) + 1\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} hybrid intelligent chunks\")\n",
    "    print(f\"\\nüìä Strategies Used:\")\n",
    "    for strategy, count in sorted(strategies_used.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {strategy:25s}: {count:3d} chunks\")\n",
    "    \n",
    "    special_count = sum(1 for c in chunks if c.is_special_content)\n",
    "    semantic_count = sum(1 for c in chunks if c.is_semantic_unit)\n",
    "    split_count = sum(1 for c in chunks if c.was_split)\n",
    "    \n",
    "    print(f\"\\nüéØ Chunk Characteristics:\")\n",
    "    print(f\"   Special content:     {special_count} ({special_count/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"   Semantic units:      {semantic_count} ({semantic_count/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"   Split chunks:        {split_count} ({split_count/len(chunks)*100:.1f}%)\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29bebaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Hybrid Intelligent Chunking...\n",
      "\n",
      "üß† Starting Hybrid Intelligent Chunking...\n",
      "üìè Target size: 1500 chars (range: 300-2500)\n",
      "üîÑ Overlap: 150 chars\n",
      "‚öôÔ∏è  Strategies:\n",
      "   ‚úì Special content preservation: True\n",
      "   ‚úì Semantic sections: True\n",
      "   ‚úì Hierarchical context: True\n",
      "   ‚úì Intelligent splitting: Always\n",
      "\n",
      "‚úÖ Created 138 hybrid intelligent chunks\n",
      "\n",
      "üìä Strategies Used:\n",
      "   semantic_section         :  86 chunks\n",
      "   special_content_code     :  40 chunks\n",
      "   special_content_table    :  12 chunks\n",
      "\n",
      "üéØ Chunk Characteristics:\n",
      "   Special content:     52 (37.7%)\n",
      "   Semantic units:      138 (100.0%)\n",
      "   Split chunks:        0 (0.0%)\n",
      "\n",
      "‚úÖ Hybrid intelligent chunking complete!\n",
      "üìä Total chunks: 138\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Starting Hybrid Intelligent Chunking...\\n\")\n",
    "\n",
    "hybrid_chunks = chunk_hybrid_intelligent(\n",
    "    jsonl_path=CLEANED_DATA_PATH,\n",
    "    target_size=1500,\n",
    "    overlap=150,\n",
    "    max_size=2500,\n",
    "    min_size=300,\n",
    "    keep_tables_whole=True,\n",
    "    keep_code_whole=True,\n",
    "    respect_sections=True,\n",
    "    add_context=True,\n",
    "    skip_types=['figure']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Hybrid intelligent chunking complete!\")\n",
    "print(f\"üìä Total chunks: {len(hybrid_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d8d7df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä HYBRID INTELLIGENT CHUNK STATISTICS\n",
      "======================================================================\n",
      "Total Chunks: 138\n",
      "\n",
      "üéØ Primary Strategy Distribution:\n",
      "  semantic_section              :  86 chunks ( 62.3%)\n",
      "  special_content_code          :  40 chunks ( 29.0%)\n",
      "  special_content_table         :  12 chunks (  8.7%)\n",
      "\n",
      "üìè Size Distribution:\n",
      "  Average Characters: 562\n",
      "  Median Characters:  200\n",
      "  Std Dev:            1248\n",
      "  Min:                4\n",
      "  Max:                8800\n",
      "\n",
      "üì¶ Size Categories:\n",
      "  Small     :  86 chunks\n",
      "  Optimal   :  48 chunks\n",
      "  Large     :   4 chunks\n",
      "\n",
      "üé® Chunk Characteristics:\n",
      "  Special Content:     52 (37.7%)\n",
      "  Semantic Units:     138 (100.0%)\n",
      "  Split Chunks:         0 (0.0%)\n",
      "  With Overlap:         0 (0.0%)\n",
      "\n",
      "üìñ Context & Structure:\n",
      "  Avg Hierarchy Depth: 1.0\n",
      "  Avg Pages per Chunk: 1.0\n",
      "  Multi-page Chunks:   6\n",
      "\n",
      "üîù Top 5 Largest Chunks:\n",
      "     chunk_id               strategy  is_special  char_count  \\\n",
      "6           6  special_content_table        True        8800   \n",
      "10         10  special_content_table        True        7627   \n",
      "80         80  special_content_table        True        7612   \n",
      "132       132  special_content_table        True        4391   \n",
      "77         77  special_content_table        True        2199   \n",
      "\n",
      "                  section  \n",
      "6        Revision History  \n",
      "10   Credit Risk Analysis  \n",
      "80       Related Examples  \n",
      "132        Binomial Model  \n",
      "77              Annuities  \n"
     ]
    }
   ],
   "source": [
    "def analyze_hybrid_chunks(chunks: List[HybridChunk]) -> pd.DataFrame:\n",
    "    \"\"\"Generate comprehensive statistics about hybrid chunks\"\"\"\n",
    "    \n",
    "    stats = []\n",
    "    for chunk in chunks:\n",
    "        stats.append({\n",
    "            'chunk_id': chunk.chunk_id,\n",
    "            'strategy': chunk.primary_strategy,\n",
    "            'num_strategies': len(chunk.strategies_applied),\n",
    "            'is_special': chunk.is_special_content,\n",
    "            'is_semantic': chunk.is_semantic_unit,\n",
    "            'was_split': chunk.was_split,\n",
    "            'has_overlap': chunk.has_overlap,\n",
    "            'char_count': len(chunk.content),\n",
    "            'word_count': len(chunk.content.split()),\n",
    "            'size_category': chunk.metadata.get('size_category', 'unknown'),\n",
    "            'pages': ', '.join(map(str, chunk.page_numbers)),\n",
    "            'num_pages': len(chunk.page_numbers),\n",
    "            'hierarchy_depth': len(chunk.heading_hierarchy),\n",
    "            'content_types': ', '.join(chunk.content_types),\n",
    "            'section': chunk.section_path[:40] + '...' if len(chunk.section_path) > 40 else chunk.section_path\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    print(\"\\nüìä HYBRID INTELLIGENT CHUNK STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Chunks: {len(chunks)}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Primary Strategy Distribution:\")\n",
    "    strategy_dist = df['strategy'].value_counts()\n",
    "    for strategy, count in strategy_dist.items():\n",
    "        pct = (count / len(chunks)) * 100\n",
    "        print(f\"  {strategy:30s}: {count:3d} chunks ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìè Size Distribution:\")\n",
    "    print(f\"  Average Characters: {df['char_count'].mean():.0f}\")\n",
    "    print(f\"  Median Characters:  {df['char_count'].median():.0f}\")\n",
    "    print(f\"  Std Dev:            {df['char_count'].std():.0f}\")\n",
    "    print(f\"  Min:                {df['char_count'].min()}\")\n",
    "    print(f\"  Max:                {df['char_count'].max()}\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Size Categories:\")\n",
    "    size_cats = df['size_category'].value_counts()\n",
    "    for cat, count in size_cats.items():\n",
    "        print(f\"  {cat.capitalize():10s}: {count:3d} chunks\")\n",
    "    \n",
    "    print(f\"\\nüé® Chunk Characteristics:\")\n",
    "    print(f\"  Special Content:    {df['is_special'].sum():3d} ({df['is_special'].sum()/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"  Semantic Units:     {df['is_semantic'].sum():3d} ({df['is_semantic'].sum()/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"  Split Chunks:       {df['was_split'].sum():3d} ({df['was_split'].sum()/len(chunks)*100:.1f}%)\")\n",
    "    print(f\"  With Overlap:       {df['has_overlap'].sum():3d} ({df['has_overlap'].sum()/len(chunks)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìñ Context & Structure:\")\n",
    "    print(f\"  Avg Hierarchy Depth: {df['hierarchy_depth'].mean():.1f}\")\n",
    "    print(f\"  Avg Pages per Chunk: {df['num_pages'].mean():.1f}\")\n",
    "    print(f\"  Multi-page Chunks:   {sum(df['num_pages'] > 1)}\")\n",
    "    \n",
    "    print(f\"\\nüîù Top 5 Largest Chunks:\")\n",
    "    print(df.nlargest(5, 'char_count')[['chunk_id', 'strategy', 'is_special', 'char_count', 'section']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run analysis\n",
    "hybrid_stats_df = analyze_hybrid_chunks(hybrid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01ac0e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ SAMPLE HYBRID INTELLIGENT CHUNKS\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SAMPLE 1: CHUNK 0 - Strategy: SEMANTIC_SECTION\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üéØ Strategy Info:\n",
      "  Primary Strategy:   semantic_section\n",
      "  All Strategies:     semantic_section, section_preservation\n",
      "\n",
      "üìã Classification:\n",
      "  Special Content:    False\n",
      "  Semantic Unit:      True\n",
      "  Was Split:          False\n",
      "  Has Overlap:        False\n",
      "  Size Category:      small\n",
      "\n",
      "üîó Context:\n",
      "  Hierarchy: MATLAB¬Æ\n",
      "  Section: MATLAB¬Æ\n",
      "  Pages: [1]\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 8 chars, 3 words\n",
      "  Content Types: paragraph\n",
      "  Blocks: 1\n",
      "\n",
      "üìù Content Preview (first 250 chars):\n",
      "  R 2025 b\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SAMPLE 2: CHUNK 6 - Strategy: SPECIAL_CONTENT_TABLE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üéØ Strategy Info:\n",
      "  Primary Strategy:   special_content_table\n",
      "  All Strategies:     special_content, table_preservation\n",
      "\n",
      "üìã Classification:\n",
      "  Special Content:    True\n",
      "  Semantic Unit:      True\n",
      "  Was Split:          False\n",
      "  Has Overlap:        False\n",
      "  Size Category:      large\n",
      "\n",
      "üîó Context:\n",
      "  Hierarchy: Revision History\n",
      "  Section: Revision History\n",
      "  Pages: [4]\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 8800 chars, 1111 words\n",
      "  Content Types: table\n",
      "  Blocks: 1\n",
      "\n",
      "üìù Content Preview (first 250 chars):\n",
      "  ## Revision History\n",
      "\n",
      "```\n",
      "| Working with Average Turnover Constraints Using PortfolioMAD Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   | 6-74                                 ...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SAMPLE 3: CHUNK 11 - Strategy: SPECIAL_CONTENT_CODE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üéØ Strategy Info:\n",
      "  Primary Strategy:   special_content_code\n",
      "  All Strategies:     special_content, code_preservation\n",
      "\n",
      "üìã Classification:\n",
      "  Special Content:    True\n",
      "  Semantic Unit:      True\n",
      "  Was Split:          False\n",
      "  Has Overlap:        False\n",
      "  Size Category:      small\n",
      "\n",
      "üîó Context:\n",
      "  Hierarchy: Credit Risk Analysis\n",
      "  Section: Credit Risk Analysis\n",
      "  Pages: [7]\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 28 chars, 5 words\n",
      "  Content Types: code\n",
      "  Blocks: 1\n",
      "\n",
      "üìù Content Preview (first 250 chars):\n",
      "  ```\n",
      "3.5475 3.5550 3.5513\n",
      "```\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SAMPLE 4: CHUNK 1 - Strategy: SEMANTIC_SECTION\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üéØ Strategy Info:\n",
      "  Primary Strategy:   semantic_section\n",
      "  All Strategies:     semantic_section, section_preservation\n",
      "\n",
      "üìã Classification:\n",
      "  Special Content:    False\n",
      "  Semantic Unit:      True\n",
      "  Was Split:          False\n",
      "  Has Overlap:        False\n",
      "  Size Category:      optimal\n",
      "\n",
      "üîó Context:\n",
      "  Hierarchy: How to Contact MathWorks\n",
      "  Section: How to Contact MathWorks\n",
      "  Pages: [2]\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 1733 chars, 242 words\n",
      "  Content Types: paragraph\n",
      "  Blocks: 15\n",
      "\n",
      "üìù Content Preview (first 250 chars):\n",
      "  Latest news:\n",
      "\n",
      "www.mathworks.com\n",
      "\n",
      "Sales and services:\n",
      "\n",
      "www.mathworks.com/sales_and_services\n",
      "\n",
      "User community:\n",
      "\n",
      "www.mathworks.com/matlabcentral\n",
      "\n",
      "Technical support:\n",
      "\n",
      "www.mathworks.com/support/contact_us\n",
      "\n",
      "Phone:\n",
      "\n",
      "508-647-7000\n",
      "\n",
      "The MathWorks, Inc. 1 Apple ...\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SAMPLE 5: CHUNK 2 - Strategy: SEMANTIC_SECTION\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üéØ Strategy Info:\n",
      "  Primary Strategy:   semantic_section\n",
      "  All Strategies:     semantic_section, section_preservation\n",
      "\n",
      "üìã Classification:\n",
      "  Special Content:    False\n",
      "  Semantic Unit:      True\n",
      "  Was Split:          False\n",
      "  Has Overlap:        False\n",
      "  Size Category:      small\n",
      "\n",
      "üîó Context:\n",
      "  Hierarchy: Trademarks\n",
      "  Section: Trademarks\n",
      "  Pages: [2]\n",
      "\n",
      "üìä Stats:\n",
      "  Size: 239 chars, 33 words\n",
      "  Content Types: paragraph\n",
      "  Blocks: 1\n",
      "\n",
      "üìù Content Preview (first 250 chars):\n",
      "  MATLAB and Simulink are registered trademarks of The MathWorks, Inc. See www.mathworks.com/trademarks for a list of additional trademarks. Other product or brand names may be trademarks or registered trademarks of their respective holders.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_hybrid_chunks(chunks: List[HybridChunk], num_samples: int = 5):\n",
    "    \"\"\"Display diverse sample chunks showing different strategies\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ SAMPLE HYBRID INTELLIGENT CHUNKS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get diverse samples by strategy\n",
    "    strategies = {}\n",
    "    for chunk in chunks:\n",
    "        strategy = chunk.primary_strategy\n",
    "        if strategy not in strategies:\n",
    "            strategies[strategy] = []\n",
    "        strategies[strategy].append(chunk)\n",
    "    \n",
    "    samples = []\n",
    "    for strategy, strategy_chunks in strategies.items():\n",
    "        if strategy_chunks:\n",
    "            samples.append(strategy_chunks[0])\n",
    "    \n",
    "    # Fill remaining with random chunks\n",
    "    while len(samples) < num_samples and len(samples) < len(chunks):\n",
    "        for chunk in chunks:\n",
    "            if chunk not in samples:\n",
    "                samples.append(chunk)\n",
    "                break\n",
    "    \n",
    "    for i, chunk in enumerate(samples[:num_samples], 1):\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"SAMPLE {i}: CHUNK {chunk.chunk_id} - Strategy: {chunk.primary_strategy.upper()}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Strategy Info:\")\n",
    "        print(f\"  Primary Strategy:   {chunk.primary_strategy}\")\n",
    "        print(f\"  All Strategies:     {', '.join(chunk.strategies_applied)}\")\n",
    "        \n",
    "        print(f\"\\nüìã Classification:\")\n",
    "        print(f\"  Special Content:    {chunk.is_special_content}\")\n",
    "        print(f\"  Semantic Unit:      {chunk.is_semantic_unit}\")\n",
    "        print(f\"  Was Split:          {chunk.was_split}\")\n",
    "        print(f\"  Has Overlap:        {chunk.has_overlap}\")\n",
    "        print(f\"  Size Category:      {chunk.metadata.get('size_category', 'unknown')}\")\n",
    "        \n",
    "        print(f\"\\nüîó Context:\")\n",
    "        if chunk.heading_hierarchy:\n",
    "            hierarchy_str = \" > \".join(chunk.heading_hierarchy)\n",
    "            print(f\"  Hierarchy: {hierarchy_str}\")\n",
    "        print(f\"  Section: {chunk.section_path}\")\n",
    "        print(f\"  Pages: {chunk.page_numbers}\")\n",
    "        \n",
    "        print(f\"\\nüìä Stats:\")\n",
    "        print(f\"  Size: {len(chunk.content)} chars, {len(chunk.content.split())} words\")\n",
    "        print(f\"  Content Types: {', '.join(chunk.content_types)}\")\n",
    "        print(f\"  Blocks: {chunk.metadata.get('num_blocks', 0)}\")\n",
    "        \n",
    "        print(f\"\\nüìù Content Preview (first 250 chars):\")\n",
    "        preview = chunk.content[:250]\n",
    "        if len(chunk.content) > 250:\n",
    "            preview += \"...\"\n",
    "        print(f\"  {preview}\")\n",
    "        print()\n",
    "\n",
    "# Preview diverse samples\n",
    "preview_hybrid_chunks(hybrid_chunks, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16dca5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0.7777777777777778,
           1
          ]
         },
         "labels": [
          "semantic_section",
          "special_content_code",
          "special_content_table"
         ],
         "type": "pie",
         "values": {
          "bdata": "VigM",
          "dtype": "i1"
         }
        },
        {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0.7777777777777778,
           1
          ]
         },
         "labels": [
          "small",
          "optimal",
          "large"
         ],
         "marker": {
          "colors": [
           "orange",
           "green",
           "red"
          ]
         },
         "type": "pie",
         "values": {
          "bdata": "VjAE",
          "dtype": "i1"
         }
        },
        {
         "type": "bar",
         "x": [
          "Special",
          "Semantic",
          "Split",
          "Overlap"
         ],
         "xaxis": "x",
         "y": [
          52,
          138,
          0,
          0
         ],
         "yaxis": "y"
        },
        {
         "name": "semantic_sectio",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "CADFBu8AeAC6BCoHBAB9A3MAcgGgAPQBfQBdAs8BDQTnAxMAFAFzAHsAvQHRBFQAzgC2AcoArAEgAXsAlQCSAEcEFQA/ApkAfgJCAAoB6AFZAZMASQG9APcAMwBvAIIBiwDjAVgBdABHADoD7wClAWQAlQOSARkELQKYAAkBCwHoAEMDXwCcA98AYgFKAa4AUgC8ADQCEwEEBP0EfgFSAFsEGgPlB3EHKwAyAA==",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "name": "special_content",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "YCJsBcsdSQFBAcsAlwi8He0AAgL8ACcR",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "name": "special_content",
         "type": "box",
         "xaxis": "x2",
         "y": {
          "bdata": "HAA1AKQAlQBRACMAXgBoAHMASgArADMAKQApAFgAMAAWADAAYgAsAFUAJgAxAOUAhQBKAHsAxQApAkoAwQBLAL8ARQBeAKwAZQCWAKUBTgA=",
          "dtype": "i2"
         },
         "yaxis": "y2"
        },
        {
         "nbinsx": 10,
         "type": "histogram",
         "x": {
          "bdata": "AQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEB",
          "dtype": "i1"
         },
         "xaxis": "x3",
         "yaxis": "y3"
        },
        {
         "type": "bar",
         "x": {
          "bdata": "AQI=",
          "dtype": "i1"
         },
         "xaxis": "x4",
         "y": {
          "bdata": "gwAHAA==",
          "dtype": "i2"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Strategy Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Size Category Distribution",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Chunk Characteristics",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Size Distribution by Strategy",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Hierarchy Depth Distribution",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Content Type Distribution",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1200,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hybrid Intelligent Chunking Analysis"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Characteristic"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Hierarchy Depth"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Number of Content Types"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "title": {
          "text": "Number of Chunks"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "title": {
          "text": "Chunk Size (chars)"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.22222222222222224
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.22222222222222224
         ],
         "title": {
          "text": "Number of Chunks"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_hybrid_chunks(chunks: List[HybridChunk], stats_df: pd.DataFrame):\n",
    "    \"\"\"Visualize hybrid chunking results\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Strategy Distribution',\n",
    "            'Size Category Distribution',\n",
    "            'Chunk Characteristics',\n",
    "            'Size Distribution by Strategy',\n",
    "            'Hierarchy Depth Distribution',\n",
    "            'Content Type Distribution'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'pie'}, {'type': 'pie'}],\n",
    "            [{'type': 'bar'}, {'type': 'box'}],\n",
    "            [{'type': 'histogram'}, {'type': 'bar'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Strategy distribution\n",
    "    strategy_counts = stats_df['strategy'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=strategy_counts.index, values=strategy_counts.values),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Size category distribution\n",
    "    size_cats = stats_df['size_category'].value_counts()\n",
    "    colors = {'small': 'orange', 'optimal': 'green', 'large': 'red'}\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=size_cats.index,\n",
    "            values=size_cats.values,\n",
    "            marker_colors=[colors.get(cat, 'gray') for cat in size_cats.index]\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Chunk characteristics\n",
    "    characteristics = {\n",
    "        'Special': stats_df['is_special'].sum(),\n",
    "        'Semantic': stats_df['is_semantic'].sum(),\n",
    "        'Split': stats_df['was_split'].sum(),\n",
    "        'Overlap': stats_df['has_overlap'].sum()\n",
    "    }\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=list(characteristics.keys()), y=list(characteristics.values())),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Characteristic\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Chunks\", row=2, col=1)\n",
    "    \n",
    "    # 4. Size distribution by strategy\n",
    "    for strategy in stats_df['strategy'].unique():\n",
    "        strategy_data = stats_df[stats_df['strategy'] == strategy]\n",
    "        fig.add_trace(\n",
    "            go.Box(y=strategy_data['char_count'], name=strategy[:15]),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    fig.update_yaxes(title_text=\"Chunk Size (chars)\", row=2, col=2)\n",
    "    \n",
    "    # 5. Hierarchy depth\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=stats_df['hierarchy_depth'], nbinsx=10),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Hierarchy Depth\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=3, col=1)\n",
    "    \n",
    "    # 6. Content types (count unique types per chunk)\n",
    "    content_type_counts = stats_df['content_types'].str.split(', ').apply(len)\n",
    "    type_distribution = content_type_counts.value_counts().sort_index()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=type_distribution.index, y=type_distribution.values),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Number of Content Types\", row=3, col=2)\n",
    "    fig.update_yaxes(title_text=\"Number of Chunks\", row=3, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Hybrid Intelligent Chunking Analysis\",\n",
    "        height=1200,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_hybrid_chunks(hybrid_chunks, hybrid_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d48803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà STRATEGY EFFECTIVENESS ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "semantic_section:\n",
      "  Count:        86\n",
      "  Avg Size:     455 chars (76 words)\n",
      "  Size Range:   4 - 2021 chars\n",
      "  Std Dev:      456\n",
      "  Semantic:     86/86\n",
      "  Special:      0/86\n",
      "\n",
      "special_content_code:\n",
      "  Count:        40\n",
      "  Avg Size:     113 chars (17 words)\n",
      "  Size Range:   22 - 553 chars\n",
      "  Std Dev:      101\n",
      "  Semantic:     40/40\n",
      "  Special:      40/40\n",
      "\n",
      "special_content_table:\n",
      "  Count:        12\n",
      "  Avg Size:     2823 chars (335 words)\n",
      "  Size Range:   203 - 8800 chars\n",
      "  Std Dev:      3223\n",
      "  Semantic:     12/12\n",
      "  Special:      12/12\n"
     ]
    }
   ],
   "source": [
    "def analyze_strategy_effectiveness(chunks: List[HybridChunk]):\n",
    "    \"\"\"Analyze which strategies produce the best chunks\"\"\"\n",
    "    \n",
    "    print(\"\\nüìà STRATEGY EFFECTIVENESS ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    by_strategy = {}\n",
    "    for chunk in chunks:\n",
    "        strategy = chunk.primary_strategy\n",
    "        if strategy not in by_strategy:\n",
    "            by_strategy[strategy] = []\n",
    "        by_strategy[strategy].append(chunk)\n",
    "    \n",
    "    for strategy, strategy_chunks in sorted(by_strategy.items()):\n",
    "        sizes = [len(c.content) for c in strategy_chunks]\n",
    "        words = [len(c.content.split()) for c in strategy_chunks]\n",
    "        \n",
    "        print(f\"\\n{strategy}:\")\n",
    "        print(f\"  Count:        {len(strategy_chunks)}\")\n",
    "        print(f\"  Avg Size:     {np.mean(sizes):.0f} chars ({np.mean(words):.0f} words)\")\n",
    "        print(f\"  Size Range:   {min(sizes)} - {max(sizes)} chars\")\n",
    "        print(f\"  Std Dev:      {np.std(sizes):.0f}\")\n",
    "        print(f\"  Semantic:     {sum(1 for c in strategy_chunks if c.is_semantic_unit)}/{len(strategy_chunks)}\")\n",
    "        print(f\"  Special:      {sum(1 for c in strategy_chunks if c.is_special_content)}/{len(strategy_chunks)}\")\n",
    "\n",
    "# Run effectiveness analysis\n",
    "analyze_strategy_effectiveness(hybrid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "656c4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved 138 chunks to: ../data/chunks/hybrid_intelligent_chunks.jsonl\n",
      "üìã Saved summary to: ../data/chunks/hybrid_intelligent_chunks_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_hybrid_chunks(chunks: List[HybridChunk], output_path: str):\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk.to_dict(), f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüíæ Saved {len(chunks)} chunks to: {output_path}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_path = output_path.replace('.jsonl', '_summary.json')\n",
    "    \n",
    "    strategies = {}\n",
    "    for chunk in chunks:\n",
    "        strategies[chunk.primary_strategy] = strategies.get(chunk.primary_strategy, 0) + 1\n",
    "    \n",
    "    summary = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'chunking_method': 'hybrid_intelligent',\n",
    "        'strategies_used': strategies,\n",
    "        'statistics': {\n",
    "            'avg_size': np.mean([len(c.content) for c in chunks]),\n",
    "            'median_size': np.median([len(c.content) for c in chunks]),\n",
    "            'std_size': np.std([len(c.content) for c in chunks]),\n",
    "            'min_size': min(len(c.content) for c in chunks),\n",
    "            'max_size': max(len(c.content) for c in chunks),\n",
    "            'special_content_chunks': sum(1 for c in chunks if c.is_special_content),\n",
    "            'semantic_unit_chunks': sum(1 for c in chunks if c.is_semantic_unit),\n",
    "            'split_chunks': sum(1 for c in chunks if c.was_split),\n",
    "            'chunks_with_overlap': sum(1 for c in chunks if c.has_overlap),\n",
    "            'avg_hierarchy_depth': np.mean([len(c.heading_hierarchy) for c in chunks])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üìã Saved summary to: {summary_path}\")\n",
    "\n",
    "# Save the chunks\n",
    "save_hybrid_chunks(hybrid_chunks, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84196e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Exported 138 chunks for embedding: ../data/chunks/hybrid_intelligent_chunks_for_embedding.jsonl\n",
      "üìù Includes hierarchical context and full metadata\n",
      "üß† Optimized for intelligent retrieval\n"
     ]
    }
   ],
   "source": [
    "def export_hybrid_for_embedding(chunks: List[HybridChunk], output_path: str):\n",
    "    \"\"\"\n",
    "    Export hybrid chunks for embedding generation.\n",
    "    Includes full context and rich metadata for intelligent retrieval.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            embedding_doc = {\n",
    "                'id': chunk.chunk_id,\n",
    "                'text': chunk.full_text_with_context,  # Includes hierarchical context\n",
    "                'metadata': {\n",
    "                    'strategy': chunk.primary_strategy,\n",
    "                    'strategies_applied': chunk.strategies_applied,\n",
    "                    'section': chunk.section_path,\n",
    "                    'hierarchy': chunk.heading_hierarchy,\n",
    "                    'pages': chunk.page_numbers,\n",
    "                    'content_types': chunk.content_types,\n",
    "                    'is_special': chunk.is_special_content,\n",
    "                    'is_semantic': chunk.is_semantic_unit,\n",
    "                    'was_split': chunk.was_split,\n",
    "                    'char_count': len(chunk.content),\n",
    "                    'word_count': len(chunk.content.split()),\n",
    "                    'source': 'fintbx.pdf'\n",
    "                }\n",
    "            }\n",
    "            json.dump(embedding_doc, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"\\nüéØ Exported {len(chunks)} chunks for embedding: {output_path}\")\n",
    "    print(f\"üìù Includes hierarchical context and full metadata\")\n",
    "    print(f\"üß† Optimized for intelligent retrieval\")\n",
    "\n",
    "# Export for embeddings\n",
    "export_hybrid_for_embedding(hybrid_chunks, OUTPUT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1021025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÜ ULTIMATE CHUNKING METHOD COMPARISON\n",
      "================================================================================\n",
      "\n",
      "                Method  Chunks   Avg   Med   Std    CV%  Min    Max\n",
      "0       Section-Based      47  1667   940  2496  149.7   19  13267\n",
      "1        Hierarchical      72  1078   733  1590  147.5    8   8800\n",
      "2          Type-Aware     141   549   203  1220  222.1    4   8800\n",
      "3       Fixed-Overlap     104   821   877   203   24.8    4    999\n",
      "4          Page-Based      43  1851  2030   924   49.9    8   2976\n",
      "5  Hybrid-Intelligent     138   561   199  1243  221.4    4   8800\n",
      "\n",
      "================================================================================\n",
      "üéØ COMPREHENSIVE SELECTION GUIDE\n",
      "================================================================================\n",
      "\n",
      "1. Section-Based:\n",
      "   When: ‚úì Clean semantic boundaries\n",
      "   Best for: General RAG, simple docs\n",
      "   Pros: Semantic coherence\n",
      "   Cons: Variable sizes\n",
      "\n",
      "2. Hierarchical:\n",
      "   When: ‚úì Document structure + context\n",
      "   Best for: Complex Q&A, technical docs\n",
      "   Pros: Rich context, structure\n",
      "   Cons: Larger chunks\n",
      "\n",
      "3. Type-Aware:\n",
      "   When: ‚úì Mixed content types\n",
      "   Best for: Technical docs, filtered search\n",
      "   Pros: Content type filtering\n",
      "   Cons: Complex metadata\n",
      "\n",
      "4. Fixed-Overlap:\n",
      "   When: ‚úì Consistent chunk sizes\n",
      "   Best for: Standard RAG, embeddings\n",
      "   Pros: Consistent, overlap\n",
      "   Cons: Splits semantics\n",
      "\n",
      "5. Page-Based:\n",
      "   When: ‚úì Precise page citations\n",
      "   Best for: Legal, academic, citations\n",
      "   Pros: Easy traceability\n",
      "   Cons: Variable sizes\n",
      "\n",
      "6. Hybrid-Intelligent:\n",
      "   When: ‚úì BEST OF ALL METHODS\n",
      "   Best for: Production RAG systems\n",
      "   Pros: Adaptive, intelligent\n",
      "   Cons: Most complex\n",
      "\n",
      "================================================================================\n",
      "üí° HYBRID INTELLIGENT ADVANTAGES\n",
      "================================================================================\n",
      "  ‚úì Preserves tables and code integrity (Type-Aware)\n",
      "  ‚úì Maintains semantic sections (Section-Based)\n",
      "  ‚úì Adds hierarchical context (Hierarchical)\n",
      "  ‚úì Uses intelligent splitting with overlap (Fixed-Overlap)\n",
      "  ‚úì Tracks pages for citations (Page-Based)\n",
      "  ‚úì Adaptive strategy selection based on content\n",
      "  ‚úì Optimal for production RAG systems\n",
      "\n",
      "üèÜ RECOMMENDATION: Use Hybrid-Intelligent for production systems!\n"
     ]
    }
   ],
   "source": [
    "def ultimate_chunking_comparison():\n",
    "    \"\"\"\n",
    "    Final comprehensive comparison of ALL six chunking methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÜ ULTIMATE CHUNKING METHOD COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    methods = {\n",
    "        'Section-Based': '../data/chunks/section_based_chunks.jsonl',\n",
    "        'Hierarchical': '../data/chunks/hierarchical_chunks.jsonl',\n",
    "        'Type-Aware': '../data/chunks/type_aware_chunks.jsonl',\n",
    "        'Fixed-Overlap': '../data/chunks/fixed_overlap_chunks.jsonl',\n",
    "        'Page-Based': '../data/chunks/page_based_chunks.jsonl',\n",
    "        'Hybrid-Intelligent': OUTPUT_PATH\n",
    "    }\n",
    "    \n",
    "    comparison = []\n",
    "    \n",
    "    for name, path in methods.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                chunks = [json.loads(line) for line in f if line.strip()]\n",
    "            \n",
    "            sizes = [c['metadata']['char_count'] for c in chunks]\n",
    "            \n",
    "            comparison.append({\n",
    "                'Method': name,\n",
    "                'Chunks': len(chunks),\n",
    "                'Avg': int(np.mean(sizes)),\n",
    "                'Med': int(np.median(sizes)),\n",
    "                'Std': int(np.std(sizes)),\n",
    "                'CV%': f\"{(np.std(sizes) / np.mean(sizes)) * 100:.1f}\",\n",
    "                'Min': min(sizes),\n",
    "                'Max': max(sizes)\n",
    "            })\n",
    "        except (FileNotFoundError, KeyError) as e:\n",
    "            continue\n",
    "    \n",
    "    if comparison:\n",
    "        comp_df = pd.DataFrame(comparison)\n",
    "        print(\"\\n\", comp_df)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"üéØ COMPREHENSIVE SELECTION GUIDE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        guides = [\n",
    "            (\"Section-Based\", \"‚úì Clean semantic boundaries\", \"General RAG, simple docs\", \"Semantic coherence\", \"Variable sizes\"),\n",
    "            (\"Hierarchical\", \"‚úì Document structure + context\", \"Complex Q&A, technical docs\", \"Rich context, structure\", \"Larger chunks\"),\n",
    "            (\"Type-Aware\", \"‚úì Mixed content types\", \"Technical docs, filtered search\", \"Content type filtering\", \"Complex metadata\"),\n",
    "            (\"Fixed-Overlap\", \"‚úì Consistent chunk sizes\", \"Standard RAG, embeddings\", \"Consistent, overlap\", \"Splits semantics\"),\n",
    "            (\"Page-Based\", \"‚úì Precise page citations\", \"Legal, academic, citations\", \"Easy traceability\", \"Variable sizes\"),\n",
    "            (\"Hybrid-Intelligent\", \"‚úì BEST OF ALL METHODS\", \"Production RAG systems\", \"Adaptive, intelligent\", \"Most complex\")\n",
    "        ]\n",
    "        \n",
    "        for i, (name, when, best_for, pros, cons) in enumerate(guides, 1):\n",
    "            print(f\"\\n{i}. {name}:\")\n",
    "            print(f\"   When: {when}\")\n",
    "            print(f\"   Best for: {best_for}\")\n",
    "            print(f\"   Pros: {pros}\")\n",
    "            print(f\"   Cons: {cons}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"üí° HYBRID INTELLIGENT ADVANTAGES\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"  ‚úì Preserves tables and code integrity (Type-Aware)\")\n",
    "        print(f\"  ‚úì Maintains semantic sections (Section-Based)\")\n",
    "        print(f\"  ‚úì Adds hierarchical context (Hierarchical)\")\n",
    "        print(f\"  ‚úì Uses intelligent splitting with overlap (Fixed-Overlap)\")\n",
    "        print(f\"  ‚úì Tracks pages for citations (Page-Based)\")\n",
    "        print(f\"  ‚úì Adaptive strategy selection based on content\")\n",
    "        print(f\"  ‚úì Optimal for production RAG systems\")\n",
    "        \n",
    "        print(f\"\\nüèÜ RECOMMENDATION: Use Hybrid-Intelligent for production systems!\")\n",
    "\n",
    "# Run ultimate comparison\n",
    "ultimate_chunking_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2d04f",
   "metadata": {},
   "source": [
    "#### üéØ **Hybrid Intelligent Chunking - The Best of All Worlds**\n",
    "\n",
    " **Key Features:**\n",
    "\n",
    "1. **Multi-Strategy Approach**: Selects best strategy per content type\n",
    "2. **Special Content Preservation**: Tables and code kept whole\n",
    "3. **Semantic Awareness**: Respects section boundaries\n",
    "4. **Hierarchical Context**: Adds breadcrumb navigation\n",
    "5. **Intelligent Splitting**: Only splits when necessary with overlap\n",
    "6. **Page Tracking**: Maintains citations\n",
    "7. **Adaptive**: Chooses optimal approach per chunk\n",
    "\n",
    " **Strategy Priority:**\n",
    "\n",
    "1. üéØ Special content (tables, code) ‚Üí Keep whole\n",
    "2. üìö Semantic sections ‚Üí Keep together if size permits\n",
    "3. üîó Add hierarchical context ‚Üí All chunks\n",
    "4. ‚úÇÔ∏è Intelligent splitting ‚Üí Only when exceeding max size\n",
    "5. üîÑ Overlap ‚Üí For split chunks\n",
    "\n",
    " **Perfect For:**\n",
    "\n",
    "- ‚úÖ Production RAG systems\n",
    "- ‚úÖ Complex technical documents\n",
    "- ‚úÖ Mixed content types\n",
    "- ‚úÖ Applications needing traceability + context\n",
    "- ‚úÖ When you want the best possible chunking\n",
    "\n",
    "This is the **ULTIMATE chunking method** - combining all the best practices from every other approach! üèÜ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
